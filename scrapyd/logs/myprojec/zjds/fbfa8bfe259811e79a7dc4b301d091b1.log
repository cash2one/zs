2017-04-20 15:14:28 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: myprojec)
2017-04-20 15:14:28 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'myprojec', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'logs/myprojec/zjds/fbfa8bfe259811e79a7dc4b301d091b1.log', 'NEWSPIDER_MODULE': 'myprojec.spiders', 'SPIDER_MODULES': ['myprojec.spiders']}
2017-04-20 15:14:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-20 15:14:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-20 15:14:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-20 15:14:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['myprojec.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'myprojec.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-20 15:14:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-20 15:14:28 [scrapy.middleware] INFO: Enabled item pipelines:
['myprojec.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-20 15:14:28 [scrapy.core.engine] INFO: Spider opened
2017-04-20 15:14:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-20 15:14:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6025
2017-04-20 15:14:28 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:28 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://zjds.zjol.com.cn/yw/> (referer: None) ['partial']
2017-04-20 15:14:28 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:28 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:28 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:28 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:28 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:28 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://zjds.zjol.com.cn/system/more/123110000/0000/123110000_00000028.shtml> (referer: http://zjds.zjol.com.cn/yw/) ['partial']
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:29 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:14:29 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://zjds.zjol.com.cn/system/2016/08/01/021249171.shtml> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-04-20 15:14:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://zjds.zjol.com.cn/system/2016/07/08/021218840.shtml> (referer: http://zjds.zjol.com.cn/yw/) ['partial']
2017-04-20 15:14:31 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:14:31 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:17:02 [zjds] ERROR: parse_webpage_error:Error 60 connecting to 192.168.1.220:6379. Operation timed out.
2017-04-20 15:17:02 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2017-04-20 15:17:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://zjds.zjol.com.cn/system/2016/07/11/021222067.shtml> (referer: http://zjds.zjol.com.cn/yw/) ['partial']
2017-04-20 15:17:02 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:17:02 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:19:33 [zjds] ERROR: parse_webpage_error:Error 60 connecting to 192.168.1.220:6379. Operation timed out.
2017-04-20 15:19:33 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-20 15:19:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://zjds.zjol.com.cn/system/2016/07/12/021223828.shtml> (referer: http://zjds.zjol.com.cn/yw/) ['partial']
2017-04-20 15:19:33 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:19:33 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:22:04 [zjds] ERROR: parse_webpage_error:Error 60 connecting to 192.168.1.220:6379. Operation timed out.
2017-04-20 15:22:04 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-20 15:22:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/system/2016/07/14/021226929.shtml> (failed 1 times): Connection was refused by other side: 61: Connection refused.
2017-04-20 15:22:04 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:22:04 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:22:05 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/system/2016/07/15/021228399.shtml> (failed 1 times): Connection was refused by other side: 61: Connection refused.
2017-04-20 15:22:05 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:22:05 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:22:07 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/system/2016/07/18/021231058.shtml> (failed 1 times): Connection was refused by other side: 61: Connection refused.
2017-04-20 15:22:07 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:22:07 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:22:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/system/2016/07/21/021235716.shtml> (failed 1 times): Connection was refused by other side: 61: Connection refused.
2017-04-20 15:22:08 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:22:08 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:22:09 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/system/2016/07/22/021237306.shtml> (failed 1 times): Connection was refused by other side: 61: Connection refused.
2017-04-20 15:22:09 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:22:09 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:22:10 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/system/2016/07/25/021240303.shtml> (failed 1 times): Connection was refused by other side: 61: Connection refused.
2017-04-20 15:22:10 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:22:10 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
2017-04-20 15:22:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/system/2016/07/26/021241691.shtml> (failed 1 times): Connection was refused by other side: 61: Connection refused.
2017-04-20 15:22:12 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-20 15:22:12 [requests.packages.urllib3.connectionpool] DEBUG: http://182.254.215.182:5999 "GET / HTTP/1.1" 200 20
