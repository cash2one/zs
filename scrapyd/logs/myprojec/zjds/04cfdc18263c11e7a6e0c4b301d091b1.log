2017-04-21 10:41:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: myprojec)
2017-04-21 10:41:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'myprojec', 'LOG_FILE': 'logs/myprojec/zjds/04cfdc18263c11e7a6e0c4b301d091b1.log', 'NEWSPIDER_MODULE': 'myprojec.spiders', 'SPIDER_MODULES': ['myprojec.spiders']}
2017-04-21 10:41:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-21 10:41:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-21 10:41:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-21 10:41:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['myprojec.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'myprojec.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-21 10:41:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-21 10:41:33 [scrapy.middleware] INFO: Enabled item pipelines:
['myprojec.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-21 10:41:33 [scrapy.core.engine] INFO: Spider opened
2017-04-21 10:41:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-21 10:41:33 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-04-21 10:41:33 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-21 10:42:48 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/yw/> (failed 1 times): HTTPConnectionPool(host='182.254.215.182', port=5999): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x10c58a668>: Failed to establish a new connection: [Errno 60] Operation timed out',))
2017-04-21 10:42:48 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-21 10:44:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://zjds.zjol.com.cn/yw/> (failed 2 times): HTTPConnectionPool(host='182.254.215.182', port=5999): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x10c58ae48>: Failed to establish a new connection: [Errno 60] Operation timed out',))
2017-04-21 10:44:04 [requests.packages.urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 182.254.215.182
2017-04-21 10:45:19 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET http://zjds.zjol.com.cn/yw/> (failed 3 times): HTTPConnectionPool(host='182.254.215.182', port=5999): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x10c5a45c0>: Failed to establish a new connection: [Errno 60] Operation timed out',))
2017-04-21 10:45:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-21 10:45:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://zjds.zjol.com.cn/yw/>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/util/connection.py", line 83, in create_connection
    raise err
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 60] Operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 356, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 964, in send
    self.connect()
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connection.py", line 166, in connect
    conn = self._new_conn()
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x10c5a45c0>: Failed to establish a new connection: [Errno 60] Operation timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/requests/adapters.py", line 423, in send
    timeout=timeout
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 649, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/util/retry.py", line 376, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='182.254.215.182', port=5999): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x10c5a45c0>: Failed to establish a new connection: [Errno 60] Operation timed out',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "/private/var/folders/vp/qslp4_vx1c5ctt1wfmwks_fc0000gn/T/myprojec-v011-y_hlknth.egg/myprojec/midle.py", line 23, in process_request
  File "/usr/local/lib/python3.6/site-packages/requests/api.py", line 70, in get
    return request('get', url, params=params, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/requests/api.py", line 56, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/requests/sessions.py", line 488, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/local/lib/python3.6/site-packages/requests/sessions.py", line 609, in send
    r = adapter.send(request, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/requests/adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='182.254.215.182', port=5999): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x10c5a45c0>: Failed to establish a new connection: [Errno 60] Operation timed out',))
2017-04-21 10:45:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-21 10:45:19 [zjds] INFO: get_webpage_count:0
2017-04-21 10:45:19 [zjds] INFO: success
2017-04-21 10:45:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/requests.exceptions.ConnectionError': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 21, 2, 45, 19, 883327),
 'log_count/DEBUG': 7,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 21, 2, 41, 33, 584361)}
2017-04-21 10:45:19 [scrapy.core.engine] INFO: Spider closed (finished)
