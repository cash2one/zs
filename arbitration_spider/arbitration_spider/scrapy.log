2017-02-27 14:04:09 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-27 14:04:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-27 14:04:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-27 14:04:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-27 14:04:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-27 14:04:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-27 14:04:09 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-27 14:04:09 [scrapy.core.engine] INFO: Spider opened
2017-02-27 14:04:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:05:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:06:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:07:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:07:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 60: Operation timed out.
2017-02-27 14:07:55 [scrapy.core.engine] INFO: Closing spider (finished)
2017-02-27 14:07:55 [guangdong] INFO: get_webpage_count:0
2017-02-27 14:07:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 1110,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 2, 27, 6, 7, 55, 11465),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/disk': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/disk': 3,
 'start_time': datetime.datetime(2017, 2, 27, 6, 4, 9, 519106)}
2017-02-27 14:07:55 [scrapy.core.engine] INFO: Spider closed (finished)
2017-02-27 14:10:39 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-27 14:10:39 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-27 14:10:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-27 14:10:39 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-27 14:10:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-27 14:10:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-27 14:10:39 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-27 14:10:39 [scrapy.core.engine] INFO: Spider opened
2017-02-27 14:10:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:11:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:12:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:13:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:14:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 60: Operation timed out.
2017-02-27 14:14:25 [scrapy.core.engine] INFO: Closing spider (finished)
2017-02-27 14:14:25 [guangdong] INFO: get_webpage_count:0
2017-02-27 14:14:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 1131,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 2, 27, 6, 14, 25, 148274),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/disk': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/disk': 3,
 'start_time': datetime.datetime(2017, 2, 27, 6, 10, 39, 527211)}
2017-02-27 14:14:25 [scrapy.core.engine] INFO: Spider closed (finished)
2017-02-27 14:21:37 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-27 14:21:37 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-27 14:21:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-27 14:21:37 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-27 14:21:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-27 14:21:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-27 14:21:37 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-27 14:21:37 [scrapy.core.engine] INFO: Spider opened
2017-02-27 14:21:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:22:26 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-27 14:22:26 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-27 14:22:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-27 14:22:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-27 14:22:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-27 14:22:49 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-27 14:22:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-27 14:22:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-27 14:22:50 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-27 14:22:50 [scrapy.core.engine] INFO: Spider opened
2017-02-27 14:22:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:23:03 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-27 14:23:03 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-27 14:23:19 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-27 14:23:19 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-27 14:23:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-27 14:23:19 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-27 14:23:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-27 14:23:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-27 14:23:20 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-27 14:23:20 [scrapy.core.engine] INFO: Spider opened
2017-02-27 14:23:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:24:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:25:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:25:22 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-27 14:25:22 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-27 14:25:46 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-27 14:25:46 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-27 14:25:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-27 14:25:46 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-27 14:25:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-27 14:25:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-27 14:25:47 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-27 14:25:47 [scrapy.core.engine] INFO: Spider opened
2017-02-27 14:25:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:26:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:26:50 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-27 14:26:50 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-27 14:26:58 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-27 14:26:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-27 14:26:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-27 14:26:58 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-27 14:26:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-27 14:26:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-27 14:26:58 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-27 14:26:58 [scrapy.core.engine] INFO: Spider opened
2017-02-27 14:26:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-27 14:27:51 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-27 14:27:51 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 15:39:19 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 15:39:19 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 15:39:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 15:39:19 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 15:39:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 15:39:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 15:39:20 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 15:39:20 [scrapy.core.engine] INFO: Spider opened
2017-02-28 15:39:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 15:39:24 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-28 15:39:24 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 15:41:59 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 15:41:59 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 15:41:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 15:41:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 15:42:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 15:42:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 15:42:00 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 15:42:00 [scrapy.core.engine] INFO: Spider opened
2017-02-28 15:42:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 15:42:03 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-28 15:42:03 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 15:44:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 15:44:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 15:44:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 15:44:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 15:44:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 15:44:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 15:44:45 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 15:44:45 [scrapy.core.engine] INFO: Spider opened
2017-02-28 15:44:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 15:44:46 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-28 15:44:46 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 15:45:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 15:45:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 15:45:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 15:45:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 15:45:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 15:45:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 15:45:08 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 15:45:08 [scrapy.core.engine] INFO: Spider opened
2017-02-28 15:45:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 15:46:08 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 50 pages/min), scraped 240 items (at 240 items/min)
2017-02-28 15:47:08 [scrapy.extensions.logstats] INFO: Crawled 99 pages (at 49 pages/min), scraped 240 items (at 0 items/min)
2017-02-28 15:48:08 [scrapy.extensions.logstats] INFO: Crawled 145 pages (at 46 pages/min), scraped 240 items (at 0 items/min)
2017-02-28 15:48:51 [zhejiang] ERROR: save_time_error:time data ' ' does not match format '%Y-%m-%d'
2017-02-28 15:48:51 [zhejiang] ERROR: save_time_error:time data ' ' does not match format '%Y-%m-%d'
2017-02-28 15:49:08 [scrapy.extensions.logstats] INFO: Crawled 188 pages (at 43 pages/min), scraped 367 items (at 127 items/min)
2017-02-28 15:50:08 [scrapy.extensions.logstats] INFO: Crawled 234 pages (at 46 pages/min), scraped 1057 items (at 690 items/min)
2017-02-28 15:51:08 [scrapy.extensions.logstats] INFO: Crawled 282 pages (at 48 pages/min), scraped 1777 items (at 720 items/min)
2017-02-28 15:52:08 [scrapy.extensions.logstats] INFO: Crawled 333 pages (at 51 pages/min), scraped 2531 items (at 754 items/min)
2017-02-28 15:53:08 [scrapy.extensions.logstats] INFO: Crawled 380 pages (at 47 pages/min), scraped 3247 items (at 716 items/min)
2017-02-28 15:53:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-02-28 15:53:32 [zhejiang] INFO: get_webpage_count:3532
2017-02-28 15:53:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 339875,
 'downloader/request_count': 399,
 'downloader/request_method_count/GET': 399,
 'downloader/response_bytes': 4597323,
 'downloader/response_count': 399,
 'downloader/response_status_count/200': 399,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 2, 28, 7, 53, 32, 235758),
 'item_scraped_count': 3532,
 'log_count/ERROR': 2,
 'log_count/INFO': 16,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 399,
 'scheduler/dequeued': 399,
 'scheduler/dequeued/disk': 399,
 'scheduler/enqueued': 399,
 'scheduler/enqueued/disk': 399,
 'start_time': datetime.datetime(2017, 2, 28, 7, 45, 8, 725665)}
2017-02-28 15:53:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-02-28 15:58:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 15:58:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 15:58:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 15:58:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 15:58:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 15:58:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 15:58:25 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 15:58:25 [scrapy.core.engine] INFO: Spider opened
2017-02-28 15:58:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 15:58:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_499.shtml>: HTTP status code is not handled or not allowed
2017-02-28 15:59:25 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 48 pages/min), scraped 30 items (at 30 items/min)
2017-02-28 16:00:01 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-28 16:00:01 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 16:01:51 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 16:01:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 16:01:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 16:01:51 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 16:01:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 16:01:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 16:01:51 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 16:01:51 [scrapy.core.engine] INFO: Spider opened
2017-02-28 16:01:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 16:02:12 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-28 16:02:12 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 16:02:28 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 16:02:28 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 16:02:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 16:02:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 16:02:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 16:02:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 16:02:28 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 16:02:28 [scrapy.core.engine] INFO: Spider opened
2017-02-28 16:02:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 16:02:30 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-28 16:02:30 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 16:02:38 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 16:02:38 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 16:02:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 16:02:38 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 16:02:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 16:02:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 16:02:38 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 16:02:38 [scrapy.core.engine] INFO: Spider opened
2017-02-28 16:02:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 16:02:41 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-28 16:02:41 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 16:04:09 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 16:04:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 16:04:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 16:04:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 16:04:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 16:04:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 16:04:09 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 16:04:09 [scrapy.core.engine] INFO: Spider opened
2017-02-28 16:04:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 16:05:09 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 48 pages/min), scraped 240 items (at 240 items/min)
2017-02-28 16:06:09 [scrapy.extensions.logstats] INFO: Crawled 96 pages (at 48 pages/min), scraped 240 items (at 0 items/min)
2017-02-28 16:07:09 [scrapy.extensions.logstats] INFO: Crawled 143 pages (at 47 pages/min), scraped 240 items (at 0 items/min)
2017-02-28 16:07:52 [zhejiang] ERROR: save_time_error:time data ' ' does not match format '%Y-%m-%d'
2017-02-28 16:07:52 [zhejiang] ERROR: save_time_error:time data ' ' does not match format '%Y-%m-%d'
2017-02-28 16:08:09 [scrapy.extensions.logstats] INFO: Crawled 188 pages (at 45 pages/min), scraped 367 items (at 127 items/min)
2017-02-28 16:09:09 [scrapy.extensions.logstats] INFO: Crawled 238 pages (at 50 pages/min), scraped 1112 items (at 745 items/min)
2017-02-28 16:10:09 [scrapy.extensions.logstats] INFO: Crawled 283 pages (at 45 pages/min), scraped 1792 items (at 680 items/min)
2017-02-28 16:11:09 [scrapy.extensions.logstats] INFO: Crawled 331 pages (at 48 pages/min), scraped 2512 items (at 720 items/min)
2017-02-28 16:12:09 [scrapy.extensions.logstats] INFO: Crawled 377 pages (at 46 pages/min), scraped 3202 items (at 690 items/min)
2017-02-28 16:12:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-02-28 16:12:37 [zhejiang] INFO: get_webpage_count:3532
2017-02-28 16:12:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 339780,
 'downloader/request_count': 399,
 'downloader/request_method_count/GET': 399,
 'downloader/response_bytes': 4597323,
 'downloader/response_count': 399,
 'downloader/response_status_count/200': 399,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 2, 28, 8, 12, 37, 776495),
 'item_scraped_count': 3532,
 'log_count/ERROR': 2,
 'log_count/INFO': 16,
 'log_count/WARNING': 1,
 'request_depth_max': 1,
 'response_received_count': 399,
 'scheduler/dequeued': 399,
 'scheduler/dequeued/disk': 399,
 'scheduler/enqueued': 399,
 'scheduler/enqueued/disk': 399,
 'start_time': datetime.datetime(2017, 2, 28, 8, 4, 9, 594798)}
2017-02-28 16:12:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-02-28 16:13:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-02-28 16:13:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-02-28 16:13:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-02-28 16:13:34 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-02-28 16:13:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-02-28 16:13:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-02-28 16:13:34 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-02-28 16:13:34 [scrapy.core.engine] INFO: Spider opened
2017-02-28 16:13:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-02-28 16:13:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_499.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:14:34 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 49 pages/min), scraped 31 items (at 31 items/min)
2017-02-28 16:15:34 [scrapy.extensions.logstats] INFO: Crawled 98 pages (at 49 pages/min), scraped 80 items (at 49 items/min)
2017-02-28 16:16:34 [scrapy.extensions.logstats] INFO: Crawled 150 pages (at 52 pages/min), scraped 132 items (at 52 items/min)
2017-02-28 16:17:34 [scrapy.extensions.logstats] INFO: Crawled 198 pages (at 48 pages/min), scraped 180 items (at 48 items/min)
2017-02-28 16:18:34 [scrapy.extensions.logstats] INFO: Crawled 247 pages (at 49 pages/min), scraped 228 items (at 48 items/min)
2017-02-28 16:19:34 [scrapy.extensions.logstats] INFO: Crawled 297 pages (at 50 pages/min), scraped 279 items (at 51 items/min)
2017-02-28 16:20:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_498.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_497.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_496.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_495.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_494.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_493.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_492.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_491.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_490.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_489.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_488.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:34 [scrapy.extensions.logstats] INFO: Crawled 347 pages (at 50 pages/min), scraped 318 items (at 39 items/min)
2017-02-28 16:20:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_487.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_486.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_485.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_484.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_483.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_482.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_481.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_480.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_479.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_478.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_477.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_476.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_475.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_474.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:51 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_473.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_472.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_471.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_470.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_469.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_468.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:20:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_467.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_466.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_465.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_464.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_463.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_462.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_461.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_460.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_459.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_458.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_457.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_456.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_454.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_453.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_452.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_451.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_450.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_449.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_448.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_447.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_446.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_445.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_444.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_443.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_442.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_441.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_440.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:34 [scrapy.extensions.logstats] INFO: Crawled 394 pages (at 47 pages/min), scraped 318 items (at 0 items/min)
2017-02-28 16:21:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_439.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_438.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_437.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_436.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_435.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_434.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_433.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_432.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_431.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_430.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_429.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_428.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_427.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_426.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_425.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_424.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_423.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_422.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_421.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:21:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_420.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_419.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_418.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_417.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_416.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_415.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_414.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_413.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_412.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_411.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_410.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_409.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_408.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_407.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_406.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_405.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_404.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_403.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_402.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_401.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_400.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_399.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_398.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_397.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_396.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_395.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_394.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_393.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_392.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:34 [scrapy.extensions.logstats] INFO: Crawled 442 pages (at 48 pages/min), scraped 318 items (at 0 items/min)
2017-02-28 16:22:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_391.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_390.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_389.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_388.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_387.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_386.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_385.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_384.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_383.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_382.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_381.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_380.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_379.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_378.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_377.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_376.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_375.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_374.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_373.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_372.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:22:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_371.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_370.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_369.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_368.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_367.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_366.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_365.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_364.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_363.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_362.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_361.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_360.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_359.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_358.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_357.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_356.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_355.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_354.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_353.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_352.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_351.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_350.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_349.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_348.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_347.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_346.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_345.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_344.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_343.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:34 [scrapy.extensions.logstats] INFO: Crawled 491 pages (at 49 pages/min), scraped 318 items (at 0 items/min)
2017-02-28 16:23:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_342.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_341.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_340.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_339.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_338.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_337.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_336.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_335.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_334.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:45 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_333.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_332.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_331.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_330.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_329.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:51 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_328.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_327.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_326.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_325.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_324.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_323.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:23:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_322.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_321.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_320.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_319.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_318.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_317.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_316.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_315.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_314.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_313.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_312.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_311.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_310.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_309.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_307.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_306.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_305.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_304.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_303.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_302.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_301.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_300.shtml>: HTTP status code is not handled or not allowed
2017-02-28 16:24:34 [scrapy.extensions.logstats] INFO: Crawled 540 pages (at 49 pages/min), scraped 318 items (at 0 items/min)
2017-02-28 16:25:34 [scrapy.extensions.logstats] INFO: Crawled 588 pages (at 48 pages/min), scraped 356 items (at 38 items/min)
2017-02-28 16:26:34 [scrapy.extensions.logstats] INFO: Crawled 636 pages (at 48 pages/min), scraped 404 items (at 48 items/min)
2017-02-28 16:27:34 [scrapy.extensions.logstats] INFO: Crawled 684 pages (at 48 pages/min), scraped 452 items (at 48 items/min)
2017-02-28 16:28:34 [scrapy.extensions.logstats] INFO: Crawled 730 pages (at 46 pages/min), scraped 498 items (at 46 items/min)
2017-02-28 16:29:34 [scrapy.extensions.logstats] INFO: Crawled 779 pages (at 49 pages/min), scraped 547 items (at 49 items/min)
2017-02-28 16:30:34 [scrapy.extensions.logstats] INFO: Crawled 825 pages (at 46 pages/min), scraped 593 items (at 46 items/min)
2017-02-28 16:31:34 [scrapy.extensions.logstats] INFO: Crawled 872 pages (at 47 pages/min), scraped 640 items (at 47 items/min)
2017-02-28 16:32:34 [scrapy.extensions.logstats] INFO: Crawled 917 pages (at 45 pages/min), scraped 668 items (at 28 items/min)
2017-02-28 16:33:34 [scrapy.extensions.logstats] INFO: Crawled 967 pages (at 50 pages/min), scraped 718 items (at 50 items/min)
2017-02-28 16:34:34 [scrapy.extensions.logstats] INFO: Crawled 1011 pages (at 44 pages/min), scraped 762 items (at 44 items/min)
2017-02-28 16:35:34 [scrapy.extensions.logstats] INFO: Crawled 1059 pages (at 48 pages/min), scraped 810 items (at 48 items/min)
2017-02-28 16:36:34 [scrapy.extensions.logstats] INFO: Crawled 1107 pages (at 48 pages/min), scraped 857 items (at 47 items/min)
2017-02-28 16:37:34 [scrapy.extensions.logstats] INFO: Crawled 1157 pages (at 50 pages/min), scraped 908 items (at 51 items/min)
2017-02-28 16:38:34 [scrapy.extensions.logstats] INFO: Crawled 1204 pages (at 47 pages/min), scraped 955 items (at 47 items/min)
2017-02-28 16:39:34 [scrapy.extensions.logstats] INFO: Crawled 1255 pages (at 51 pages/min), scraped 993 items (at 38 items/min)
2017-02-28 16:40:34 [scrapy.extensions.logstats] INFO: Crawled 1297 pages (at 42 pages/min), scraped 1031 items (at 38 items/min)
2017-02-28 16:41:34 [scrapy.extensions.logstats] INFO: Crawled 1345 pages (at 48 pages/min), scraped 1079 items (at 48 items/min)
2017-02-28 16:42:34 [scrapy.extensions.logstats] INFO: Crawled 1393 pages (at 48 pages/min), scraped 1127 items (at 48 items/min)
2017-02-28 16:43:34 [scrapy.extensions.logstats] INFO: Crawled 1441 pages (at 48 pages/min), scraped 1175 items (at 48 items/min)
2017-02-28 16:44:34 [scrapy.extensions.logstats] INFO: Crawled 1488 pages (at 47 pages/min), scraped 1221 items (at 46 items/min)
2017-02-28 16:45:34 [scrapy.extensions.logstats] INFO: Crawled 1535 pages (at 47 pages/min), scraped 1269 items (at 48 items/min)
2017-02-28 16:46:34 [scrapy.extensions.logstats] INFO: Crawled 1585 pages (at 50 pages/min), scraped 1319 items (at 50 items/min)
2017-02-28 16:47:34 [scrapy.extensions.logstats] INFO: Crawled 1633 pages (at 48 pages/min), scraped 1350 items (at 31 items/min)
2017-02-28 16:48:34 [scrapy.extensions.logstats] INFO: Crawled 1683 pages (at 50 pages/min), scraped 1400 items (at 50 items/min)
2017-02-28 16:49:34 [scrapy.extensions.logstats] INFO: Crawled 1729 pages (at 46 pages/min), scraped 1446 items (at 46 items/min)
2017-02-28 16:50:34 [scrapy.extensions.logstats] INFO: Crawled 1778 pages (at 49 pages/min), scraped 1495 items (at 49 items/min)
2017-02-28 16:51:34 [scrapy.extensions.logstats] INFO: Crawled 1828 pages (at 50 pages/min), scraped 1545 items (at 50 items/min)
2017-02-28 16:52:34 [scrapy.extensions.logstats] INFO: Crawled 1875 pages (at 47 pages/min), scraped 1592 items (at 47 items/min)
2017-02-28 16:53:34 [scrapy.extensions.logstats] INFO: Crawled 1925 pages (at 50 pages/min), scraped 1642 items (at 50 items/min)
2017-02-28 16:54:34 [scrapy.extensions.logstats] INFO: Crawled 1974 pages (at 49 pages/min), scraped 1674 items (at 32 items/min)
2017-02-28 16:55:34 [scrapy.extensions.logstats] INFO: Crawled 2024 pages (at 50 pages/min), scraped 1724 items (at 50 items/min)
2017-02-28 16:56:34 [scrapy.extensions.logstats] INFO: Crawled 2073 pages (at 49 pages/min), scraped 1773 items (at 49 items/min)
2017-02-28 16:57:34 [scrapy.extensions.logstats] INFO: Crawled 2119 pages (at 46 pages/min), scraped 1819 items (at 46 items/min)
2017-02-28 16:58:34 [scrapy.extensions.logstats] INFO: Crawled 2166 pages (at 47 pages/min), scraped 1866 items (at 47 items/min)
2017-02-28 16:59:34 [scrapy.extensions.logstats] INFO: Crawled 2215 pages (at 49 pages/min), scraped 1915 items (at 49 items/min)
2017-02-28 17:00:34 [scrapy.extensions.logstats] INFO: Crawled 2262 pages (at 47 pages/min), scraped 1962 items (at 47 items/min)
2017-02-28 17:01:34 [scrapy.extensions.logstats] INFO: Crawled 2312 pages (at 50 pages/min), scraped 2006 items (at 44 items/min)
2017-02-28 17:02:34 [scrapy.extensions.logstats] INFO: Crawled 2361 pages (at 49 pages/min), scraped 2044 items (at 38 items/min)
2017-02-28 17:03:34 [scrapy.extensions.logstats] INFO: Crawled 2410 pages (at 49 pages/min), scraped 2093 items (at 49 items/min)
2017-02-28 17:04:34 [scrapy.extensions.logstats] INFO: Crawled 2457 pages (at 47 pages/min), scraped 2140 items (at 47 items/min)
2017-02-28 17:05:34 [scrapy.extensions.logstats] INFO: Crawled 2506 pages (at 49 pages/min), scraped 2189 items (at 49 items/min)
2017-02-28 17:06:34 [scrapy.extensions.logstats] INFO: Crawled 2552 pages (at 46 pages/min), scraped 2235 items (at 46 items/min)
2017-02-28 17:07:34 [scrapy.extensions.logstats] INFO: Crawled 2601 pages (at 49 pages/min), scraped 2284 items (at 49 items/min)
2017-02-28 17:08:34 [scrapy.extensions.logstats] INFO: Crawled 2651 pages (at 50 pages/min), scraped 2334 items (at 50 items/min)
2017-02-28 17:09:34 [scrapy.extensions.logstats] INFO: Crawled 2701 pages (at 50 pages/min), scraped 2366 items (at 32 items/min)
2017-02-28 17:10:34 [scrapy.extensions.logstats] INFO: Crawled 2748 pages (at 47 pages/min), scraped 2414 items (at 48 items/min)
2017-02-28 17:11:34 [scrapy.extensions.logstats] INFO: Crawled 2798 pages (at 50 pages/min), scraped 2464 items (at 50 items/min)
2017-02-28 17:12:34 [scrapy.extensions.logstats] INFO: Crawled 2845 pages (at 47 pages/min), scraped 2511 items (at 47 items/min)
2017-02-28 17:13:34 [scrapy.extensions.logstats] INFO: Crawled 2893 pages (at 48 pages/min), scraped 2559 items (at 48 items/min)
2017-02-28 17:14:34 [scrapy.extensions.logstats] INFO: Crawled 2932 pages (at 39 pages/min), scraped 2598 items (at 39 items/min)
2017-02-28 17:15:34 [scrapy.extensions.logstats] INFO: Crawled 2982 pages (at 50 pages/min), scraped 2647 items (at 49 items/min)
2017-02-28 17:16:34 [scrapy.extensions.logstats] INFO: Crawled 3029 pages (at 47 pages/min), scraped 2680 items (at 33 items/min)
2017-02-28 17:17:34 [scrapy.extensions.logstats] INFO: Crawled 3078 pages (at 49 pages/min), scraped 2727 items (at 47 items/min)
2017-02-28 17:18:34 [scrapy.extensions.logstats] INFO: Crawled 3128 pages (at 50 pages/min), scraped 2777 items (at 50 items/min)
2017-02-28 17:19:34 [scrapy.extensions.logstats] INFO: Crawled 3173 pages (at 45 pages/min), scraped 2822 items (at 45 items/min)
2017-02-28 17:20:34 [scrapy.extensions.logstats] INFO: Crawled 3222 pages (at 49 pages/min), scraped 2871 items (at 49 items/min)
2017-02-28 17:21:34 [scrapy.extensions.logstats] INFO: Crawled 3270 pages (at 48 pages/min), scraped 2919 items (at 48 items/min)
2017-02-28 17:22:34 [scrapy.extensions.logstats] INFO: Crawled 3319 pages (at 49 pages/min), scraped 2968 items (at 49 items/min)
2017-02-28 17:23:34 [scrapy.extensions.logstats] INFO: Crawled 3367 pages (at 48 pages/min), scraped 3016 items (at 48 items/min)
2017-02-28 17:24:34 [scrapy.extensions.logstats] INFO: Crawled 3418 pages (at 51 pages/min), scraped 3050 items (at 34 items/min)
2017-02-28 17:25:34 [scrapy.extensions.logstats] INFO: Crawled 3467 pages (at 49 pages/min), scraped 3099 items (at 49 items/min)
2017-02-28 17:26:34 [scrapy.extensions.logstats] INFO: Crawled 3517 pages (at 50 pages/min), scraped 3149 items (at 50 items/min)
2017-02-28 17:27:34 [scrapy.extensions.logstats] INFO: Crawled 3569 pages (at 52 pages/min), scraped 3201 items (at 52 items/min)
2017-02-28 17:28:34 [scrapy.extensions.logstats] INFO: Crawled 3619 pages (at 50 pages/min), scraped 3251 items (at 50 items/min)
2017-02-28 17:29:34 [scrapy.extensions.logstats] INFO: Crawled 3668 pages (at 49 pages/min), scraped 3300 items (at 49 items/min)
2017-02-28 17:30:34 [scrapy.extensions.logstats] INFO: Crawled 3715 pages (at 47 pages/min), scraped 3347 items (at 47 items/min)
2017-02-28 17:31:34 [scrapy.extensions.logstats] INFO: Crawled 3764 pages (at 49 pages/min), scraped 3379 items (at 32 items/min)
2017-02-28 17:32:34 [scrapy.extensions.logstats] INFO: Crawled 3812 pages (at 48 pages/min), scraped 3426 items (at 47 items/min)
2017-02-28 17:33:34 [scrapy.extensions.logstats] INFO: Crawled 3860 pages (at 48 pages/min), scraped 3475 items (at 49 items/min)
2017-02-28 17:34:34 [scrapy.extensions.logstats] INFO: Crawled 3910 pages (at 50 pages/min), scraped 3524 items (at 49 items/min)
2017-02-28 17:35:34 [scrapy.extensions.logstats] INFO: Crawled 3957 pages (at 47 pages/min), scraped 3572 items (at 48 items/min)
2017-02-28 17:36:34 [scrapy.extensions.logstats] INFO: Crawled 4005 pages (at 48 pages/min), scraped 3620 items (at 48 items/min)
2017-02-28 17:37:34 [scrapy.extensions.logstats] INFO: Crawled 4054 pages (at 49 pages/min), scraped 3669 items (at 49 items/min)
2017-02-28 17:38:34 [scrapy.extensions.logstats] INFO: Crawled 4104 pages (at 50 pages/min), scraped 3702 items (at 33 items/min)
2017-02-28 17:39:34 [scrapy.extensions.logstats] INFO: Crawled 4154 pages (at 50 pages/min), scraped 3752 items (at 50 items/min)
2017-02-28 17:40:34 [scrapy.extensions.logstats] INFO: Crawled 4203 pages (at 49 pages/min), scraped 3800 items (at 48 items/min)
2017-02-28 17:41:34 [scrapy.extensions.logstats] INFO: Crawled 4251 pages (at 48 pages/min), scraped 3849 items (at 49 items/min)
2017-02-28 17:42:34 [scrapy.extensions.logstats] INFO: Crawled 4299 pages (at 48 pages/min), scraped 3897 items (at 48 items/min)
2017-02-28 17:43:34 [scrapy.extensions.logstats] INFO: Crawled 4347 pages (at 48 pages/min), scraped 3945 items (at 48 items/min)
2017-02-28 17:44:34 [scrapy.extensions.logstats] INFO: Crawled 4395 pages (at 48 pages/min), scraped 3993 items (at 48 items/min)
2017-02-28 17:45:34 [scrapy.extensions.logstats] INFO: Crawled 4445 pages (at 50 pages/min), scraped 4029 items (at 36 items/min)
2017-02-28 17:46:34 [scrapy.extensions.logstats] INFO: Crawled 4492 pages (at 47 pages/min), scraped 4073 items (at 44 items/min)
2017-02-28 17:47:34 [scrapy.extensions.logstats] INFO: Crawled 4540 pages (at 48 pages/min), scraped 4121 items (at 48 items/min)
2017-02-28 17:48:34 [scrapy.extensions.logstats] INFO: Crawled 4588 pages (at 48 pages/min), scraped 4169 items (at 48 items/min)
2017-02-28 17:49:34 [scrapy.extensions.logstats] INFO: Crawled 4636 pages (at 48 pages/min), scraped 4217 items (at 48 items/min)
2017-02-28 17:50:34 [scrapy.extensions.logstats] INFO: Crawled 4685 pages (at 49 pages/min), scraped 4266 items (at 49 items/min)
2017-02-28 17:51:34 [scrapy.extensions.logstats] INFO: Crawled 4733 pages (at 48 pages/min), scraped 4314 items (at 48 items/min)
2017-02-28 17:52:34 [scrapy.extensions.logstats] INFO: Crawled 4782 pages (at 49 pages/min), scraped 4362 items (at 48 items/min)
2017-02-28 17:53:34 [scrapy.extensions.logstats] INFO: Crawled 4829 pages (at 47 pages/min), scraped 4393 items (at 31 items/min)
2017-02-28 17:54:34 [scrapy.extensions.logstats] INFO: Crawled 4878 pages (at 49 pages/min), scraped 4442 items (at 49 items/min)
2017-02-28 17:55:34 [scrapy.extensions.logstats] INFO: Crawled 4926 pages (at 48 pages/min), scraped 4490 items (at 48 items/min)
2017-02-28 17:56:34 [scrapy.extensions.logstats] INFO: Crawled 4973 pages (at 47 pages/min), scraped 4536 items (at 46 items/min)
2017-02-28 17:57:34 [scrapy.extensions.logstats] INFO: Crawled 5022 pages (at 49 pages/min), scraped 4586 items (at 50 items/min)
2017-02-28 17:58:34 [scrapy.extensions.logstats] INFO: Crawled 5070 pages (at 48 pages/min), scraped 4634 items (at 48 items/min)
2017-02-28 17:59:34 [scrapy.extensions.logstats] INFO: Crawled 5120 pages (at 50 pages/min), scraped 4684 items (at 50 items/min)
2017-02-28 18:00:34 [scrapy.extensions.logstats] INFO: Crawled 5167 pages (at 47 pages/min), scraped 4714 items (at 30 items/min)
2017-02-28 18:01:34 [scrapy.extensions.logstats] INFO: Crawled 5215 pages (at 48 pages/min), scraped 4762 items (at 48 items/min)
2017-02-28 18:02:34 [scrapy.extensions.logstats] INFO: Crawled 5261 pages (at 46 pages/min), scraped 4808 items (at 46 items/min)
2017-02-28 18:03:34 [scrapy.extensions.logstats] INFO: Crawled 5312 pages (at 51 pages/min), scraped 4859 items (at 51 items/min)
2017-02-28 18:04:34 [scrapy.extensions.logstats] INFO: Crawled 5361 pages (at 49 pages/min), scraped 4907 items (at 48 items/min)
2017-02-28 18:05:34 [scrapy.extensions.logstats] INFO: Crawled 5408 pages (at 47 pages/min), scraped 4955 items (at 48 items/min)
2017-02-28 18:06:34 [scrapy.extensions.logstats] INFO: Crawled 5455 pages (at 47 pages/min), scraped 5002 items (at 47 items/min)
2017-02-28 18:07:21 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-02-28 18:07:21 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-02-28 18:07:34 [scrapy.extensions.logstats] INFO: Crawled 5503 pages (at 48 pages/min), scraped 5042 items (at 40 items/min)
2017-02-28 18:07:41 [shanghai] INFO: get_webpage_count:5042
2017-02-28 18:07:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 40,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 40,
 'downloader/request_bytes': 3046002,
 'downloader/request_count': 5549,
 'downloader/request_method_count/GET': 5549,
 'downloader/response_bytes': 93199427,
 'downloader/response_count': 5509,
 'downloader/response_status_count/200': 5311,
 'downloader/response_status_count/404': 198,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 2, 28, 10, 7, 41, 317036),
 'item_scraped_count': 5042,
 'log_count/INFO': 321,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 5509,
 'scheduler/dequeued': 5549,
 'scheduler/dequeued/disk': 5549,
 'scheduler/enqueued': 5901,
 'scheduler/enqueued/disk': 5901,
 'start_time': datetime.datetime(2017, 2, 28, 8, 13, 34, 652894)}
2017-02-28 18:07:41 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-01 10:55:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-01 10:55:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-01 10:55:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-03-01 10:55:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-01 10:55:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-01 10:55:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-01 10:55:14 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-01 10:55:14 [scrapy.core.engine] INFO: Spider opened
2017-03-01 10:55:14 [scrapy.core.scheduler] INFO: Resuming crawl (352 requests scheduled)
2017-03-01 10:55:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-01 10:56:14 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 46 pages/min), scraped 46 items (at 46 items/min)
2017-03-01 10:57:14 [scrapy.extensions.logstats] INFO: Crawled 93 pages (at 47 pages/min), scraped 93 items (at 47 items/min)
2017-03-01 10:58:14 [scrapy.extensions.logstats] INFO: Crawled 142 pages (at 49 pages/min), scraped 142 items (at 49 items/min)
2017-03-01 10:59:15 [scrapy.extensions.logstats] INFO: Crawled 187 pages (at 45 pages/min), scraped 186 items (at 44 items/min)
2017-03-01 11:00:14 [scrapy.extensions.logstats] INFO: Crawled 230 pages (at 43 pages/min), scraped 230 items (at 44 items/min)
2017-03-01 11:01:14 [scrapy.extensions.logstats] INFO: Crawled 279 pages (at 49 pages/min), scraped 279 items (at 49 items/min)
2017-03-01 11:02:14 [scrapy.extensions.logstats] INFO: Crawled 325 pages (at 46 pages/min), scraped 308 items (at 29 items/min)
2017-03-01 11:03:14 [scrapy.extensions.logstats] INFO: Crawled 373 pages (at 48 pages/min), scraped 356 items (at 48 items/min)
2017-03-01 11:04:14 [scrapy.extensions.logstats] INFO: Crawled 420 pages (at 47 pages/min), scraped 403 items (at 47 items/min)
2017-03-01 11:05:14 [scrapy.extensions.logstats] INFO: Crawled 468 pages (at 48 pages/min), scraped 451 items (at 48 items/min)
2017-03-01 11:06:14 [scrapy.extensions.logstats] INFO: Crawled 513 pages (at 45 pages/min), scraped 496 items (at 45 items/min)
2017-03-01 11:07:14 [scrapy.extensions.logstats] INFO: Crawled 561 pages (at 48 pages/min), scraped 544 items (at 48 items/min)
2017-03-01 11:08:14 [scrapy.extensions.logstats] INFO: Crawled 609 pages (at 48 pages/min), scraped 592 items (at 48 items/min)
2017-03-01 11:09:14 [scrapy.extensions.logstats] INFO: Crawled 651 pages (at 42 pages/min), scraped 619 items (at 27 items/min)
2017-03-01 11:10:14 [scrapy.extensions.logstats] INFO: Crawled 701 pages (at 50 pages/min), scraped 669 items (at 50 items/min)
2017-03-01 11:11:14 [scrapy.extensions.logstats] INFO: Crawled 750 pages (at 49 pages/min), scraped 718 items (at 49 items/min)
2017-03-01 11:12:14 [scrapy.extensions.logstats] INFO: Crawled 799 pages (at 49 pages/min), scraped 767 items (at 49 items/min)
2017-03-01 11:13:14 [scrapy.extensions.logstats] INFO: Crawled 845 pages (at 46 pages/min), scraped 813 items (at 46 items/min)
2017-03-01 11:14:14 [scrapy.extensions.logstats] INFO: Crawled 895 pages (at 50 pages/min), scraped 862 items (at 49 items/min)
2017-03-01 11:15:14 [scrapy.extensions.logstats] INFO: Crawled 945 pages (at 50 pages/min), scraped 913 items (at 51 items/min)
2017-03-01 11:16:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_308.shtml>: HTTP status code is not handled or not allowed
2017-03-01 11:16:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_455.shtml>: HTTP status code is not handled or not allowed
2017-03-01 11:16:13 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-01 11:16:13 [shanghai] INFO: get_webpage_count:958
2017-03-01 11:16:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 5,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 5,
 'downloader/request_bytes': 547703,
 'downloader/request_count': 998,
 'downloader/request_method_count/GET': 998,
 'downloader/response_bytes': 16715031,
 'downloader/response_count': 993,
 'downloader/response_status_count/200': 991,
 'downloader/response_status_count/404': 2,
 'dupefilter/filtered': 500,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 1, 3, 16, 13, 916042),
 'item_scraped_count': 958,
 'log_count/INFO': 31,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 993,
 'scheduler/dequeued': 998,
 'scheduler/dequeued/disk': 998,
 'scheduler/enqueued': 646,
 'scheduler/enqueued/disk': 646,
 'start_time': datetime.datetime(2017, 3, 1, 2, 55, 14, 688942)}
2017-03-01 11:16:13 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-06 11:09:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 11:09:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 11:09:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-03-06 11:09:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:09:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 11:09:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 11:09:33 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 11:09:33 [scrapy.core.engine] INFO: Spider opened
2017-03-06 11:09:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 11:09:43 [guangdong] ERROR: save_time_error:time data '2017-02-28' does not match format '%Y%m%d'
2017-03-06 11:09:45 [guangdong] ERROR: save_time_error:time data '2017-01-06' does not match format '%Y%m%d'
2017-03-06 11:09:46 [guangdong] ERROR: save_time_error:time data '2017-01-09' does not match format '%Y%m%d'
2017-03-06 11:09:47 [guangdong] ERROR: save_time_error:time data '2017-01-10' does not match format '%Y%m%d'
2017-03-06 11:09:48 [guangdong] ERROR: save_time_error:time data '2017-01-10' does not match format '%Y%m%d'
2017-03-06 11:09:48 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-06 11:09:48 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-06 11:26:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 11:26:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 11:26:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.spiderstate.SpiderState']
2017-03-06 11:26:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:26:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:26:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 11:26:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 11:26:47 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 11:26:47 [scrapy.core.engine] INFO: Spider opened
2017-03-06 11:26:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 11:26:50 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-06 11:26:50 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-06 11:26:50 [guangdong] INFO: get_webpage_count:0
2017-03-06 11:26:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1428,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 6, 3, 26, 50, 225374),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/disk': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/disk': 3,
 'start_time': datetime.datetime(2017, 3, 6, 3, 26, 47, 790329)}
2017-03-06 11:26:50 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-06 11:28:28 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 11:28:28 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 11:28:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 11:28:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:28:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:28:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 11:28:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 11:28:28 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 11:28:28 [scrapy.core.engine] INFO: Spider opened
2017-03-06 11:28:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 11:28:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-06 11:28:31 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-06 11:28:31 [guangdong] INFO: get_webpage_count:0
2017-03-06 11:28:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 6, 3, 28, 31, 314401),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 6, 3, 28, 28, 872081)}
2017-03-06 11:28:31 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-06 11:28:54 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 11:28:54 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 11:28:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 11:28:54 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:28:54 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:28:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 11:28:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 11:28:54 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 11:28:54 [scrapy.core.engine] INFO: Spider opened
2017-03-06 11:28:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 11:29:37 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-06 11:29:37 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-06 11:29:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 11:29:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 11:29:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 11:29:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:29:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:29:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 11:29:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 11:29:45 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 11:29:45 [scrapy.core.engine] INFO: Spider opened
2017-03-06 11:29:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 11:29:53 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-06 11:29:53 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-06 11:33:43 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 11:33:43 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 11:33:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 11:33:43 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:33:43 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:33:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 11:33:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 11:33:44 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 11:33:44 [scrapy.core.engine] INFO: Spider opened
2017-03-06 11:33:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 11:33:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-06 11:33:46 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-06 11:33:46 [guangdong] INFO: get_webpage_count:0
2017-03-06 11:33:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1434,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 6, 3, 33, 46, 398509),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 6, 3, 33, 44, 166939)}
2017-03-06 11:33:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-06 11:37:38 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 11:37:38 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 11:37:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 11:37:38 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:37:38 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 11:37:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 11:37:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 11:37:39 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 11:37:39 [scrapy.core.engine] INFO: Spider opened
2017-03-06 11:37:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 11:37:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-06 11:37:57 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-06 11:37:57 [guangdong] INFO: get_webpage_count:0
2017-03-06 11:37:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 6, 3, 37, 57, 592074),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 6, 3, 37, 39, 325594)}
2017-03-06 11:37:57 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-06 13:34:07 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 13:34:07 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 13:34:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 13:34:07 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 13:34:07 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 13:34:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 13:34:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 13:34:07 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 13:34:07 [scrapy.core.engine] INFO: Spider opened
2017-03-06 13:34:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 13:34:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-06 13:34:10 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-06 13:34:10 [guangdong] INFO: get_webpage_count:0
2017-03-06 13:34:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 6, 5, 34, 10, 230892),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 6, 5, 34, 7, 309751)}
2017-03-06 13:34:10 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-06 13:36:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 13:36:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 13:36:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 13:36:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 13:36:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 13:36:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 13:36:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 13:36:35 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 13:36:35 [scrapy.core.engine] INFO: Spider opened
2017-03-06 13:36:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 13:36:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-06 13:36:38 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-06 13:36:38 [guangdong] INFO: get_webpage_count:0
2017-03-06 13:36:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 6, 5, 36, 38, 160839),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 6, 5, 36, 35, 295592)}
2017-03-06 13:36:38 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-06 13:59:51 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 13:59:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 13:59:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 13:59:51 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 13:59:51 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 13:59:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 13:59:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 13:59:51 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 13:59:51 [scrapy.core.engine] INFO: Spider opened
2017-03-06 13:59:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 14:00:22 [guangdong] ERROR: save_time_error:time data '2017-02-28' does not match format '%Y%m%d'
2017-03-06 14:00:23 [guangdong] ERROR: save_time_error:time data '2016-12-09' does not match format '%Y%m%d'
2017-03-06 14:00:24 [guangdong] ERROR: save_time_error:time data '2016-12-12' does not match format '%Y%m%d'
2017-03-06 14:00:26 [guangdong] ERROR: save_time_error:time data '2016-12-12' does not match format '%Y%m%d'
2017-03-06 14:00:27 [guangdong] ERROR: save_time_error:time data '2016-12-19' does not match format '%Y%m%d'
2017-03-06 14:00:29 [guangdong] ERROR: save_time_error:time data '2016-12-20' does not match format '%Y%m%d'
2017-03-06 14:00:30 [guangdong] ERROR: save_time_error:time data '2016-12-20' does not match format '%Y%m%d'
2017-03-06 14:00:31 [guangdong] ERROR: save_time_error:time data '2016-12-24' does not match format '%Y%m%d'
2017-03-06 14:00:31 [guangdong] ERROR: save_time_error:time data '2016-12-27' does not match format '%Y%m%d'
2017-03-06 14:00:32 [guangdong] ERROR: save_time_error:time data '2016-12-28' does not match format '%Y%m%d'
2017-03-06 14:00:33 [guangdong] ERROR: save_time_error:time data '2016-12-28' does not match format '%Y%m%d'
2017-03-06 14:00:34 [guangdong] ERROR: save_time_error:time data '2016-12-30' does not match format '%Y%m%d'
2017-03-06 14:00:35 [guangdong] ERROR: save_time_error:time data '2017-01-03' does not match format '%Y%m%d'
2017-03-06 14:00:37 [guangdong] ERROR: save_time_error:time data '2017-01-03' does not match format '%Y%m%d'
2017-03-06 14:00:37 [guangdong] ERROR: save_time_error:time data '2017-01-04' does not match format '%Y%m%d'
2017-03-06 14:00:39 [guangdong] ERROR: save_time_error:time data '2017-01-05' does not match format '%Y%m%d'
2017-03-06 14:00:41 [guangdong] ERROR: save_time_error:time data '2015-02-06' does not match format '%Y%m%d'
2017-03-06 14:00:42 [guangdong] ERROR: save_time_error:time data '2014-07-25' does not match format '%Y%m%d'
2017-03-06 14:00:43 [guangdong] ERROR: save_time_error:time data '2014-07-25' does not match format '%Y%m%d'
2017-03-06 14:00:44 [guangdong] ERROR: save_time_error:time data '2014-07-25' does not match format '%Y%m%d'
2017-03-06 14:00:45 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-06 14:00:47 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-06 14:00:47 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-06 14:00:48 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-06 14:00:50 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-06 14:00:51 [guangdong] ERROR: save_time_error:time data '2014-07-29' does not match format '%Y%m%d'
2017-03-06 14:00:51 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 27 pages/min), scraped 26 items (at 26 items/min)
2017-03-06 14:00:53 [guangdong] ERROR: save_time_error:time data '2014-07-29' does not match format '%Y%m%d'
2017-03-06 14:00:54 [guangdong] ERROR: save_time_error:time data '2014-07-31' does not match format '%Y%m%d'
2017-03-06 14:01:51 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 2 pages/min), scraped 28 items (at 2 items/min)
2017-03-06 14:02:20 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-06 14:02:20 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-06 14:02:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-06 14:02:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-06 14:02:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-06 14:02:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 14:02:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-06 14:02:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-06 14:02:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-06 14:02:24 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-06 14:02:24 [scrapy.core.engine] INFO: Spider opened
2017-03-06 14:02:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-06 14:02:36 [guangdong] ERROR: save_time_error:time data '2017-02-28' does not match format '%Y%m%d'
2017-03-06 14:02:38 [guangdong] ERROR: save_time_error:time data '2016-12-09' does not match format '%Y%m%d'
2017-03-06 14:02:39 [guangdong] ERROR: save_time_error:time data '2016-12-12' does not match format '%Y%m%d'
2017-03-06 14:02:40 [guangdong] ERROR: save_time_error:time data '2016-12-12' does not match format '%Y%m%d'
2017-03-06 14:02:41 [guangdong] ERROR: save_time_error:time data '2016-12-19' does not match format '%Y%m%d'
2017-03-06 14:02:43 [guangdong] ERROR: save_time_error:time data '2016-12-20' does not match format '%Y%m%d'
2017-03-06 14:02:44 [guangdong] ERROR: save_time_error:time data '2016-12-20' does not match format '%Y%m%d'
2017-03-06 14:02:44 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-06 14:02:44 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-06 14:02:45 [guangdong] ERROR: save_time_error:time data '2016-12-24' does not match format '%Y%m%d'
2017-03-06 14:02:46 [guangdong] ERROR: save_time_error:time data '2016-12-27' does not match format '%Y%m%d'
2017-03-06 14:02:48 [guangdong] ERROR: save_time_error:time data '2016-12-28' does not match format '%Y%m%d'
2017-03-06 14:02:49 [guangdong] ERROR: save_time_error:time data '2016-12-28' does not match format '%Y%m%d'
2017-03-06 14:02:50 [guangdong] ERROR: save_time_error:time data '2016-12-30' does not match format '%Y%m%d'
2017-03-06 14:02:51 [guangdong] ERROR: save_time_error:time data '2017-01-03' does not match format '%Y%m%d'
2017-03-06 14:02:52 [guangdong] ERROR: save_time_error:time data '2017-01-03' does not match format '%Y%m%d'
2017-03-06 14:02:53 [guangdong] ERROR: save_time_error:time data '2017-01-04' does not match format '%Y%m%d'
2017-03-06 14:02:55 [guangdong] ERROR: save_time_error:time data '2017-01-05' does not match format '%Y%m%d'
2017-03-06 14:02:56 [guangdong] ERROR: save_time_error:time data '2014-11-26' does not match format '%Y%m%d'
2017-03-07 13:24:10 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-07 13:24:10 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-07 13:24:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-07 13:24:10 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:24:10 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:24:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-07 13:24:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-07 13:24:11 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-07 13:24:11 [scrapy.core.engine] INFO: Spider opened
2017-03-07 13:24:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 13:25:17 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-07 13:25:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-07 13:25:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-07 13:25:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-07 13:25:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:25:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:25:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-07 13:25:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-07 13:25:44 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-07 13:25:44 [scrapy.core.engine] INFO: Spider opened
2017-03-07 13:25:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 13:26:09 [guangdong] ERROR: save_time_error:time data '2017-02-28' does not match format '%Y%m%d'
2017-03-07 13:26:11 [guangdong] ERROR: save_time_error:time data '2017-01-06' does not match format '%Y%m%d'
2017-03-07 13:26:11 [guangdong] ERROR: save_time_error:time data '2017-01-10' does not match format '%Y%m%d'
2017-03-07 13:26:11 [guangdong] ERROR: save_time_error:time data '2017-01-09' does not match format '%Y%m%d'
2017-03-07 13:26:12 [guangdong] ERROR: save_time_error:time data '2017-01-11' does not match format '%Y%m%d'
2017-03-07 13:26:12 [guangdong] ERROR: save_time_error:time data '2017-01-10' does not match format '%Y%m%d'
2017-03-07 13:26:13 [guangdong] ERROR: save_time_error:time data '2017-01-11' does not match format '%Y%m%d'
2017-03-07 13:26:13 [guangdong] ERROR: save_time_error:time data '2017-01-10' does not match format '%Y%m%d'
2017-03-07 13:26:29 [guangdong] ERROR: save_time_error:time data '2017-01-12' does not match format '%Y%m%d'
2017-03-07 13:26:30 [guangdong] ERROR: save_time_error:time data '2017-01-13' does not match format '%Y%m%d'
2017-03-07 13:26:30 [guangdong] ERROR: save_time_error:time data '2017-01-13' does not match format '%Y%m%d'
2017-03-07 13:26:30 [guangdong] ERROR: save_time_error:time data '2017-01-20' does not match format '%Y%m%d'
2017-03-07 13:26:30 [guangdong] ERROR: save_time_error:time data '2017-01-19' does not match format '%Y%m%d'
2017-03-07 13:26:30 [guangdong] ERROR: save_time_error:time data '2017-01-18' does not match format '%Y%m%d'
2017-03-07 13:26:30 [guangdong] ERROR: save_time_error:time data '2017-01-16' does not match format '%Y%m%d'
2017-03-07 13:26:31 [guangdong] ERROR: save_time_error:time data '2017-01-20' does not match format '%Y%m%d'
2017-03-07 13:26:50 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 17 pages/min), scraped 16 items (at 16 items/min)
2017-03-07 13:27:11 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-07 13:27:11 [guangdong] ERROR: save_time_error:time data '2014-07-29' does not match format '%Y%m%d'
2017-03-07 13:27:11 [guangdong] ERROR: save_time_error:time data '2014-07-29' does not match format '%Y%m%d'
2017-03-07 13:27:11 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-07 13:27:12 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-07 13:27:12 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-07 13:27:12 [guangdong] ERROR: save_time_error:time data '2014-07-28' does not match format '%Y%m%d'
2017-03-07 13:27:12 [guangdong] ERROR: save_time_error:time data '2014-07-31' does not match format '%Y%m%d'
2017-03-07 13:27:13 [guangdong] ERROR: save_time_error:time data '2014-08-01' does not match format '%Y%m%d'
2017-03-07 13:27:17 [guangdong] ERROR: save_time_error:time data '2014-08-01' does not match format '%Y%m%d'
2017-03-07 13:27:17 [guangdong] ERROR: save_time_error:time data '2014-08-05' does not match format '%Y%m%d'
2017-03-07 13:27:17 [guangdong] ERROR: save_time_error:time data '2014-08-05' does not match format '%Y%m%d'
2017-03-07 13:27:17 [guangdong] ERROR: save_time_error:time data '2014-08-04' does not match format '%Y%m%d'
2017-03-07 13:27:17 [guangdong] ERROR: save_time_error:time data '2014-08-06' does not match format '%Y%m%d'
2017-03-07 13:27:17 [guangdong] ERROR: save_time_error:time data '2014-08-05' does not match format '%Y%m%d'
2017-03-07 13:27:17 [guangdong] ERROR: save_time_error:time data '2014-08-05' does not match format '%Y%m%d'
2017-03-07 13:27:20 [guangdong] ERROR: save_time_error:time data '2014-08-07' does not match format '%Y%m%d'
2017-03-07 13:27:20 [guangdong] ERROR: save_time_error:time data '2014-08-12' does not match format '%Y%m%d'
2017-03-07 13:27:20 [guangdong] ERROR: save_time_error:time data '2014-08-11' does not match format '%Y%m%d'
2017-03-07 13:27:20 [guangdong] ERROR: save_time_error:time data '2014-08-13' does not match format '%Y%m%d'
2017-03-07 13:27:20 [guangdong] ERROR: save_time_error:time data '2014-08-15' does not match format '%Y%m%d'
2017-03-07 13:27:20 [guangdong] ERROR: save_time_error:time data '2014-08-14' does not match format '%Y%m%d'
2017-03-07 13:27:20 [guangdong] ERROR: save_time_error:time data '2014-08-14' does not match format '%Y%m%d'
2017-03-07 13:27:20 [guangdong] ERROR: save_time_error:time data '2014-08-14' does not match format '%Y%m%d'
2017-03-07 13:27:23 [guangdong] ERROR: save_time_error:time data '2014-08-18' does not match format '%Y%m%d'
2017-03-07 13:27:23 [guangdong] ERROR: save_time_error:time data '2014-08-18' does not match format '%Y%m%d'
2017-03-07 13:27:23 [guangdong] ERROR: save_time_error:time data '2014-08-19' does not match format '%Y%m%d'
2017-03-07 13:27:23 [guangdong] ERROR: save_time_error:time data '2014-08-21' does not match format '%Y%m%d'
2017-03-07 13:27:23 [guangdong] ERROR: save_time_error:time data '2014-08-20' does not match format '%Y%m%d'
2017-03-07 13:27:23 [guangdong] ERROR: save_time_error:time data '2014-08-21' does not match format '%Y%m%d'
2017-03-07 13:27:24 [guangdong] ERROR: save_time_error:time data '2014-08-20' does not match format '%Y%m%d'
2017-03-07 13:27:24 [guangdong] ERROR: save_time_error:time data '2014-08-21' does not match format '%Y%m%d'
2017-03-07 13:27:28 [guangdong] ERROR: save_time_error:time data '2014-08-21' does not match format '%Y%m%d'
2017-03-07 13:27:28 [guangdong] ERROR: save_time_error:time data '2014-08-21' does not match format '%Y%m%d'
2017-03-07 13:27:29 [guangdong] ERROR: save_time_error:time data '2014-08-23' does not match format '%Y%m%d'
2017-03-07 13:27:29 [guangdong] ERROR: save_time_error:time data '2014-08-22' does not match format '%Y%m%d'
2017-03-07 13:27:29 [guangdong] ERROR: save_time_error:time data '2014-08-22' does not match format '%Y%m%d'
2017-03-07 13:27:29 [guangdong] ERROR: save_time_error:time data '2014-08-25' does not match format '%Y%m%d'
2017-03-07 13:27:29 [guangdong] ERROR: save_time_error:time data '2014-08-27' does not match format '%Y%m%d'
2017-03-07 13:27:29 [guangdong] ERROR: save_time_error:time data '2014-08-22' does not match format '%Y%m%d'
2017-03-07 13:27:33 [guangdong] ERROR: save_time_error:time data '2014-08-28' does not match format '%Y%m%d'
2017-03-07 13:27:34 [guangdong] ERROR: save_time_error:time data '2014-08-28' does not match format '%Y%m%d'
2017-03-07 13:27:35 [guangdong] ERROR: save_time_error:time data '2014-09-01' does not match format '%Y%m%d'
2017-03-07 13:27:35 [guangdong] ERROR: save_time_error:time data '2014-09-01' does not match format '%Y%m%d'
2017-03-07 13:27:35 [guangdong] ERROR: save_time_error:time data '2014-08-29' does not match format '%Y%m%d'
2017-03-07 13:27:35 [guangdong] ERROR: save_time_error:time data '2014-08-29' does not match format '%Y%m%d'
2017-03-07 13:27:35 [guangdong] ERROR: save_time_error:time data '2014-09-01' does not match format '%Y%m%d'
2017-03-07 13:27:35 [guangdong] ERROR: save_time_error:time data '2014-08-28' does not match format '%Y%m%d'
2017-03-07 13:27:38 [guangdong] ERROR: save_time_error:time data '2014-09-02' does not match format '%Y%m%d'
2017-03-07 13:27:38 [guangdong] ERROR: save_time_error:time data '2014-09-02' does not match format '%Y%m%d'
2017-03-07 13:27:41 [guangdong] ERROR: save_time_error:time data '2014-09-04' does not match format '%Y%m%d'
2017-03-07 13:27:41 [guangdong] ERROR: save_time_error:time data '2014-09-04' does not match format '%Y%m%d'
2017-03-07 13:27:41 [guangdong] ERROR: save_time_error:time data '2014-09-04' does not match format '%Y%m%d'
2017-03-07 13:27:41 [guangdong] ERROR: save_time_error:time data '2014-09-04' does not match format '%Y%m%d'
2017-03-07 13:27:41 [guangdong] ERROR: save_time_error:time data '2014-09-02' does not match format '%Y%m%d'
2017-03-07 13:27:41 [guangdong] ERROR: save_time_error:time data '2014-09-04' does not match format '%Y%m%d'
2017-03-07 13:27:55 [guangdong] ERROR: save_time_error:time data '2014-09-09' does not match format '%Y%m%d'
2017-03-07 13:27:55 [scrapy.extensions.logstats] INFO: Crawled 81 pages (at 64 pages/min), scraped 73 items (at 57 items/min)
2017-03-07 13:27:55 [guangdong] ERROR: save_time_error:time data '2014-09-09' does not match format '%Y%m%d'
2017-03-07 13:27:55 [guangdong] ERROR: save_time_error:time data '2014-09-11' does not match format '%Y%m%d'
2017-03-07 13:27:55 [guangdong] ERROR: save_time_error:time data '2014-09-12' does not match format '%Y%m%d'
2017-03-07 13:27:57 [guangdong] ERROR: save_time_error:time data '2014-09-10' does not match format '%Y%m%d'
2017-03-07 13:27:57 [guangdong] ERROR: save_time_error:time data '2014-09-15' does not match format '%Y%m%d'
2017-03-07 13:27:57 [guangdong] ERROR: save_time_error:time data '2014-09-15' does not match format '%Y%m%d'
2017-03-07 13:27:57 [guangdong] ERROR: save_time_error:time data '2014-09-05' does not match format '%Y%m%d'
2017-03-07 13:27:59 [guangdong] ERROR: save_time_error:time data '2015-09-16' does not match format '%Y%m%d'
2017-03-07 13:28:03 [guangdong] ERROR: save_time_error:time data '2014-09-16' does not match format '%Y%m%d'
2017-03-07 13:28:03 [guangdong] ERROR: save_time_error:time data '2014-09-17' does not match format '%Y%m%d'
2017-03-07 13:28:03 [guangdong] ERROR: save_time_error:time data '2014-09-17' does not match format '%Y%m%d'
2017-03-07 13:28:03 [guangdong] ERROR: save_time_error:time data '2014-09-18' does not match format '%Y%m%d'
2017-03-07 13:28:03 [guangdong] ERROR: save_time_error:time data '2014-09-19' does not match format '%Y%m%d'
2017-03-07 13:28:03 [guangdong] ERROR: save_time_error:time data '2014-09-17' does not match format '%Y%m%d'
2017-03-07 13:28:04 [guangdong] ERROR: save_time_error:time data '2014-09-17' does not match format '%Y%m%d'
2017-03-07 13:28:09 [guangdong] ERROR: save_time_error:time data '2014-09-23' does not match format '%Y%m%d'
2017-03-07 13:28:10 [guangdong] ERROR: save_time_error:time data '2014-09-22' does not match format '%Y%m%d'
2017-03-07 13:28:10 [guangdong] ERROR: save_time_error:time data '2014-09-23' does not match format '%Y%m%d'
2017-03-07 13:28:10 [guangdong] ERROR: save_time_error:time data '2014-09-25' does not match format '%Y%m%d'
2017-03-07 13:28:10 [guangdong] ERROR: save_time_error:time data '2014-09-25' does not match format '%Y%m%d'
2017-03-07 13:28:10 [guangdong] ERROR: save_time_error:time data '2014-09-24' does not match format '%Y%m%d'
2017-03-07 13:28:10 [guangdong] ERROR: save_time_error:time data '2014-09-25' does not match format '%Y%m%d'
2017-03-07 13:28:11 [guangdong] ERROR: save_time_error:time data '2014-09-25' does not match format '%Y%m%d'
2017-03-07 13:28:18 [guangdong] ERROR: save_time_error:time data '2014-09-26' does not match format '%Y%m%d'
2017-03-07 13:28:18 [guangdong] ERROR: save_time_error:time data '2014-09-28' does not match format '%Y%m%d'
2017-03-07 13:28:18 [guangdong] ERROR: save_time_error:time data '2014-09-26' does not match format '%Y%m%d'
2017-03-07 13:28:20 [guangdong] ERROR: save_time_error:time data '2014-09-26' does not match format '%Y%m%d'
2017-03-07 13:28:24 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:28:24 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:28:24 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:28:25 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:28:28 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:28:48 [scrapy.extensions.logstats] INFO: Crawled 106 pages (at 25 pages/min), scraped 105 items (at 32 items/min)
2017-03-07 13:28:55 [guangdong] ERROR: save_time_error:time data '2014-10-24' does not match format '%Y%m%d'
2017-03-07 13:28:55 [guangdong] ERROR: save_time_error:time data '2014-10-24' does not match format '%Y%m%d'
2017-03-07 13:28:55 [guangdong] ERROR: save_time_error:time data '2014-10-28' does not match format '%Y%m%d'
2017-03-07 13:28:55 [guangdong] ERROR: save_time_error:time data '2014-10-28' does not match format '%Y%m%d'
2017-03-07 13:28:55 [guangdong] ERROR: save_time_error:time data '2014-10-27' does not match format '%Y%m%d'
2017-03-07 13:28:55 [guangdong] ERROR: save_time_error:time data '2014-10-29' does not match format '%Y%m%d'
2017-03-07 13:28:55 [guangdong] ERROR: save_time_error:time data '2014-10-27' does not match format '%Y%m%d'
2017-03-07 13:28:58 [guangdong] ERROR: save_time_error:time data '2014-10-29' does not match format '%Y%m%d'
2017-03-07 13:28:58 [guangdong] ERROR: save_time_error:time data '2014-10-29' does not match format '%Y%m%d'
2017-03-07 13:28:58 [guangdong] ERROR: save_time_error:time data '2014-10-31' does not match format '%Y%m%d'
2017-03-07 13:28:58 [guangdong] ERROR: save_time_error:time data '2014-10-30' does not match format '%Y%m%d'
2017-03-07 13:28:58 [guangdong] ERROR: save_time_error:time data '2014-10-30' does not match format '%Y%m%d'
2017-03-07 13:28:58 [guangdong] ERROR: save_time_error:time data '2014-10-30' does not match format '%Y%m%d'
2017-03-07 13:28:58 [guangdong] ERROR: save_time_error:time data '2014-10-31' does not match format '%Y%m%d'
2017-03-07 13:29:01 [guangdong] ERROR: save_time_error:time data '2014-10-31' does not match format '%Y%m%d'
2017-03-07 13:29:01 [guangdong] ERROR: save_time_error:time data '2014-10-31' does not match format '%Y%m%d'
2017-03-07 13:29:01 [guangdong] ERROR: save_time_error:time data '2014-10-31' does not match format '%Y%m%d'
2017-03-07 13:29:01 [guangdong] ERROR: save_time_error:time data '2014-11-03' does not match format '%Y%m%d'
2017-03-07 13:29:01 [guangdong] ERROR: save_time_error:time data '2014-11-03' does not match format '%Y%m%d'
2017-03-07 13:29:01 [guangdong] ERROR: save_time_error:time data '2014-10-31' does not match format '%Y%m%d'
2017-03-07 13:29:01 [guangdong] ERROR: save_time_error:time data '2014-10-31' does not match format '%Y%m%d'
2017-03-07 13:29:03 [guangdong] ERROR: save_time_error:time data '2014-11-06' does not match format '%Y%m%d'
2017-03-07 13:29:03 [guangdong] ERROR: save_time_error:time data '2014-11-04' does not match format '%Y%m%d'
2017-03-07 13:29:03 [guangdong] ERROR: save_time_error:time data '2014-11-10' does not match format '%Y%m%d'
2017-03-07 13:29:03 [guangdong] ERROR: save_time_error:time data '2014-11-07' does not match format '%Y%m%d'
2017-03-07 13:29:03 [guangdong] ERROR: save_time_error:time data '2014-11-13' does not match format '%Y%m%d'
2017-03-07 13:29:03 [guangdong] ERROR: save_time_error:time data '2014-11-05' does not match format '%Y%m%d'
2017-03-07 13:29:03 [guangdong] ERROR: save_time_error:time data '2014-11-07' does not match format '%Y%m%d'
2017-03-07 13:29:06 [guangdong] ERROR: save_time_error:time data '2014-11-14' does not match format '%Y%m%d'
2017-03-07 13:29:06 [guangdong] ERROR: save_time_error:time data '2014-11-13' does not match format '%Y%m%d'
2017-03-07 13:29:06 [guangdong] ERROR: save_time_error:time data '2014-11-14' does not match format '%Y%m%d'
2017-03-07 13:29:06 [guangdong] ERROR: save_time_error:time data '2014-11-14' does not match format '%Y%m%d'
2017-03-07 13:29:06 [guangdong] ERROR: save_time_error:time data '2014-11-17' does not match format '%Y%m%d'
2017-03-07 13:29:06 [guangdong] ERROR: save_time_error:time data '2014-11-17' does not match format '%Y%m%d'
2017-03-07 13:29:06 [guangdong] ERROR: save_time_error:time data '2014-11-14' does not match format '%Y%m%d'
2017-03-07 13:29:09 [guangdong] ERROR: save_time_error:time data '2014-11-18' does not match format '%Y%m%d'
2017-03-07 13:29:09 [guangdong] ERROR: save_time_error:time data '2014-11-18' does not match format '%Y%m%d'
2017-03-07 13:29:09 [guangdong] ERROR: save_time_error:time data '2014-11-19' does not match format '%Y%m%d'
2017-03-07 13:29:09 [guangdong] ERROR: save_time_error:time data '2014-11-19' does not match format '%Y%m%d'
2017-03-07 13:29:09 [guangdong] ERROR: save_time_error:time data '2014-11-18' does not match format '%Y%m%d'
2017-03-07 13:29:09 [guangdong] ERROR: save_time_error:time data '2014-11-17' does not match format '%Y%m%d'
2017-03-07 13:29:09 [guangdong] ERROR: save_time_error:time data '2014-11-19' does not match format '%Y%m%d'
2017-03-07 13:29:11 [guangdong] ERROR: save_time_error:time data '2014-11-20' does not match format '%Y%m%d'
2017-03-07 13:29:11 [guangdong] ERROR: save_time_error:time data '2014-11-20' does not match format '%Y%m%d'
2017-03-07 13:29:11 [guangdong] ERROR: save_time_error:time data '2014-11-20' does not match format '%Y%m%d'
2017-03-07 13:29:11 [guangdong] ERROR: save_time_error:time data '2014-11-21' does not match format '%Y%m%d'
2017-03-07 13:29:11 [guangdong] ERROR: save_time_error:time data '2014-11-24' does not match format '%Y%m%d'
2017-03-07 13:29:11 [guangdong] ERROR: save_time_error:time data '2014-11-24' does not match format '%Y%m%d'
2017-03-07 13:29:11 [guangdong] ERROR: save_time_error:time data '2014-11-21' does not match format '%Y%m%d'
2017-03-07 13:29:14 [guangdong] ERROR: save_time_error:time data '2014-11-25' does not match format '%Y%m%d'
2017-03-07 13:29:14 [guangdong] ERROR: save_time_error:time data '2014-11-28' does not match format '%Y%m%d'
2017-03-07 13:29:14 [guangdong] ERROR: save_time_error:time data '2014-11-25' does not match format '%Y%m%d'
2017-03-07 13:29:14 [guangdong] ERROR: save_time_error:time data '2014-11-26' does not match format '%Y%m%d'
2017-03-07 13:29:14 [guangdong] ERROR: save_time_error:time data '2014-11-26' does not match format '%Y%m%d'
2017-03-07 13:29:14 [guangdong] ERROR: save_time_error:time data '2014-11-26' does not match format '%Y%m%d'
2017-03-07 13:29:14 [guangdong] ERROR: save_time_error:time data '2014-11-26' does not match format '%Y%m%d'
2017-03-07 13:29:17 [guangdong] ERROR: save_time_error:time data '2014-11-28' does not match format '%Y%m%d'
2017-03-07 13:29:17 [guangdong] ERROR: save_time_error:time data '2014-12-01' does not match format '%Y%m%d'
2017-03-07 13:29:17 [guangdong] ERROR: save_time_error:time data '2014-12-02' does not match format '%Y%m%d'
2017-03-07 13:29:17 [guangdong] ERROR: save_time_error:time data '2014-12-04' does not match format '%Y%m%d'
2017-03-07 13:29:17 [guangdong] ERROR: save_time_error:time data '2014-12-01' does not match format '%Y%m%d'
2017-03-07 13:29:17 [guangdong] ERROR: save_time_error:time data '2014-12-01' does not match format '%Y%m%d'
2017-03-07 13:29:17 [guangdong] ERROR: save_time_error:time data '2014-12-02' does not match format '%Y%m%d'
2017-03-07 13:29:19 [guangdong] ERROR: save_time_error:time data '2014-12-04' does not match format '%Y%m%d'
2017-03-07 13:29:20 [guangdong] ERROR: save_time_error:time data '2014-12-09' does not match format '%Y%m%d'
2017-03-07 13:29:20 [guangdong] ERROR: save_time_error:time data '2014-12-08' does not match format '%Y%m%d'
2017-03-07 13:29:20 [guangdong] ERROR: save_time_error:time data '2014-12-09' does not match format '%Y%m%d'
2017-03-07 13:29:20 [guangdong] ERROR: save_time_error:time data '2014-12-05' does not match format '%Y%m%d'
2017-03-07 13:29:20 [guangdong] ERROR: save_time_error:time data '2014-12-09' does not match format '%Y%m%d'
2017-03-07 13:29:20 [guangdong] ERROR: save_time_error:time data '2014-12-09' does not match format '%Y%m%d'
2017-03-07 13:29:22 [guangdong] ERROR: save_time_error:time data '2014-12-09' does not match format '%Y%m%d'
2017-03-07 13:29:22 [guangdong] ERROR: save_time_error:time data '2014-12-09' does not match format '%Y%m%d'
2017-03-07 13:29:22 [guangdong] ERROR: save_time_error:time data '2014-12-10' does not match format '%Y%m%d'
2017-03-07 13:29:22 [guangdong] ERROR: save_time_error:time data '2014-12-09' does not match format '%Y%m%d'
2017-03-07 13:29:22 [guangdong] ERROR: save_time_error:time data '2014-12-10' does not match format '%Y%m%d'
2017-03-07 13:29:22 [guangdong] ERROR: save_time_error:time data '2014-12-15' does not match format '%Y%m%d'
2017-03-07 13:29:23 [guangdong] ERROR: save_time_error:time data '2014-12-09' does not match format '%Y%m%d'
2017-03-07 13:29:24 [guangdong] ERROR: save_time_error:time data '2014-12-16' does not match format '%Y%m%d'
2017-03-07 13:29:26 [guangdong] ERROR: save_time_error:time data '2014-12-17' does not match format '%Y%m%d'
2017-03-07 13:29:27 [guangdong] ERROR: save_time_error:time data '2014-12-18' does not match format '%Y%m%d'
2017-03-07 13:29:27 [guangdong] ERROR: save_time_error:time data '2014-12-18' does not match format '%Y%m%d'
2017-03-07 13:29:27 [guangdong] ERROR: save_time_error:time data '2014-12-18' does not match format '%Y%m%d'
2017-03-07 13:29:27 [guangdong] ERROR: save_time_error:time data '2014-12-18' does not match format '%Y%m%d'
2017-03-07 13:29:27 [guangdong] ERROR: save_time_error:time data '2014-12-17' does not match format '%Y%m%d'
2017-03-07 13:29:29 [guangdong] ERROR: save_time_error:time data '2014-12-24' does not match format '%Y%m%d'
2017-03-07 13:29:29 [guangdong] ERROR: save_time_error:time data '2014-12-18' does not match format '%Y%m%d'
2017-03-07 13:29:29 [guangdong] ERROR: save_time_error:time data '2014-12-22' does not match format '%Y%m%d'
2017-03-07 13:29:29 [guangdong] ERROR: save_time_error:time data '2014-12-19' does not match format '%Y%m%d'
2017-03-07 13:29:29 [guangdong] ERROR: save_time_error:time data '2014-12-25' does not match format '%Y%m%d'
2017-03-07 13:29:29 [guangdong] ERROR: save_time_error:time data '2014-12-19' does not match format '%Y%m%d'
2017-03-07 13:29:30 [guangdong] ERROR: save_time_error:time data '2014-12-25' does not match format '%Y%m%d'
2017-03-07 13:29:31 [guangdong] ERROR: save_time_error:time data '2014-12-25' does not match format '%Y%m%d'
2017-03-07 13:29:33 [guangdong] ERROR: save_time_error:time data '2014-12-25' does not match format '%Y%m%d'
2017-03-07 13:29:33 [guangdong] ERROR: save_time_error:time data '2014-12-30' does not match format '%Y%m%d'
2017-03-07 13:29:33 [guangdong] ERROR: save_time_error:time data '2014-12-25' does not match format '%Y%m%d'
2017-03-07 13:29:33 [guangdong] ERROR: save_time_error:time data '2014-12-29' does not match format '%Y%m%d'
2017-03-07 13:29:34 [guangdong] ERROR: save_time_error:time data '2014-12-25' does not match format '%Y%m%d'
2017-03-07 13:29:34 [guangdong] ERROR: save_time_error:time data '2014-12-26' does not match format '%Y%m%d'
2017-03-07 13:29:34 [guangdong] ERROR: save_time_error:time data '2014-12-30' does not match format '%Y%m%d'
2017-03-07 13:29:34 [guangdong] ERROR: save_time_error:time data '2014-12-30' does not match format '%Y%m%d'
2017-03-07 13:29:36 [guangdong] ERROR: save_time_error:time data '2014-12-30' does not match format '%Y%m%d'
2017-03-07 13:29:36 [guangdong] ERROR: save_time_error:time data '2014-12-31' does not match format '%Y%m%d'
2017-03-07 13:29:37 [guangdong] ERROR: save_time_error:time data '2015-01-03' does not match format '%Y%m%d'
2017-03-07 13:29:37 [guangdong] ERROR: save_time_error:time data '2015-01-04' does not match format '%Y%m%d'
2017-03-07 13:29:37 [guangdong] ERROR: save_time_error:time data '2014-12-31' does not match format '%Y%m%d'
2017-03-07 13:29:37 [guangdong] ERROR: save_time_error:time data '2015-01-04' does not match format '%Y%m%d'
2017-03-07 13:29:37 [guangdong] ERROR: save_time_error:time data '2015-01-04' does not match format '%Y%m%d'
2017-03-07 13:29:37 [guangdong] ERROR: save_time_error:time data '2015-01-05' does not match format '%Y%m%d'
2017-03-07 13:29:40 [guangdong] ERROR: save_time_error:time data '2015-01-06' does not match format '%Y%m%d'
2017-03-07 13:29:41 [guangdong] ERROR: save_time_error:time data '2015-01-07' does not match format '%Y%m%d'
2017-03-07 13:29:41 [guangdong] ERROR: save_time_error:time data '2015-01-07' does not match format '%Y%m%d'
2017-03-07 13:29:41 [guangdong] ERROR: save_time_error:time data '2015-01-06' does not match format '%Y%m%d'
2017-03-07 13:29:41 [guangdong] ERROR: save_time_error:time data '2015-01-07' does not match format '%Y%m%d'
2017-03-07 13:29:41 [guangdong] ERROR: save_time_error:time data '2015-01-07' does not match format '%Y%m%d'
2017-03-07 13:29:41 [guangdong] ERROR: save_time_error:time data '2015-01-08' does not match format '%Y%m%d'
2017-03-07 13:29:42 [guangdong] ERROR: save_time_error:time data '2015-01-08' does not match format '%Y%m%d'
2017-03-07 13:29:44 [guangdong] ERROR: save_time_error:time data '2015-01-09' does not match format '%Y%m%d'
2017-03-07 13:29:45 [guangdong] ERROR: save_time_error:time data '2015-01-12' does not match format '%Y%m%d'
2017-03-07 13:29:45 [guangdong] ERROR: save_time_error:time data '2015-01-12' does not match format '%Y%m%d'
2017-03-07 13:29:45 [guangdong] ERROR: save_time_error:time data '2015-01-09' does not match format '%Y%m%d'
2017-03-07 13:29:45 [guangdong] ERROR: save_time_error:time data '2015-01-09' does not match format '%Y%m%d'
2017-03-07 13:29:45 [scrapy.extensions.logstats] INFO: Crawled 230 pages (at 124 pages/min), scraped 226 items (at 121 items/min)
2017-03-07 13:29:46 [guangdong] ERROR: save_time_error:time data '2015-01-13' does not match format '%Y%m%d'
2017-03-07 13:29:46 [guangdong] ERROR: save_time_error:time data '2015-01-13' does not match format '%Y%m%d'
2017-03-07 13:29:46 [guangdong] ERROR: save_time_error:time data '2015-01-13' does not match format '%Y%m%d'
2017-03-07 13:29:47 [guangdong] ERROR: save_time_error:time data '2015-01-14' does not match format '%Y%m%d'
2017-03-07 13:29:48 [guangdong] ERROR: save_time_error:time data '2015-01-15' does not match format '%Y%m%d'
2017-03-07 13:29:48 [guangdong] ERROR: save_time_error:time data '2015-01-14' does not match format '%Y%m%d'
2017-03-07 13:29:48 [guangdong] ERROR: save_time_error:time data '2015-01-14' does not match format '%Y%m%d'
2017-03-07 13:29:49 [guangdong] ERROR: save_time_error:time data '2015-01-15' does not match format '%Y%m%d'
2017-03-07 13:29:49 [guangdong] ERROR: save_time_error:time data '2015-01-14' does not match format '%Y%m%d'
2017-03-07 13:29:49 [guangdong] ERROR: save_time_error:time data '2015-01-15' does not match format '%Y%m%d'
2017-03-07 13:29:49 [guangdong] ERROR: save_time_error:time data '2015-01-15' does not match format '%Y%m%d'
2017-03-07 13:29:50 [guangdong] ERROR: save_time_error:time data '2015-01-16' does not match format '%Y%m%d'
2017-03-07 13:29:51 [guangdong] ERROR: save_time_error:time data '2015-01-18' does not match format '%Y%m%d'
2017-03-07 13:29:51 [guangdong] ERROR: save_time_error:time data '2015-01-16' does not match format '%Y%m%d'
2017-03-07 13:29:51 [guangdong] ERROR: save_time_error:time data '2015-01-19' does not match format '%Y%m%d'
2017-03-07 13:29:52 [guangdong] ERROR: save_time_error:time data '2015-01-20' does not match format '%Y%m%d'
2017-03-07 13:29:52 [guangdong] ERROR: save_time_error:time data '2015-01-21' does not match format '%Y%m%d'
2017-03-07 13:29:52 [guangdong] ERROR: save_time_error:time data '2015-01-20' does not match format '%Y%m%d'
2017-03-07 13:29:52 [guangdong] ERROR: save_time_error:time data '2015-01-21' does not match format '%Y%m%d'
2017-03-07 13:29:53 [guangdong] ERROR: save_time_error:time data '2015-01-21' does not match format '%Y%m%d'
2017-03-07 13:29:56 [guangdong] ERROR: save_time_error:time data '2015-01-22' does not match format '%Y%m%d'
2017-03-07 13:29:56 [guangdong] ERROR: save_time_error:time data '2015-01-21' does not match format '%Y%m%d'
2017-03-07 13:29:56 [guangdong] ERROR: save_time_error:time data '2015-01-21' does not match format '%Y%m%d'
2017-03-07 13:29:56 [guangdong] ERROR: save_time_error:time data '2015-01-23' does not match format '%Y%m%d'
2017-03-07 13:29:56 [guangdong] ERROR: save_time_error:time data '2015-01-23' does not match format '%Y%m%d'
2017-03-07 13:29:56 [guangdong] ERROR: save_time_error:time data '2015-01-22' does not match format '%Y%m%d'
2017-03-07 13:29:56 [guangdong] ERROR: save_time_error:time data '2015-01-26' does not match format '%Y%m%d'
2017-03-07 13:29:57 [guangdong] ERROR: save_time_error:time data '2015-01-26' does not match format '%Y%m%d'
2017-03-07 13:29:59 [guangdong] ERROR: save_time_error:time data '2015-01-27' does not match format '%Y%m%d'
2017-03-07 13:29:59 [guangdong] ERROR: save_time_error:time data '2015-01-27' does not match format '%Y%m%d'
2017-03-07 13:29:59 [guangdong] ERROR: save_time_error:time data '2015-01-28' does not match format '%Y%m%d'
2017-03-07 13:29:59 [guangdong] ERROR: save_time_error:time data '2015-01-28' does not match format '%Y%m%d'
2017-03-07 13:29:59 [guangdong] ERROR: save_time_error:time data '2015-01-27' does not match format '%Y%m%d'
2017-03-07 13:29:59 [guangdong] ERROR: save_time_error:time data '2015-01-27' does not match format '%Y%m%d'
2017-03-07 13:29:59 [guangdong] ERROR: save_time_error:time data '2015-01-29' does not match format '%Y%m%d'
2017-03-07 13:30:00 [guangdong] ERROR: save_time_error:time data '2015-01-29' does not match format '%Y%m%d'
2017-03-07 13:30:02 [guangdong] ERROR: save_time_error:time data '2015-01-29' does not match format '%Y%m%d'
2017-03-07 13:30:02 [guangdong] ERROR: save_time_error:time data '2015-01-29' does not match format '%Y%m%d'
2017-03-07 13:30:02 [guangdong] ERROR: save_time_error:time data '2015-01-30' does not match format '%Y%m%d'
2017-03-07 13:30:02 [guangdong] ERROR: save_time_error:time data '2015-01-30' does not match format '%Y%m%d'
2017-03-07 13:30:02 [guangdong] ERROR: save_time_error:time data '2015-01-30' does not match format '%Y%m%d'
2017-03-07 13:30:03 [guangdong] ERROR: save_time_error:time data '2015-01-30' does not match format '%Y%m%d'
2017-03-07 13:30:04 [guangdong] ERROR: save_time_error:time data '2015-02-02' does not match format '%Y%m%d'
2017-03-07 13:30:05 [guangdong] ERROR: save_time_error:time data '2015-02-02' does not match format '%Y%m%d'
2017-03-07 13:30:07 [guangdong] ERROR: save_time_error:time data '2015-02-02' does not match format '%Y%m%d'
2017-03-07 13:30:07 [guangdong] ERROR: save_time_error:time data '2015-02-03' does not match format '%Y%m%d'
2017-03-07 13:30:07 [guangdong] ERROR: save_time_error:time data '2015-02-06' does not match format '%Y%m%d'
2017-03-07 13:30:07 [guangdong] ERROR: save_time_error:time data '2015-02-06' does not match format '%Y%m%d'
2017-03-07 13:30:07 [guangdong] ERROR: save_time_error:time data '2015-02-06' does not match format '%Y%m%d'
2017-03-07 13:30:07 [guangdong] ERROR: save_time_error:time data '2015-02-06' does not match format '%Y%m%d'
2017-03-07 13:30:08 [guangdong] ERROR: save_time_error:time data '2015-02-09' does not match format '%Y%m%d'
2017-03-07 13:30:08 [guangdong] ERROR: save_time_error:time data '2015-02-12' does not match format '%Y%m%d'
2017-03-07 13:30:10 [guangdong] ERROR: save_time_error:time data '2015-02-12' does not match format '%Y%m%d'
2017-03-07 13:30:10 [guangdong] ERROR: save_time_error:time data '2015-02-12' does not match format '%Y%m%d'
2017-03-07 13:30:10 [guangdong] ERROR: save_time_error:time data '2015-02-12' does not match format '%Y%m%d'
2017-03-07 13:30:10 [guangdong] ERROR: save_time_error:time data '2015-02-13' does not match format '%Y%m%d'
2017-03-07 13:30:10 [guangdong] ERROR: save_time_error:time data '2015-02-12' does not match format '%Y%m%d'
2017-03-07 13:30:10 [guangdong] ERROR: save_time_error:time data '2015-02-12' does not match format '%Y%m%d'
2017-03-07 13:30:11 [guangdong] ERROR: save_time_error:time data '2015-02-15' does not match format '%Y%m%d'
2017-03-07 13:30:11 [guangdong] ERROR: save_time_error:time data '2015-02-15' does not match format '%Y%m%d'
2017-03-07 13:30:13 [guangdong] ERROR: save_time_error:time data '2015-02-16' does not match format '%Y%m%d'
2017-03-07 13:30:13 [guangdong] ERROR: save_time_error:time data '2015-02-15' does not match format '%Y%m%d'
2017-03-07 13:30:13 [guangdong] ERROR: save_time_error:time data '2015-02-25' does not match format '%Y%m%d'
2017-03-07 13:30:13 [guangdong] ERROR: save_time_error:time data '2015-02-28' does not match format '%Y%m%d'
2017-03-07 13:30:13 [guangdong] ERROR: save_time_error:time data '2015-02-28' does not match format '%Y%m%d'
2017-03-07 13:30:13 [guangdong] ERROR: save_time_error:time data '2015-02-28' does not match format '%Y%m%d'
2017-03-07 13:30:14 [guangdong] ERROR: save_time_error:time data '2015-03-02' does not match format '%Y%m%d'
2017-03-07 13:30:14 [guangdong] ERROR: save_time_error:time data '2015-03-04' does not match format '%Y%m%d'
2017-03-07 13:30:16 [guangdong] ERROR: save_time_error:time data '2015-03-04' does not match format '%Y%m%d'
2017-03-07 13:30:16 [guangdong] ERROR: save_time_error:time data '2015-03-04' does not match format '%Y%m%d'
2017-03-07 13:30:17 [guangdong] ERROR: save_time_error:time data '2015-03-05' does not match format '%Y%m%d'
2017-03-07 13:30:17 [guangdong] ERROR: save_time_error:time data '2015-03-05' does not match format '%Y%m%d'
2017-03-07 13:30:17 [guangdong] ERROR: save_time_error:time data '2015-03-06' does not match format '%Y%m%d'
2017-03-07 13:30:17 [guangdong] ERROR: save_time_error:time data '2015-03-10' does not match format '%Y%m%d'
2017-03-07 13:30:17 [guangdong] ERROR: save_time_error:time data '2015-03-11' does not match format '%Y%m%d'
2017-03-07 13:30:24 [guangdong] ERROR: save_time_error:time data '2015-03-13' does not match format '%Y%m%d'
2017-03-07 13:30:24 [guangdong] ERROR: save_time_error:time data '2015-03-12' does not match format '%Y%m%d'
2017-03-07 13:30:24 [guangdong] ERROR: save_time_error:time data '2015-03-18' does not match format '%Y%m%d'
2017-03-07 13:30:24 [guangdong] ERROR: save_time_error:time data '2015-03-19' does not match format '%Y%m%d'
2017-03-07 13:30:24 [guangdong] ERROR: save_time_error:time data '2015-03-12' does not match format '%Y%m%d'
2017-03-07 13:30:24 [guangdong] ERROR: save_time_error:time data '2015-03-18' does not match format '%Y%m%d'
2017-03-07 13:30:24 [guangdong] ERROR: save_time_error:time data '2015-03-17' does not match format '%Y%m%d'
2017-03-07 13:30:47 [scrapy.extensions.logstats] INFO: Crawled 309 pages (at 79 pages/min), scraped 308 items (at 82 items/min)
2017-03-07 13:30:53 [guangdong] ERROR: save_time_error:time data '2015-05-21' does not match format '%Y%m%d'
2017-03-07 13:30:54 [guangdong] ERROR: save_time_error:time data '2015-06-01' does not match format '%Y%m%d'
2017-03-07 13:30:54 [guangdong] ERROR: save_time_error:time data '2015-06-02' does not match format '%Y%m%d'
2017-03-07 13:30:54 [guangdong] ERROR: save_time_error:time data '2015-06-09' does not match format '%Y%m%d'
2017-03-07 13:30:55 [guangdong] ERROR: save_time_error:time data '2015-06-09' does not match format '%Y%m%d'
2017-03-07 13:30:55 [guangdong] ERROR: save_time_error:time data '2015-06-09' does not match format '%Y%m%d'
2017-03-07 13:30:56 [guangdong] ERROR: save_time_error:time data '2015-06-09' does not match format '%Y%m%d'
2017-03-07 13:30:56 [guangdong] ERROR: save_time_error:time data '2015-06-09' does not match format '%Y%m%d'
2017-03-07 13:30:57 [guangdong] ERROR: save_time_error:time data '2015-06-09' does not match format '%Y%m%d'
2017-03-07 13:30:57 [guangdong] ERROR: save_time_error:time data '2015-06-10' does not match format '%Y%m%d'
2017-03-07 13:30:58 [guangdong] ERROR: save_time_error:time data '2015-06-10' does not match format '%Y%m%d'
2017-03-07 13:30:58 [guangdong] ERROR: save_time_error:time data '2015-06-16' does not match format '%Y%m%d'
2017-03-07 13:30:59 [guangdong] ERROR: save_time_error:time data '2015-06-19' does not match format '%Y%m%d'
2017-03-07 13:30:59 [guangdong] ERROR: save_time_error:time data '2015-06-19' does not match format '%Y%m%d'
2017-03-07 13:30:59 [guangdong] ERROR: save_time_error:time data '2015-06-19' does not match format '%Y%m%d'
2017-03-07 13:31:00 [guangdong] ERROR: save_time_error:time data '2015-06-24' does not match format '%Y%m%d'
2017-03-07 13:31:00 [guangdong] ERROR: save_time_error:time data '2015-06-26' does not match format '%Y%m%d'
2017-03-07 13:31:01 [guangdong] ERROR: save_time_error:time data '2015-06-29' does not match format '%Y%m%d'
2017-03-07 13:31:01 [guangdong] ERROR: save_time_error:time data '2015-06-29' does not match format '%Y%m%d'
2017-03-07 13:31:02 [guangdong] ERROR: save_time_error:time data '2015-07-01' does not match format '%Y%m%d'
2017-03-07 13:31:02 [guangdong] ERROR: save_time_error:time data '2015-07-01' does not match format '%Y%m%d'
2017-03-07 13:31:03 [guangdong] ERROR: save_time_error:time data '2015-07-02' does not match format '%Y%m%d'
2017-03-07 13:31:03 [guangdong] ERROR: save_time_error:time data '2015-07-02' does not match format '%Y%m%d'
2017-03-07 13:31:04 [guangdong] ERROR: save_time_error:time data '2015-07-02' does not match format '%Y%m%d'
2017-03-07 13:31:04 [guangdong] ERROR: save_time_error:time data '2015-07-03' does not match format '%Y%m%d'
2017-03-07 13:31:05 [guangdong] ERROR: save_time_error:time data '2015-07-03' does not match format '%Y%m%d'
2017-03-07 13:31:05 [guangdong] ERROR: save_time_error:time data '2015-07-04' does not match format '%Y%m%d'
2017-03-07 13:31:06 [guangdong] ERROR: save_time_error:time data '2015-07-06' does not match format '%Y%m%d'
2017-03-07 13:31:06 [guangdong] ERROR: save_time_error:time data '2015-07-06' does not match format '%Y%m%d'
2017-03-07 13:31:07 [guangdong] ERROR: save_time_error:time data '2015-07-08' does not match format '%Y%m%d'
2017-03-07 13:31:07 [guangdong] ERROR: save_time_error:time data '2015-07-09' does not match format '%Y%m%d'
2017-03-07 13:31:08 [guangdong] ERROR: save_time_error:time data '2015-07-09' does not match format '%Y%m%d'
2017-03-07 13:31:08 [guangdong] ERROR: save_time_error:time data '2015-07-10' does not match format '%Y%m%d'
2017-03-07 13:31:08 [guangdong] ERROR: save_time_error:time data '2015-07-13' does not match format '%Y%m%d'
2017-03-07 13:31:09 [guangdong] ERROR: save_time_error:time data '2015-07-13' does not match format '%Y%m%d'
2017-03-07 13:31:11 [guangdong] ERROR: save_time_error:time data '2015-07-13' does not match format '%Y%m%d'
2017-03-07 13:31:11 [guangdong] ERROR: save_time_error:time data '2015-07-13' does not match format '%Y%m%d'
2017-03-07 13:31:12 [guangdong] ERROR: save_time_error:time data '2015-07-14' does not match format '%Y%m%d'
2017-03-07 13:31:12 [guangdong] ERROR: save_time_error:time data '2015-07-14' does not match format '%Y%m%d'
2017-03-07 13:31:12 [guangdong] ERROR: save_time_error:time data '2015-07-14' does not match format '%Y%m%d'
2017-03-07 13:31:13 [guangdong] ERROR: save_time_error:time data '2015-07-14' does not match format '%Y%m%d'
2017-03-07 13:31:13 [guangdong] ERROR: save_time_error:time data '2015-07-15' does not match format '%Y%m%d'
2017-03-07 13:31:14 [guangdong] ERROR: save_time_error:time data '2015-07-17' does not match format '%Y%m%d'
2017-03-07 13:31:14 [guangdong] ERROR: save_time_error:time data '2015-07-17' does not match format '%Y%m%d'
2017-03-07 13:31:15 [guangdong] ERROR: save_time_error:time data '2015-07-19' does not match format '%Y%m%d'
2017-03-07 13:31:16 [guangdong] ERROR: save_time_error:time data '2015-07-22' does not match format '%Y%m%d'
2017-03-07 13:31:16 [guangdong] ERROR: save_time_error:time data '2015-07-23' does not match format '%Y%m%d'
2017-03-07 13:31:16 [guangdong] ERROR: save_time_error:time data '2015-07-28' does not match format '%Y%m%d'
2017-03-07 13:31:17 [guangdong] ERROR: save_time_error:time data '2015-07-28' does not match format '%Y%m%d'
2017-03-07 13:31:17 [guangdong] ERROR: save_time_error:time data '2015-07-28' does not match format '%Y%m%d'
2017-03-07 13:31:18 [guangdong] ERROR: save_time_error:time data '2015-07-30' does not match format '%Y%m%d'
2017-03-07 13:31:18 [guangdong] ERROR: save_time_error:time data '2015-07-30' does not match format '%Y%m%d'
2017-03-07 13:31:19 [guangdong] ERROR: save_time_error:time data '2015-07-31' does not match format '%Y%m%d'
2017-03-07 13:31:19 [guangdong] ERROR: save_time_error:time data '2015-07-31' does not match format '%Y%m%d'
2017-03-07 13:31:19 [guangdong] ERROR: save_time_error:time data '2015-07-31' does not match format '%Y%m%d'
2017-03-07 13:31:20 [guangdong] ERROR: save_time_error:time data '2015-07-31' does not match format '%Y%m%d'
2017-03-07 13:31:20 [guangdong] ERROR: save_time_error:time data '2015-08-03' does not match format '%Y%m%d'
2017-03-07 13:31:21 [guangdong] ERROR: save_time_error:time data '2015-08-03' does not match format '%Y%m%d'
2017-03-07 13:31:23 [guangdong] ERROR: save_time_error:time data '2015-08-03' does not match format '%Y%m%d'
2017-03-07 13:31:23 [guangdong] ERROR: save_time_error:time data '2015-08-03' does not match format '%Y%m%d'
2017-03-07 13:31:24 [guangdong] ERROR: save_time_error:time data '2015-08-04' does not match format '%Y%m%d'
2017-03-07 13:31:24 [guangdong] ERROR: save_time_error:time data '2015-08-05' does not match format '%Y%m%d'
2017-03-07 13:31:25 [guangdong] ERROR: save_time_error:time data '2015-08-05' does not match format '%Y%m%d'
2017-03-07 13:31:25 [guangdong] ERROR: save_time_error:time data '2015-08-05' does not match format '%Y%m%d'
2017-03-07 13:31:26 [guangdong] ERROR: save_time_error:time data '2015-08-10' does not match format '%Y%m%d'
2017-03-07 13:31:26 [guangdong] ERROR: save_time_error:time data '2015-08-12' does not match format '%Y%m%d'
2017-03-07 13:31:27 [guangdong] ERROR: save_time_error:time data '2015-08-12' does not match format '%Y%m%d'
2017-03-07 13:31:27 [guangdong] ERROR: save_time_error:time data '2015-08-12' does not match format '%Y%m%d'
2017-03-07 13:31:27 [guangdong] ERROR: save_time_error:time data '2015-08-12' does not match format '%Y%m%d'
2017-03-07 13:31:28 [guangdong] ERROR: save_time_error:time data '2015-08-13' does not match format '%Y%m%d'
2017-03-07 13:31:28 [guangdong] ERROR: save_time_error:time data '2015-08-13' does not match format '%Y%m%d'
2017-03-07 13:31:29 [guangdong] ERROR: save_time_error:time data '2015-08-14' does not match format '%Y%m%d'
2017-03-07 13:31:29 [guangdong] ERROR: save_time_error:time data '2015-08-14' does not match format '%Y%m%d'
2017-03-07 13:31:30 [guangdong] ERROR: save_time_error:time data '2015-08-14' does not match format '%Y%m%d'
2017-03-07 13:31:31 [guangdong] ERROR: save_time_error:time data '2015-08-16' does not match format '%Y%m%d'
2017-03-07 13:31:31 [guangdong] ERROR: save_time_error:time data '2015-08-17' does not match format '%Y%m%d'
2017-03-07 13:31:32 [guangdong] ERROR: save_time_error:time data '2015-08-17' does not match format '%Y%m%d'
2017-03-07 13:31:32 [guangdong] ERROR: save_time_error:time data '2015-08-17' does not match format '%Y%m%d'
2017-03-07 13:31:32 [guangdong] ERROR: save_time_error:time data '2015-08-17' does not match format '%Y%m%d'
2017-03-07 13:31:33 [guangdong] ERROR: save_time_error:time data '2015-08-18' does not match format '%Y%m%d'
2017-03-07 13:31:33 [guangdong] ERROR: save_time_error:time data '2015-08-18' does not match format '%Y%m%d'
2017-03-07 13:31:34 [guangdong] ERROR: save_time_error:time data '2015-08-18' does not match format '%Y%m%d'
2017-03-07 13:31:35 [guangdong] ERROR: save_time_error:time data '2015-08-19' does not match format '%Y%m%d'
2017-03-07 13:31:35 [guangdong] ERROR: save_time_error:time data '2015-08-21' does not match format '%Y%m%d'
2017-03-07 13:31:36 [guangdong] ERROR: save_time_error:time data '2015-08-21' does not match format '%Y%m%d'
2017-03-07 13:31:36 [guangdong] ERROR: save_time_error:time data '2015-08-24' does not match format '%Y%m%d'
2017-03-07 13:31:37 [guangdong] ERROR: save_time_error:time data '2015-08-24' does not match format '%Y%m%d'
2017-03-07 13:31:37 [guangdong] ERROR: save_time_error:time data '2015-08-25' does not match format '%Y%m%d'
2017-03-07 13:31:38 [guangdong] ERROR: save_time_error:time data '2015-08-26' does not match format '%Y%m%d'
2017-03-07 13:31:39 [guangdong] ERROR: save_time_error:time data '2015-08-27' does not match format '%Y%m%d'
2017-03-07 13:31:39 [guangdong] ERROR: save_time_error:time data '2015-08-31' does not match format '%Y%m%d'
2017-03-07 13:31:40 [guangdong] ERROR: save_time_error:time data '2015-08-31' does not match format '%Y%m%d'
2017-03-07 13:31:40 [guangdong] ERROR: save_time_error:time data '2015-08-31' does not match format '%Y%m%d'
2017-03-07 13:31:41 [guangdong] ERROR: save_time_error:time data '2015-09-01' does not match format '%Y%m%d'
2017-03-07 13:31:41 [guangdong] ERROR: save_time_error:time data '2015-09-01' does not match format '%Y%m%d'
2017-03-07 13:31:42 [guangdong] ERROR: save_time_error:time data '2015-09-01' does not match format '%Y%m%d'
2017-03-07 13:31:42 [guangdong] ERROR: save_time_error:time data '2015-09-02' does not match format '%Y%m%d'
2017-03-07 13:31:43 [guangdong] ERROR: save_time_error:time data '2015-09-02' does not match format '%Y%m%d'
2017-03-07 13:31:43 [guangdong] ERROR: save_time_error:time data '2015-09-06' does not match format '%Y%m%d'
2017-03-07 13:31:43 [guangdong] ERROR: save_time_error:time data '2015-09-07' does not match format '%Y%m%d'
2017-03-07 13:31:44 [guangdong] ERROR: save_time_error:time data '2015-09-07' does not match format '%Y%m%d'
2017-03-07 13:31:44 [scrapy.extensions.logstats] INFO: Crawled 411 pages (at 102 pages/min), scraped 409 items (at 101 items/min)
2017-03-07 13:31:44 [guangdong] ERROR: save_time_error:time data '2015-09-09' does not match format '%Y%m%d'
2017-03-07 13:31:45 [guangdong] ERROR: save_time_error:time data '2015-09-09' does not match format '%Y%m%d'
2017-03-07 13:31:46 [guangdong] ERROR: save_time_error:time data '2015-09-10' does not match format '%Y%m%d'
2017-03-07 13:31:46 [guangdong] ERROR: save_time_error:time data '2015-09-11' does not match format '%Y%m%d'
2017-03-07 13:31:47 [guangdong] ERROR: save_time_error:time data '2015-09-11' does not match format '%Y%m%d'
2017-03-07 13:31:47 [guangdong] ERROR: save_time_error:time data '2015-09-11' does not match format '%Y%m%d'
2017-03-07 13:31:48 [guangdong] ERROR: save_time_error:time data '2015-09-11' does not match format '%Y%m%d'
2017-03-07 13:31:49 [guangdong] ERROR: save_time_error:time data '2015-09-14' does not match format '%Y%m%d'
2017-03-07 13:31:49 [guangdong] ERROR: save_time_error:time data '2015-09-14' does not match format '%Y%m%d'
2017-03-07 13:31:50 [guangdong] ERROR: save_time_error:time data '2015-09-15' does not match format '%Y%m%d'
2017-03-07 13:31:51 [guangdong] ERROR: save_time_error:time data '2015-09-15' does not match format '%Y%m%d'
2017-03-07 13:31:51 [guangdong] ERROR: save_time_error:time data '2015-09-15' does not match format '%Y%m%d'
2017-03-07 13:31:51 [guangdong] ERROR: save_time_error:time data '2015-09-16' does not match format '%Y%m%d'
2017-03-07 13:31:51 [guangdong] ERROR: save_time_error:time data '2015-09-16' does not match format '%Y%m%d'
2017-03-07 13:31:52 [guangdong] ERROR: save_time_error:time data '2015-09-17' does not match format '%Y%m%d'
2017-03-07 13:31:52 [guangdong] ERROR: save_time_error:time data '2015-09-16' does not match format '%Y%m%d'
2017-03-07 13:31:53 [guangdong] ERROR: save_time_error:time data '2015-09-21' does not match format '%Y%m%d'
2017-03-07 13:31:53 [guangdong] ERROR: save_time_error:time data '2015-09-21' does not match format '%Y%m%d'
2017-03-07 13:31:54 [guangdong] ERROR: save_time_error:time data '2015-09-22' does not match format '%Y%m%d'
2017-03-07 13:31:54 [guangdong] ERROR: save_time_error:time data '2015-09-21' does not match format '%Y%m%d'
2017-03-07 13:31:55 [guangdong] ERROR: save_time_error:time data '2015-09-24' does not match format '%Y%m%d'
2017-03-07 13:31:55 [guangdong] ERROR: save_time_error:time data '2015-09-24' does not match format '%Y%m%d'
2017-03-07 13:31:56 [guangdong] ERROR: save_time_error:time data '2015-09-24' does not match format '%Y%m%d'
2017-03-07 13:31:56 [guangdong] ERROR: save_time_error:time data '2015-09-24' does not match format '%Y%m%d'
2017-03-07 13:31:57 [guangdong] ERROR: save_time_error:time data '2015-09-25' does not match format '%Y%m%d'
2017-03-07 13:31:57 [guangdong] ERROR: save_time_error:time data '2015-09-28' does not match format '%Y%m%d'
2017-03-07 13:31:57 [guangdong] ERROR: save_time_error:time data '2015-09-29' does not match format '%Y%m%d'
2017-03-07 13:31:57 [guangdong] ERROR: save_time_error:time data '2015-09-29' does not match format '%Y%m%d'
2017-03-07 13:31:58 [guangdong] ERROR: save_time_error:time data '2015-09-29' does not match format '%Y%m%d'
2017-03-07 13:31:58 [guangdong] ERROR: save_time_error:time data '2015-09-29' does not match format '%Y%m%d'
2017-03-07 13:31:59 [guangdong] ERROR: save_time_error:time data '2015-09-30' does not match format '%Y%m%d'
2017-03-07 13:31:59 [guangdong] ERROR: save_time_error:time data '2015-09-30' does not match format '%Y%m%d'
2017-03-07 13:32:00 [guangdong] ERROR: save_time_error:time data '2015-10-09' does not match format '%Y%m%d'
2017-03-07 13:32:00 [guangdong] ERROR: save_time_error:time data '2015-09-30' does not match format '%Y%m%d'
2017-03-07 13:32:01 [guangdong] ERROR: save_time_error:time data '2015-10-09' does not match format '%Y%m%d'
2017-03-07 13:32:01 [guangdong] ERROR: save_time_error:time data '2015-10-09' does not match format '%Y%m%d'
2017-03-07 13:32:01 [guangdong] ERROR: save_time_error:time data '2015-10-10' does not match format '%Y%m%d'
2017-03-07 13:32:01 [guangdong] ERROR: save_time_error:time data '2015-10-10' does not match format '%Y%m%d'
2017-03-07 13:32:02 [guangdong] ERROR: save_time_error:time data '2015-10-12' does not match format '%Y%m%d'
2017-03-07 13:32:02 [guangdong] ERROR: save_time_error:time data '2015-10-12' does not match format '%Y%m%d'
2017-03-07 13:32:03 [guangdong] ERROR: save_time_error:time data '2015-10-12' does not match format '%Y%m%d'
2017-03-07 13:32:03 [guangdong] ERROR: save_time_error:time data '2015-10-12' does not match format '%Y%m%d'
2017-03-07 13:32:04 [guangdong] ERROR: save_time_error:time data '2015-10-13' does not match format '%Y%m%d'
2017-03-07 13:32:04 [guangdong] ERROR: save_time_error:time data '2015-10-13' does not match format '%Y%m%d'
2017-03-07 13:32:05 [guangdong] ERROR: save_time_error:time data '2015-10-13' does not match format '%Y%m%d'
2017-03-07 13:32:05 [guangdong] ERROR: save_time_error:time data '2015-10-13' does not match format '%Y%m%d'
2017-03-07 13:32:06 [guangdong] ERROR: save_time_error:time data '2015-10-13' does not match format '%Y%m%d'
2017-03-07 13:32:06 [guangdong] ERROR: save_time_error:time data '2015-10-14' does not match format '%Y%m%d'
2017-03-07 13:32:06 [guangdong] ERROR: save_time_error:time data '2015-10-14' does not match format '%Y%m%d'
2017-03-07 13:32:06 [guangdong] ERROR: save_time_error:time data '2015-10-15' does not match format '%Y%m%d'
2017-03-07 13:32:07 [guangdong] ERROR: save_time_error:time data '2015-10-15' does not match format '%Y%m%d'
2017-03-07 13:32:07 [guangdong] ERROR: save_time_error:time data '2015-10-16' does not match format '%Y%m%d'
2017-03-07 13:32:08 [guangdong] ERROR: save_time_error:time data '2015-10-16' does not match format '%Y%m%d'
2017-03-07 13:32:08 [guangdong] ERROR: save_time_error:time data '2015-10-16' does not match format '%Y%m%d'
2017-03-07 13:32:09 [guangdong] ERROR: save_time_error:time data '2015-10-21' does not match format '%Y%m%d'
2017-03-07 13:32:09 [guangdong] ERROR: save_time_error:time data '2015-10-16' does not match format '%Y%m%d'
2017-03-07 13:32:10 [guangdong] ERROR: save_time_error:time data '2015-10-21' does not match format '%Y%m%d'
2017-03-07 13:32:10 [guangdong] ERROR: save_time_error:time data '2015-10-23' does not match format '%Y%m%d'
2017-03-07 13:32:11 [guangdong] ERROR: save_time_error:time data '2015-10-27' does not match format '%Y%m%d'
2017-03-07 13:32:11 [guangdong] ERROR: save_time_error:time data '2015-10-27' does not match format '%Y%m%d'
2017-03-07 13:32:11 [guangdong] ERROR: save_time_error:time data '2015-10-28' does not match format '%Y%m%d'
2017-03-07 13:32:12 [guangdong] ERROR: save_time_error:time data '2015-10-28' does not match format '%Y%m%d'
2017-03-07 13:32:13 [guangdong] ERROR: save_time_error:time data '2015-10-30' does not match format '%Y%m%d'
2017-03-07 13:32:13 [guangdong] ERROR: save_time_error:time data '2015-10-30' does not match format '%Y%m%d'
2017-03-07 13:32:14 [guangdong] ERROR: save_time_error:time data '2015-10-30' does not match format '%Y%m%d'
2017-03-07 13:32:14 [guangdong] ERROR: save_time_error:time data '2015-10-30' does not match format '%Y%m%d'
2017-03-07 13:32:15 [guangdong] ERROR: save_time_error:time data '2015-10-30' does not match format '%Y%m%d'
2017-03-07 13:32:15 [guangdong] ERROR: save_time_error:time data '2015-10-30' does not match format '%Y%m%d'
2017-03-07 13:32:16 [guangdong] ERROR: save_time_error:time data '2015-11-02' does not match format '%Y%m%d'
2017-03-07 13:32:16 [guangdong] ERROR: save_time_error:time data '2015-11-03' does not match format '%Y%m%d'
2017-03-07 13:32:17 [guangdong] ERROR: save_time_error:time data '2015-11-04' does not match format '%Y%m%d'
2017-03-07 13:32:17 [guangdong] ERROR: save_time_error:time data '2015-11-03' does not match format '%Y%m%d'
2017-03-07 13:32:25 [guangdong] ERROR: save_time_error:time data '2015-11-05' does not match format '%Y%m%d'
2017-03-07 13:32:26 [guangdong] ERROR: save_time_error:time data '2015-11-05' does not match format '%Y%m%d'
2017-03-07 13:32:46 [scrapy.extensions.logstats] INFO: Crawled 484 pages (at 73 pages/min), scraped 483 items (at 74 items/min)
2017-03-07 13:33:44 [scrapy.extensions.logstats] INFO: Crawled 484 pages (at 0 pages/min), scraped 483 items (at 0 items/min)
2017-03-07 13:33:54 [guangdong] ERROR: save_time_error:time data '2015-12-18' does not match format '%Y%m%d'
2017-03-07 13:33:54 [guangdong] ERROR: save_time_error:time data '2015-12-17' does not match format '%Y%m%d'
2017-03-07 13:33:54 [guangdong] ERROR: save_time_error:time data '2015-12-18' does not match format '%Y%m%d'
2017-03-07 13:33:54 [guangdong] ERROR: save_time_error:time data '2015-12-16' does not match format '%Y%m%d'
2017-03-07 13:33:54 [guangdong] ERROR: save_time_error:time data '2015-12-17' does not match format '%Y%m%d'
2017-03-07 13:33:54 [guangdong] ERROR: save_time_error:time data '2015-12-15' does not match format '%Y%m%d'
2017-03-07 13:33:58 [guangdong] ERROR: save_time_error:time data '2015-12-21' does not match format '%Y%m%d'
2017-03-07 13:33:58 [guangdong] ERROR: save_time_error:time data '2015-12-24' does not match format '%Y%m%d'
2017-03-07 13:33:58 [guangdong] ERROR: save_time_error:time data '2015-12-24' does not match format '%Y%m%d'
2017-03-07 13:33:58 [guangdong] ERROR: save_time_error:time data '2015-12-21' does not match format '%Y%m%d'
2017-03-07 13:33:58 [guangdong] ERROR: save_time_error:time data '2015-12-21' does not match format '%Y%m%d'
2017-03-07 13:33:58 [guangdong] ERROR: save_time_error:time data '2015-12-22' does not match format '%Y%m%d'
2017-03-07 13:34:01 [guangdong] ERROR: save_time_error:time data '2015-12-25' does not match format '%Y%m%d'
2017-03-07 13:34:02 [guangdong] ERROR: save_time_error:time data '2015-12-25' does not match format '%Y%m%d'
2017-03-07 13:34:02 [guangdong] ERROR: save_time_error:time data '2015-12-28' does not match format '%Y%m%d'
2017-03-07 13:34:02 [guangdong] ERROR: save_time_error:time data '2015-12-25' does not match format '%Y%m%d'
2017-03-07 13:34:02 [guangdong] ERROR: save_time_error:time data '2015-12-29' does not match format '%Y%m%d'
2017-03-07 13:34:02 [guangdong] ERROR: save_time_error:time data '2015-12-25' does not match format '%Y%m%d'
2017-03-07 13:34:02 [guangdong] ERROR: save_time_error:time data '2015-12-30' does not match format '%Y%m%d'
2017-03-07 13:34:04 [guangdong] ERROR: save_time_error:time data '2015-12-30' does not match format '%Y%m%d'
2017-03-07 13:34:05 [guangdong] ERROR: save_time_error:time data '2015-12-31' does not match format '%Y%m%d'
2017-03-07 13:34:05 [guangdong] ERROR: save_time_error:time data '2015-12-31' does not match format '%Y%m%d'
2017-03-07 13:34:05 [guangdong] ERROR: save_time_error:time data '2015-12-31' does not match format '%Y%m%d'
2017-03-07 13:34:05 [guangdong] ERROR: save_time_error:time data '2015-12-31' does not match format '%Y%m%d'
2017-03-07 13:34:05 [guangdong] ERROR: save_time_error:time data '2015-12-31' does not match format '%Y%m%d'
2017-03-07 13:34:05 [guangdong] ERROR: save_time_error:time data '2016-01-04' does not match format '%Y%m%d'
2017-03-07 13:34:05 [guangdong] ERROR: save_time_error:time data '2016-01-04' does not match format '%Y%m%d'
2017-03-07 13:34:10 [guangdong] ERROR: save_time_error:time data '2016-01-08' does not match format '%Y%m%d'
2017-03-07 13:34:11 [guangdong] ERROR: save_time_error:time data '2016-01-07' does not match format '%Y%m%d'
2017-03-07 13:34:11 [guangdong] ERROR: save_time_error:time data '2016-01-05' does not match format '%Y%m%d'
2017-03-07 13:34:11 [guangdong] ERROR: save_time_error:time data '2016-01-04' does not match format '%Y%m%d'
2017-03-07 13:34:11 [guangdong] ERROR: save_time_error:time data '2016-01-08' does not match format '%Y%m%d'
2017-03-07 13:34:11 [guangdong] ERROR: save_time_error:time data '2016-01-04' does not match format '%Y%m%d'
2017-03-07 13:34:12 [guangdong] ERROR: save_time_error:time data '2016-01-11' does not match format '%Y%m%d'
2017-03-07 13:34:13 [guangdong] ERROR: save_time_error:time data '2016-01-12' does not match format '%Y%m%d'
2017-03-07 13:34:14 [guangdong] ERROR: save_time_error:time data '2016-01-20' does not match format '%Y%m%d'
2017-03-07 13:34:14 [guangdong] ERROR: save_time_error:time data '2016-01-14' does not match format '%Y%m%d'
2017-03-07 13:34:14 [guangdong] ERROR: save_time_error:time data '2016-01-14' does not match format '%Y%m%d'
2017-03-07 13:34:14 [guangdong] ERROR: save_time_error:time data '2016-01-21' does not match format '%Y%m%d'
2017-03-07 13:34:14 [guangdong] ERROR: save_time_error:time data '2016-01-14' does not match format '%Y%m%d'
2017-03-07 13:34:14 [guangdong] ERROR: save_time_error:time data '2016-01-22' does not match format '%Y%m%d'
2017-03-07 13:34:16 [guangdong] ERROR: save_time_error:time data '2016-01-25' does not match format '%Y%m%d'
2017-03-07 13:34:17 [guangdong] ERROR: save_time_error:time data '2016-01-26' does not match format '%Y%m%d'
2017-03-07 13:34:17 [guangdong] ERROR: save_time_error:time data '2016-01-25' does not match format '%Y%m%d'
2017-03-07 13:34:17 [guangdong] ERROR: save_time_error:time data '2016-01-25' does not match format '%Y%m%d'
2017-03-07 13:34:17 [guangdong] ERROR: save_time_error:time data '2016-01-26' does not match format '%Y%m%d'
2017-03-07 13:34:18 [guangdong] ERROR: save_time_error:time data '2016-01-22' does not match format '%Y%m%d'
2017-03-07 13:34:20 [guangdong] ERROR: save_time_error:time data '2016-01-26' does not match format '%Y%m%d'
2017-03-07 13:34:23 [guangdong] ERROR: save_time_error:time data '2016-01-26' does not match format '%Y%m%d'
2017-03-07 13:34:25 [guangdong] ERROR: save_time_error:time data '2016-01-27' does not match format '%Y%m%d'
2017-03-07 13:34:25 [guangdong] ERROR: save_time_error:time data '2016-01-26' does not match format '%Y%m%d'
2017-03-07 13:34:25 [guangdong] ERROR: save_time_error:time data '2016-01-26' does not match format '%Y%m%d'
2017-03-07 13:34:25 [guangdong] ERROR: save_time_error:time data '2016-01-26' does not match format '%Y%m%d'
2017-03-07 13:34:48 [scrapy.extensions.logstats] INFO: Crawled 537 pages (at 53 pages/min), scraped 536 items (at 53 items/min)
2017-03-07 13:35:44 [scrapy.extensions.logstats] INFO: Crawled 537 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2017-03-07 13:35:58 [guangdong] ERROR: save_time_error:time data '2016-05-19' does not match format '%Y%m%d'
2017-03-07 13:35:59 [guangdong] ERROR: save_time_error:time data '2016-05-20' does not match format '%Y%m%d'
2017-03-07 13:36:01 [guangdong] ERROR: save_time_error:time data '2016-05-23' does not match format '%Y%m%d'
2017-03-07 13:36:01 [guangdong] ERROR: save_time_error:time data '2016-05-30' does not match format '%Y%m%d'
2017-03-07 13:36:02 [guangdong] ERROR: save_time_error:time data '2016-06-01' does not match format '%Y%m%d'
2017-03-07 13:36:04 [guangdong] ERROR: save_time_error:time data '2016-06-01' does not match format '%Y%m%d'
2017-03-07 13:36:04 [guangdong] ERROR: save_time_error:time data '2016-06-01' does not match format '%Y%m%d'
2017-03-07 13:36:06 [guangdong] ERROR: save_time_error:time data '2016-06-06' does not match format '%Y%m%d'
2017-03-07 13:36:06 [guangdong] ERROR: save_time_error:time data '2016-06-06' does not match format '%Y%m%d'
2017-03-07 13:36:09 [guangdong] ERROR: save_time_error:time data '2016-06-07' does not match format '%Y%m%d'
2017-03-07 13:36:09 [guangdong] ERROR: save_time_error:time data '2016-06-12' does not match format '%Y%m%d'
2017-03-07 13:36:10 [guangdong] ERROR: save_time_error:time data '2016-06-12' does not match format '%Y%m%d'
2017-03-07 13:36:11 [guangdong] ERROR: save_time_error:time data '2016-06-14' does not match format '%Y%m%d'
2017-03-07 13:36:13 [guangdong] ERROR: save_time_error:time data '2016-06-20' does not match format '%Y%m%d'
2017-03-07 13:36:13 [guangdong] ERROR: save_time_error:time data '2016-06-21' does not match format '%Y%m%d'
2017-03-07 13:36:15 [guangdong] ERROR: save_time_error:time data '2016-06-22' does not match format '%Y%m%d'
2017-03-07 13:36:15 [guangdong] ERROR: save_time_error:time data '2016-06-23' does not match format '%Y%m%d'
2017-03-07 13:36:16 [guangdong] ERROR: save_time_error:time data '2016-07-01' does not match format '%Y%m%d'
2017-03-07 13:36:16 [guangdong] ERROR: save_time_error:time data '2016-07-01' does not match format '%Y%m%d'
2017-03-07 13:36:21 [guangdong] ERROR: save_time_error:time data '2016-07-01' does not match format '%Y%m%d'
2017-03-07 13:36:21 [guangdong] ERROR: save_time_error:time data '2016-07-01' does not match format '%Y%m%d'
2017-03-07 13:36:22 [guangdong] ERROR: save_time_error:time data '2016-07-05' does not match format '%Y%m%d'
2017-03-07 13:36:23 [guangdong] ERROR: save_time_error:time data '2016-07-01' does not match format '%Y%m%d'
2017-03-07 13:36:46 [scrapy.extensions.logstats] INFO: Crawled 560 pages (at 23 pages/min), scraped 559 items (at 23 items/min)
2017-03-07 13:37:44 [scrapy.extensions.logstats] INFO: Crawled 560 pages (at 0 pages/min), scraped 559 items (at 0 items/min)
2017-03-07 13:37:50 [guangdong] ERROR: save_time_error:time data '2016-08-10' does not match format '%Y%m%d'
2017-03-07 13:37:50 [guangdong] ERROR: save_time_error:time data '2016-08-10' does not match format '%Y%m%d'
2017-03-07 13:37:51 [guangdong] ERROR: save_time_error:time data '2016-08-10' does not match format '%Y%m%d'
2017-03-07 13:37:51 [guangdong] ERROR: save_time_error:time data '2016-08-22' does not match format '%Y%m%d'
2017-03-07 13:37:51 [guangdong] ERROR: save_time_error:time data '2016-08-23' does not match format '%Y%m%d'
2017-03-07 13:37:52 [guangdong] ERROR: save_time_error:time data '2016-08-23' does not match format '%Y%m%d'
2017-03-07 13:37:53 [guangdong] ERROR: save_time_error:time data '2016-08-24' does not match format '%Y%m%d'
2017-03-07 13:37:53 [guangdong] ERROR: save_time_error:time data '2016-08-24' does not match format '%Y%m%d'
2017-03-07 13:37:57 [guangdong] ERROR: save_time_error:time data '2016-08-24' does not match format '%Y%m%d'
2017-03-07 13:37:59 [guangdong] ERROR: save_time_error:time data '2016-08-30' does not match format '%Y%m%d'
2017-03-07 13:37:59 [guangdong] ERROR: save_time_error:time data '2016-08-30' does not match format '%Y%m%d'
2017-03-07 13:37:59 [guangdong] ERROR: save_time_error:time data '2016-08-30' does not match format '%Y%m%d'
2017-03-07 13:38:01 [guangdong] ERROR: save_time_error:time data '2016-08-31' does not match format '%Y%m%d'
2017-03-07 13:38:01 [guangdong] ERROR: save_time_error:time data '2016-09-02' does not match format '%Y%m%d'
2017-03-07 13:38:01 [guangdong] ERROR: save_time_error:time data '2016-09-01' does not match format '%Y%m%d'
2017-03-07 13:38:01 [guangdong] ERROR: save_time_error:time data '2016-09-02' does not match format '%Y%m%d'
2017-03-07 13:38:01 [guangdong] ERROR: save_time_error:time data '2016-09-01' does not match format '%Y%m%d'
2017-03-07 13:38:01 [guangdong] ERROR: save_time_error:time data '2016-08-31' does not match format '%Y%m%d'
2017-03-07 13:38:04 [guangdong] ERROR: save_time_error:time data '2016-09-02' does not match format '%Y%m%d'
2017-03-07 13:38:04 [guangdong] ERROR: save_time_error:time data '2016-09-02' does not match format '%Y%m%d'
2017-03-07 13:38:05 [guangdong] ERROR: save_time_error:time data '2016-09-05' does not match format '%Y%m%d'
2017-03-07 13:38:05 [guangdong] ERROR: save_time_error:time data '2016-09-05' does not match format '%Y%m%d'
2017-03-07 13:38:05 [guangdong] ERROR: save_time_error:time data '2016-09-02' does not match format '%Y%m%d'
2017-03-07 13:38:05 [guangdong] ERROR: save_time_error:time data '2016-09-05' does not match format '%Y%m%d'
2017-03-07 13:38:07 [guangdong] ERROR: save_time_error:time data '2016-09-05' does not match format '%Y%m%d'
2017-03-07 13:38:08 [guangdong] ERROR: save_time_error:time data '2016-09-05' does not match format '%Y%m%d'
2017-03-07 13:38:08 [guangdong] ERROR: save_time_error:time data '2016-09-05' does not match format '%Y%m%d'
2017-03-07 13:38:08 [guangdong] ERROR: save_time_error:time data '2016-09-05' does not match format '%Y%m%d'
2017-03-07 13:38:08 [guangdong] ERROR: save_time_error:time data '2016-09-07' does not match format '%Y%m%d'
2017-03-07 13:38:08 [guangdong] ERROR: save_time_error:time data '2016-09-09' does not match format '%Y%m%d'
2017-03-07 13:38:10 [guangdong] ERROR: save_time_error:time data '2016-09-09' does not match format '%Y%m%d'
2017-03-07 13:38:10 [guangdong] ERROR: save_time_error:time data '2016-09-13' does not match format '%Y%m%d'
2017-03-07 13:38:10 [guangdong] ERROR: save_time_error:time data '2016-09-18' does not match format '%Y%m%d'
2017-03-07 13:38:10 [guangdong] ERROR: save_time_error:time data '2016-09-22' does not match format '%Y%m%d'
2017-03-07 13:38:10 [guangdong] ERROR: save_time_error:time data '2016-09-23' does not match format '%Y%m%d'
2017-03-07 13:38:10 [guangdong] ERROR: save_time_error:time data '2016-09-23' does not match format '%Y%m%d'
2017-03-07 13:38:13 [guangdong] ERROR: save_time_error:time data '2016-09-23' does not match format '%Y%m%d'
2017-03-07 13:38:13 [guangdong] ERROR: save_time_error:time data '2016-09-23' does not match format '%Y%m%d'
2017-03-07 13:38:13 [guangdong] ERROR: save_time_error:time data '2016-09-27' does not match format '%Y%m%d'
2017-03-07 13:38:13 [guangdong] ERROR: save_time_error:time data '2016-09-27' does not match format '%Y%m%d'
2017-03-07 13:38:13 [guangdong] ERROR: save_time_error:time data '2016-09-30' does not match format '%Y%m%d'
2017-03-07 13:38:13 [guangdong] ERROR: save_time_error:time data '2016-09-27' does not match format '%Y%m%d'
2017-03-07 13:38:15 [guangdong] ERROR: save_time_error:time data '2016-10-08' does not match format '%Y%m%d'
2017-03-07 13:38:16 [guangdong] ERROR: save_time_error:time data '2016-10-10' does not match format '%Y%m%d'
2017-03-07 13:38:16 [guangdong] ERROR: save_time_error:time data '2016-10-09' does not match format '%Y%m%d'
2017-03-07 13:38:16 [guangdong] ERROR: save_time_error:time data '2016-10-13' does not match format '%Y%m%d'
2017-03-07 13:38:16 [guangdong] ERROR: save_time_error:time data '2016-10-13' does not match format '%Y%m%d'
2017-03-07 13:38:16 [guangdong] ERROR: save_time_error:time data '2016-10-10' does not match format '%Y%m%d'
2017-03-07 13:38:23 [guangdong] ERROR: save_time_error:time data '2016-10-20' does not match format '%Y%m%d'
2017-03-07 13:38:24 [guangdong] ERROR: save_time_error:time data '2016-10-17' does not match format '%Y%m%d'
2017-03-07 13:38:24 [guangdong] ERROR: save_time_error:time data '2016-10-21' does not match format '%Y%m%d'
2017-03-07 13:38:24 [guangdong] ERROR: save_time_error:time data '2016-10-21' does not match format '%Y%m%d'
2017-03-07 13:38:24 [guangdong] ERROR: save_time_error:time data '2016-10-21' does not match format '%Y%m%d'
2017-03-07 13:38:24 [guangdong] ERROR: save_time_error:time data '2016-10-20' does not match format '%Y%m%d'
2017-03-07 13:38:46 [scrapy.extensions.logstats] INFO: Crawled 614 pages (at 54 pages/min), scraped 613 items (at 54 items/min)
2017-03-07 13:38:54 [guangdong] ERROR: save_time_error:time data '2017-01-05' does not match format '%Y%m%d'
2017-03-07 13:38:54 [guangdong] ERROR: save_time_error:time data '2017-01-03' does not match format '%Y%m%d'
2017-03-07 13:38:54 [guangdong] ERROR: save_time_error:time data '2017-01-03' does not match format '%Y%m%d'
2017-03-07 13:38:54 [guangdong] ERROR: save_time_error:time data '2016-12-30' does not match format '%Y%m%d'
2017-03-07 13:38:54 [guangdong] ERROR: save_time_error:time data '2017-01-04' does not match format '%Y%m%d'
2017-03-07 13:38:54 [guangdong] ERROR: save_time_error:time data '2017-01-20' does not match format '%Y%m%d'
2017-03-07 13:38:55 [guangdong] ERROR: save_time_error:time data '2017-01-22' does not match format '%Y%m%d'
2017-03-07 13:38:55 [guangdong] ERROR: save_time_error:time data '2017-01-25' does not match format '%Y%m%d'
2017-03-07 13:38:56 [guangdong] ERROR: save_time_error:time data '2017-01-25' does not match format '%Y%m%d'
2017-03-07 13:38:56 [guangdong] ERROR: save_time_error:time data '2017-02-06' does not match format '%Y%m%d'
2017-03-07 13:38:57 [guangdong] ERROR: save_time_error:time data '2017-02-08' does not match format '%Y%m%d'
2017-03-07 13:38:57 [guangdong] ERROR: save_time_error:time data '2017-02-09' does not match format '%Y%m%d'
2017-03-07 13:38:58 [guangdong] ERROR: save_time_error:time data '2017-02-09' does not match format '%Y%m%d'
2017-03-07 13:38:58 [guangdong] ERROR: save_time_error:time data '2017-02-13' does not match format '%Y%m%d'
2017-03-07 13:38:59 [guangdong] ERROR: save_time_error:time data '2017-02-16' does not match format '%Y%m%d'
2017-03-07 13:38:59 [guangdong] ERROR: save_time_error:time data '2017-02-16' does not match format '%Y%m%d'
2017-03-07 13:39:00 [guangdong] ERROR: save_time_error:time data '2017-02-21' does not match format '%Y%m%d'
2017-03-07 13:39:00 [guangdong] ERROR: save_time_error:time data '2017-02-18' does not match format '%Y%m%d'
2017-03-07 13:39:01 [guangdong] ERROR: save_time_error:time data '2017-02-21' does not match format '%Y%m%d'
2017-03-07 13:39:01 [guangdong] ERROR: save_time_error:time data '2017-02-21' does not match format '%Y%m%d'
2017-03-07 13:39:02 [guangdong] ERROR: save_time_error:time data '2017-02-21' does not match format '%Y%m%d'
2017-03-07 13:39:02 [guangdong] ERROR: save_time_error:time data '2017-02-21' does not match format '%Y%m%d'
2017-03-07 13:39:03 [guangdong] ERROR: save_time_error:time data '2017-02-24' does not match format '%Y%m%d'
2017-03-07 13:39:04 [guangdong] ERROR: save_time_error:time data '2017-02-28' does not match format '%Y%m%d'
2017-03-07 13:39:04 [guangdong] ERROR: save_time_error:time data '2016-12-28' does not match format '%Y%m%d'
2017-03-07 13:39:04 [guangdong] ERROR: save_time_error:time data '2016-12-28' does not match format '%Y%m%d'
2017-03-07 13:39:05 [guangdong] ERROR: save_time_error:time data '2016-12-20' does not match format '%Y%m%d'
2017-03-07 13:39:05 [guangdong] ERROR: save_time_error:time data '2016-12-27' does not match format '%Y%m%d'
2017-03-07 13:39:06 [guangdong] ERROR: save_time_error:time data '2016-12-20' does not match format '%Y%m%d'
2017-03-07 13:39:06 [guangdong] ERROR: save_time_error:time data '2016-12-24' does not match format '%Y%m%d'
2017-03-07 13:39:07 [guangdong] ERROR: save_time_error:time data '2016-12-19' does not match format '%Y%m%d'
2017-03-07 13:39:07 [guangdong] ERROR: save_time_error:time data '2016-12-12' does not match format '%Y%m%d'
2017-03-07 13:39:08 [guangdong] ERROR: save_time_error:time data '2016-12-09' does not match format '%Y%m%d'
2017-03-07 13:39:08 [guangdong] ERROR: save_time_error:time data '2016-12-12' does not match format '%Y%m%d'
2017-03-07 13:39:08 [guangdong] ERROR: save_time_error:time data '2016-12-06' does not match format '%Y%m%d'
2017-03-07 13:39:08 [guangdong] ERROR: save_time_error:time data '2016-12-09' does not match format '%Y%m%d'
2017-03-07 13:39:09 [guangdong] ERROR: save_time_error:time data '2016-12-07' does not match format '%Y%m%d'
2017-03-07 13:39:09 [guangdong] ERROR: save_time_error:time data '2016-12-09' does not match format '%Y%m%d'
2017-03-07 13:39:10 [guangdong] ERROR: save_time_error:time data '2016-12-05' does not match format '%Y%m%d'
2017-03-07 13:39:10 [guangdong] ERROR: save_time_error:time data '2016-12-05' does not match format '%Y%m%d'
2017-03-07 13:39:11 [guangdong] ERROR: save_time_error:time data '2016-12-02' does not match format '%Y%m%d'
2017-03-07 13:39:11 [guangdong] ERROR: save_time_error:time data '2016-12-02' does not match format '%Y%m%d'
2017-03-07 13:39:12 [guangdong] ERROR: save_time_error:time data '2016-12-02' does not match format '%Y%m%d'
2017-03-07 13:39:12 [guangdong] ERROR: save_time_error:time data '2016-12-02' does not match format '%Y%m%d'
2017-03-07 13:39:13 [guangdong] ERROR: save_time_error:time data '2016-12-01' does not match format '%Y%m%d'
2017-03-07 13:39:13 [guangdong] ERROR: save_time_error:time data '2016-11-28' does not match format '%Y%m%d'
2017-03-07 13:39:14 [guangdong] ERROR: save_time_error:time data '2016-12-01' does not match format '%Y%m%d'
2017-03-07 13:39:14 [guangdong] ERROR: save_time_error:time data '2016-11-23' does not match format '%Y%m%d'
2017-03-07 13:39:15 [guangdong] ERROR: save_time_error:time data '2016-11-24' does not match format '%Y%m%d'
2017-03-07 13:39:15 [guangdong] ERROR: save_time_error:time data '2016-11-24' does not match format '%Y%m%d'
2017-03-07 13:39:16 [guangdong] ERROR: save_time_error:time data '2016-11-24' does not match format '%Y%m%d'
2017-03-07 13:39:16 [guangdong] ERROR: save_time_error:time data '2016-11-23' does not match format '%Y%m%d'
2017-03-07 13:39:17 [guangdong] ERROR: save_time_error:time data '2016-11-21' does not match format '%Y%m%d'
2017-03-07 13:39:17 [guangdong] ERROR: save_time_error:time data '2016-11-17' does not match format '%Y%m%d'
2017-03-07 13:39:17 [guangdong] ERROR: save_time_error:time data '2016-11-16' does not match format '%Y%m%d'
2017-03-07 13:39:17 [guangdong] ERROR: save_time_error:time data '2016-11-11' does not match format '%Y%m%d'
2017-03-07 13:39:18 [guangdong] ERROR: save_time_error:time data '2016-11-15' does not match format '%Y%m%d'
2017-03-07 13:39:18 [guangdong] ERROR: save_time_error:time data '2016-11-14' does not match format '%Y%m%d'
2017-03-07 13:39:19 [guangdong] ERROR: save_time_error:time data '2016-11-16' does not match format '%Y%m%d'
2017-03-07 13:39:19 [guangdong] ERROR: save_time_error:time data '2016-11-11' does not match format '%Y%m%d'
2017-03-07 13:39:20 [guangdong] ERROR: save_time_error:time data '2016-11-10' does not match format '%Y%m%d'
2017-03-07 13:39:20 [guangdong] ERROR: save_time_error:time data '2016-11-08' does not match format '%Y%m%d'
2017-03-07 13:39:21 [guangdong] ERROR: save_time_error:time data '2016-11-08' does not match format '%Y%m%d'
2017-03-07 13:39:21 [guangdong] ERROR: save_time_error:time data '2016-11-09' does not match format '%Y%m%d'
2017-03-07 13:39:23 [guangdong] ERROR: save_time_error:time data '2016-11-10' does not match format '%Y%m%d'
2017-03-07 13:39:23 [guangdong] ERROR: save_time_error:time data '2016-11-08' does not match format '%Y%m%d'
2017-03-07 13:39:24 [guangdong] ERROR: save_time_error:time data '2016-11-08' does not match format '%Y%m%d'
2017-03-07 13:39:24 [guangdong] ERROR: save_time_error:time data '2016-11-08' does not match format '%Y%m%d'
2017-03-07 13:39:24 [guangdong] ERROR: save_time_error:time data '2016-10-28' does not match format '%Y%m%d'
2017-03-07 13:39:25 [guangdong] ERROR: save_time_error:time data '2016-11-01' does not match format '%Y%m%d'
2017-03-07 13:39:25 [guangdong] ERROR: save_time_error:time data '2016-11-02' does not match format '%Y%m%d'
2017-03-07 13:39:25 [guangdong] ERROR: save_time_error:time data '2016-10-28' does not match format '%Y%m%d'
2017-03-07 13:39:26 [guangdong] ERROR: save_time_error:time data '2016-10-25' does not match format '%Y%m%d'
2017-03-07 13:39:26 [guangdong] ERROR: save_time_error:time data '2016-11-02' does not match format '%Y%m%d'
2017-03-07 13:39:27 [guangdong] ERROR: save_time_error:time data '2016-10-26' does not match format '%Y%m%d'
2017-03-07 13:39:27 [guangdong] ERROR: save_time_error:time data '2016-10-26' does not match format '%Y%m%d'
2017-03-07 13:39:28 [guangdong] ERROR: save_time_error:time data '2016-10-27' does not match format '%Y%m%d'
2017-03-07 13:39:28 [guangdong] ERROR: save_time_error:time data '2016-10-27' does not match format '%Y%m%d'
2017-03-07 13:39:29 [guangdong] ERROR: save_time_error:time data '2016-10-25' does not match format '%Y%m%d'
2017-03-07 13:39:29 [guangdong] ERROR: save_time_error:time data '2016-05-19' does not match format '%Y%m%d'
2017-03-07 13:39:30 [guangdong] ERROR: save_time_error:time data '2016-05-18' does not match format '%Y%m%d'
2017-03-07 13:39:30 [guangdong] ERROR: save_time_error:time data '2016-05-09' does not match format '%Y%m%d'
2017-03-07 13:39:31 [guangdong] ERROR: save_time_error:time data '2016-05-06' does not match format '%Y%m%d'
2017-03-07 13:39:31 [guangdong] ERROR: save_time_error:time data '2016-04-29' does not match format '%Y%m%d'
2017-03-07 13:39:32 [guangdong] ERROR: save_time_error:time data '2016-04-27' does not match format '%Y%m%d'
2017-03-07 13:39:32 [guangdong] ERROR: save_time_error:time data '2016-08-09' does not match format '%Y%m%d'
2017-03-07 13:39:32 [guangdong] ERROR: save_time_error:time data '2016-08-08' does not match format '%Y%m%d'
2017-03-07 13:39:32 [guangdong] ERROR: save_time_error:time data '2016-08-09' does not match format '%Y%m%d'
2017-03-07 13:39:33 [guangdong] ERROR: save_time_error:time data '2016-08-04' does not match format '%Y%m%d'
2017-03-07 13:39:33 [guangdong] ERROR: save_time_error:time data '2016-08-01' does not match format '%Y%m%d'
2017-03-07 13:39:34 [guangdong] ERROR: save_time_error:time data '2016-07-28' does not match format '%Y%m%d'
2017-03-07 13:39:34 [guangdong] ERROR: save_time_error:time data '2016-07-28' does not match format '%Y%m%d'
2017-03-07 13:39:35 [guangdong] ERROR: save_time_error:time data '2016-07-27' does not match format '%Y%m%d'
2017-03-07 13:39:35 [guangdong] ERROR: save_time_error:time data '2016-07-27' does not match format '%Y%m%d'
2017-03-07 13:39:36 [guangdong] ERROR: save_time_error:time data '2016-07-25' does not match format '%Y%m%d'
2017-03-07 13:39:36 [guangdong] ERROR: save_time_error:time data '2016-07-26' does not match format '%Y%m%d'
2017-03-07 13:39:36 [guangdong] ERROR: save_time_error:time data '2016-07-18' does not match format '%Y%m%d'
2017-03-07 13:39:36 [guangdong] ERROR: save_time_error:time data '2016-07-19' does not match format '%Y%m%d'
2017-03-07 13:39:37 [guangdong] ERROR: save_time_error:time data '2016-07-18' does not match format '%Y%m%d'
2017-03-07 13:39:37 [guangdong] ERROR: save_time_error:time data '2016-07-18' does not match format '%Y%m%d'
2017-03-07 13:39:38 [guangdong] ERROR: save_time_error:time data '2016-07-14' does not match format '%Y%m%d'
2017-03-07 13:39:38 [guangdong] ERROR: save_time_error:time data '2016-07-13' does not match format '%Y%m%d'
2017-03-07 13:39:39 [guangdong] ERROR: save_time_error:time data '2016-07-12' does not match format '%Y%m%d'
2017-03-07 13:39:39 [guangdong] ERROR: save_time_error:time data '2016-07-13' does not match format '%Y%m%d'
2017-03-07 13:39:40 [guangdong] ERROR: save_time_error:time data '2016-07-12' does not match format '%Y%m%d'
2017-03-07 13:39:40 [guangdong] ERROR: save_time_error:time data '2016-07-12' does not match format '%Y%m%d'
2017-03-07 13:39:41 [guangdong] ERROR: save_time_error:time data '2016-07-08' does not match format '%Y%m%d'
2017-03-07 13:39:41 [guangdong] ERROR: save_time_error:time data '2016-07-12' does not match format '%Y%m%d'
2017-03-07 13:39:42 [guangdong] ERROR: save_time_error:time data '2016-07-07' does not match format '%Y%m%d'
2017-03-07 13:39:42 [guangdong] ERROR: save_time_error:time data '2016-07-08' does not match format '%Y%m%d'
2017-03-07 13:39:43 [guangdong] ERROR: save_time_error:time data '2016-07-07' does not match format '%Y%m%d'
2017-03-07 13:39:43 [guangdong] ERROR: save_time_error:time data '2016-07-06' does not match format '%Y%m%d'
2017-03-07 13:39:44 [guangdong] ERROR: save_time_error:time data '2015-12-14' does not match format '%Y%m%d'
2017-03-07 13:39:44 [guangdong] ERROR: save_time_error:time data '2015-12-11' does not match format '%Y%m%d'
2017-03-07 13:39:44 [guangdong] ERROR: save_time_error:time data '2016-04-22' does not match format '%Y%m%d'
2017-03-07 13:39:44 [scrapy.extensions.logstats] INFO: Crawled 730 pages (at 116 pages/min), scraped 728 items (at 115 items/min)
2017-03-07 13:39:44 [guangdong] ERROR: save_time_error:time data '2016-04-27' does not match format '%Y%m%d'
2017-03-07 13:39:46 [guangdong] ERROR: save_time_error:time data '2016-04-22' does not match format '%Y%m%d'
2017-03-07 13:39:46 [guangdong] ERROR: save_time_error:time data '2016-04-21' does not match format '%Y%m%d'
2017-03-07 13:39:46 [guangdong] ERROR: save_time_error:time data '2016-04-20' does not match format '%Y%m%d'
2017-03-07 13:39:46 [guangdong] ERROR: save_time_error:time data '2016-04-19' does not match format '%Y%m%d'
2017-03-07 13:39:47 [guangdong] ERROR: save_time_error:time data '2016-04-14' does not match format '%Y%m%d'
2017-03-07 13:39:47 [guangdong] ERROR: save_time_error:time data '2016-04-18' does not match format '%Y%m%d'
2017-03-07 13:39:48 [guangdong] ERROR: save_time_error:time data '2016-04-18' does not match format '%Y%m%d'
2017-03-07 13:39:48 [guangdong] ERROR: save_time_error:time data '2016-04-15' does not match format '%Y%m%d'
2017-03-07 13:39:49 [guangdong] ERROR: save_time_error:time data '2016-04-13' does not match format '%Y%m%d'
2017-03-07 13:39:49 [guangdong] ERROR: save_time_error:time data '2016-04-13' does not match format '%Y%m%d'
2017-03-07 13:39:51 [guangdong] ERROR: save_time_error:time data '2016-04-08' does not match format '%Y%m%d'
2017-03-07 13:39:51 [guangdong] ERROR: save_time_error:time data '2016-03-31' does not match format '%Y%m%d'
2017-03-07 13:39:52 [guangdong] ERROR: save_time_error:time data '2016-04-12' does not match format '%Y%m%d'
2017-03-07 13:39:52 [guangdong] ERROR: save_time_error:time data '2016-04-12' does not match format '%Y%m%d'
2017-03-07 13:39:54 [guangdong] ERROR: save_time_error:time data '2016-04-08' does not match format '%Y%m%d'
2017-03-07 13:39:54 [guangdong] ERROR: save_time_error:time data '2016-03-31' does not match format '%Y%m%d'
2017-03-07 13:39:55 [guangdong] ERROR: save_time_error:time data '2016-03-30' does not match format '%Y%m%d'
2017-03-07 13:39:55 [guangdong] ERROR: save_time_error:time data '2016-03-25' does not match format '%Y%m%d'
2017-03-07 13:39:55 [guangdong] ERROR: save_time_error:time data '2016-03-25' does not match format '%Y%m%d'
2017-03-07 13:39:55 [guangdong] ERROR: save_time_error:time data '2016-03-30' does not match format '%Y%m%d'
2017-03-07 13:39:56 [guangdong] ERROR: save_time_error:time data '2016-03-30' does not match format '%Y%m%d'
2017-03-07 13:39:56 [guangdong] ERROR: save_time_error:time data '2016-03-28' does not match format '%Y%m%d'
2017-03-07 13:39:57 [guangdong] ERROR: save_time_error:time data '2016-03-24' does not match format '%Y%m%d'
2017-03-07 13:39:57 [guangdong] ERROR: save_time_error:time data '2016-03-24' does not match format '%Y%m%d'
2017-03-07 13:39:58 [guangdong] ERROR: save_time_error:time data '2016-03-22' does not match format '%Y%m%d'
2017-03-07 13:39:58 [guangdong] ERROR: save_time_error:time data '2016-03-15' does not match format '%Y%m%d'
2017-03-07 13:39:59 [guangdong] ERROR: save_time_error:time data '2016-03-16' does not match format '%Y%m%d'
2017-03-07 13:39:59 [guangdong] ERROR: save_time_error:time data '2016-03-18' does not match format '%Y%m%d'
2017-03-07 13:40:00 [guangdong] ERROR: save_time_error:time data '2016-03-21' does not match format '%Y%m%d'
2017-03-07 13:40:00 [guangdong] ERROR: save_time_error:time data '2016-03-09' does not match format '%Y%m%d'
2017-03-07 13:40:01 [guangdong] ERROR: save_time_error:time data '2016-03-14' does not match format '%Y%m%d'
2017-03-07 13:40:01 [guangdong] ERROR: save_time_error:time data '2016-03-07' does not match format '%Y%m%d'
2017-03-07 13:40:02 [guangdong] ERROR: save_time_error:time data '2016-03-08' does not match format '%Y%m%d'
2017-03-07 13:40:02 [guangdong] ERROR: save_time_error:time data '2016-03-04' does not match format '%Y%m%d'
2017-03-07 13:40:03 [guangdong] ERROR: save_time_error:time data '2016-03-04' does not match format '%Y%m%d'
2017-03-07 13:40:03 [guangdong] ERROR: save_time_error:time data '2016-03-07' does not match format '%Y%m%d'
2017-03-07 13:40:03 [guangdong] ERROR: save_time_error:time data '2016-03-02' does not match format '%Y%m%d'
2017-03-07 13:40:03 [guangdong] ERROR: save_time_error:time data '2016-03-03' does not match format '%Y%m%d'
2017-03-07 13:40:04 [guangdong] ERROR: save_time_error:time data '2016-02-17' does not match format '%Y%m%d'
2017-03-07 13:40:04 [guangdong] ERROR: save_time_error:time data '2016-02-05' does not match format '%Y%m%d'
2017-03-07 13:40:05 [guangdong] ERROR: save_time_error:time data '2016-02-26' does not match format '%Y%m%d'
2017-03-07 13:40:05 [guangdong] ERROR: save_time_error:time data '2016-02-25' does not match format '%Y%m%d'
2017-03-07 13:40:06 [guangdong] ERROR: save_time_error:time data '2016-02-23' does not match format '%Y%m%d'
2017-03-07 13:40:06 [guangdong] ERROR: save_time_error:time data '2016-02-04' does not match format '%Y%m%d'
2017-03-07 13:40:07 [guangdong] ERROR: save_time_error:time data '2016-02-03' does not match format '%Y%m%d'
2017-03-07 13:40:07 [guangdong] ERROR: save_time_error:time data '2016-02-03' does not match format '%Y%m%d'
2017-03-07 13:40:08 [guangdong] ERROR: save_time_error:time data '2016-02-02' does not match format '%Y%m%d'
2017-03-07 13:40:08 [guangdong] ERROR: save_time_error:time data '2016-02-01' does not match format '%Y%m%d'
2017-03-07 13:40:10 [guangdong] ERROR: save_time_error:time data '2016-02-03' does not match format '%Y%m%d'
2017-03-07 13:40:10 [guangdong] ERROR: save_time_error:time data '2016-02-02' does not match format '%Y%m%d'
2017-03-07 13:40:13 [guangdong] ERROR: save_time_error:time data '2016-01-29' does not match format '%Y%m%d'
2017-03-07 13:40:13 [guangdong] ERROR: save_time_error:time data '2016-02-01' does not match format '%Y%m%d'
2017-03-07 13:40:29 [guangdong] ERROR: save_time_error:time data '2015-05-27' does not match format '%Y%m%d'
2017-03-07 13:40:29 [guangdong] ERROR: save_time_error:time data '2015-05-21' does not match format '%Y%m%d'
2017-03-07 13:40:29 [guangdong] ERROR: save_time_error:time data '2015-05-22' does not match format '%Y%m%d'
2017-03-07 13:40:29 [guangdong] ERROR: save_time_error:time data '2015-05-28' does not match format '%Y%m%d'
2017-03-07 13:40:44 [scrapy.extensions.logstats] INFO: Crawled 786 pages (at 56 pages/min), scraped 785 items (at 57 items/min)
2017-03-07 13:41:44 [scrapy.extensions.logstats] INFO: Crawled 786 pages (at 0 pages/min), scraped 785 items (at 0 items/min)
2017-03-07 13:42:44 [scrapy.extensions.logstats] INFO: Crawled 786 pages (at 0 pages/min), scraped 785 items (at 0 items/min)
2017-03-07 13:43:14 [guangdong] ERROR: save_time_error:time data '2015-11-27' does not match format '%Y%m%d'
2017-03-07 13:43:14 [guangdong] ERROR: save_time_error:time data '2015-11-26' does not match format '%Y%m%d'
2017-03-07 13:43:14 [guangdong] ERROR: save_time_error:time data '2015-11-27' does not match format '%Y%m%d'
2017-03-07 13:43:14 [guangdong] ERROR: save_time_error:time data '2015-11-27' does not match format '%Y%m%d'
2017-03-07 13:43:20 [guangdong] ERROR: save_time_error:time data '2015-11-25' does not match format '%Y%m%d'
2017-03-07 13:43:20 [guangdong] ERROR: save_time_error:time data '2015-11-24' does not match format '%Y%m%d'
2017-03-07 13:43:20 [guangdong] ERROR: save_time_error:time data '2015-11-24' does not match format '%Y%m%d'
2017-03-07 13:43:20 [guangdong] ERROR: save_time_error:time data '2015-11-24' does not match format '%Y%m%d'
2017-03-07 13:43:28 [guangdong] ERROR: save_time_error:time data '2015-11-24' does not match format '%Y%m%d'
2017-03-07 13:43:29 [guangdong] ERROR: save_time_error:time data '2015-11-24' does not match format '%Y%m%d'
2017-03-07 13:43:29 [guangdong] ERROR: save_time_error:time data '2015-11-24' does not match format '%Y%m%d'
2017-03-07 13:43:29 [guangdong] ERROR: save_time_error:time data '2015-11-24' does not match format '%Y%m%d'
2017-03-07 13:43:30 [guangdong] ERROR: save_time_error:time data '2015-11-23' does not match format '%Y%m%d'
2017-03-07 13:43:31 [guangdong] ERROR: save_time_error:time data '2015-11-23' does not match format '%Y%m%d'
2017-03-07 13:43:31 [guangdong] ERROR: save_time_error:time data '2015-11-23' does not match format '%Y%m%d'
2017-03-07 13:43:33 [guangdong] ERROR: save_time_error:time data '2015-11-23' does not match format '%Y%m%d'
2017-03-07 13:43:34 [guangdong] ERROR: save_time_error:time data '2015-11-20' does not match format '%Y%m%d'
2017-03-07 13:43:34 [guangdong] ERROR: save_time_error:time data '2015-11-20' does not match format '%Y%m%d'
2017-03-07 13:43:34 [guangdong] ERROR: save_time_error:time data '2015-11-20' does not match format '%Y%m%d'
2017-03-07 13:43:35 [guangdong] ERROR: save_time_error:time data '2015-11-20' does not match format '%Y%m%d'
2017-03-07 13:43:36 [guangdong] ERROR: save_time_error:time data '2015-11-18' does not match format '%Y%m%d'
2017-03-07 13:43:37 [guangdong] ERROR: save_time_error:time data '2015-11-19' does not match format '%Y%m%d'
2017-03-07 13:43:37 [guangdong] ERROR: save_time_error:time data '2015-11-18' does not match format '%Y%m%d'
2017-03-07 13:43:37 [guangdong] ERROR: save_time_error:time data '2015-11-17' does not match format '%Y%m%d'
2017-03-07 13:43:38 [guangdong] ERROR: save_time_error:time data '2015-11-18' does not match format '%Y%m%d'
2017-03-07 13:43:39 [guangdong] ERROR: save_time_error:time data '2015-11-17' does not match format '%Y%m%d'
2017-03-07 13:43:42 [guangdong] ERROR: save_time_error:time data '2015-11-17' does not match format '%Y%m%d'
2017-03-07 13:43:42 [guangdong] ERROR: save_time_error:time data '2015-11-16' does not match format '%Y%m%d'
2017-03-07 13:43:43 [guangdong] ERROR: save_time_error:time data '2015-11-16' does not match format '%Y%m%d'
2017-03-07 13:43:44 [guangdong] ERROR: save_time_error:time data '2015-11-16' does not match format '%Y%m%d'
2017-03-07 13:43:47 [guangdong] ERROR: save_time_error:time data '2015-11-13' does not match format '%Y%m%d'
2017-03-07 13:43:47 [scrapy.extensions.logstats] INFO: Crawled 820 pages (at 34 pages/min), scraped 816 items (at 31 items/min)
2017-03-07 13:43:48 [guangdong] ERROR: save_time_error:time data '2015-11-12' does not match format '%Y%m%d'
2017-03-07 13:43:48 [guangdong] ERROR: save_time_error:time data '2015-11-12' does not match format '%Y%m%d'
2017-03-07 13:43:49 [guangdong] ERROR: save_time_error:time data '2015-11-12' does not match format '%Y%m%d'
2017-03-07 13:43:50 [guangdong] ERROR: save_time_error:time data '2015-11-12' does not match format '%Y%m%d'
2017-03-07 13:43:51 [guangdong] ERROR: save_time_error:time data '2015-11-11' does not match format '%Y%m%d'
2017-03-07 13:43:52 [guangdong] ERROR: save_time_error:time data '2015-11-11' does not match format '%Y%m%d'
2017-03-07 13:43:52 [guangdong] ERROR: save_time_error:time data '2015-11-11' does not match format '%Y%m%d'
2017-03-07 13:43:53 [guangdong] ERROR: save_time_error:time data '2015-11-10' does not match format '%Y%m%d'
2017-03-07 13:43:54 [guangdong] ERROR: save_time_error:time data '2015-11-10' does not match format '%Y%m%d'
2017-03-07 13:43:57 [guangdong] ERROR: save_time_error:time data '2015-11-10' does not match format '%Y%m%d'
2017-03-07 13:43:58 [guangdong] ERROR: save_time_error:time data '2015-11-09' does not match format '%Y%m%d'
2017-03-07 13:43:58 [guangdong] ERROR: save_time_error:time data '2015-11-06' does not match format '%Y%m%d'
2017-03-07 13:43:59 [guangdong] ERROR: save_time_error:time data '2015-11-06' does not match format '%Y%m%d'
2017-03-07 13:44:00 [guangdong] ERROR: save_time_error:time data '2015-11-06' does not match format '%Y%m%d'
2017-03-07 13:44:01 [guangdong] ERROR: save_time_error:time data '2015-11-06' does not match format '%Y%m%d'
2017-03-07 13:44:01 [guangdong] ERROR: save_time_error:time data '2015-11-06' does not match format '%Y%m%d'
2017-03-07 13:44:01 [guangdong] ERROR: save_time_error:time data '2015-11-06' does not match format '%Y%m%d'
2017-03-07 13:44:01 [guangdong] ERROR: save_time_error:time data '2014-10-24' does not match format '%Y%m%d'
2017-03-07 13:44:03 [guangdong] ERROR: save_time_error:time data '2015-05-21' does not match format '%Y%m%d'
2017-03-07 13:44:03 [guangdong] ERROR: save_time_error:time data '2015-05-17' does not match format '%Y%m%d'
2017-03-07 13:44:03 [guangdong] ERROR: save_time_error:time data '2015-05-18' does not match format '%Y%m%d'
2017-03-07 13:44:03 [guangdong] ERROR: save_time_error:time data '2015-05-19' does not match format '%Y%m%d'
2017-03-07 13:44:08 [guangdong] ERROR: save_time_error:time data '2015-05-15' does not match format '%Y%m%d'
2017-03-07 13:44:08 [guangdong] ERROR: save_time_error:time data '2015-05-18' does not match format '%Y%m%d'
2017-03-07 13:44:08 [guangdong] ERROR: save_time_error:time data '2015-05-15' does not match format '%Y%m%d'
2017-03-07 13:44:08 [guangdong] ERROR: save_time_error:time data '2015-05-19' does not match format '%Y%m%d'
2017-03-07 13:44:10 [guangdong] ERROR: save_time_error:time data '2015-05-11' does not match format '%Y%m%d'
2017-03-07 13:44:10 [guangdong] ERROR: save_time_error:time data '2015-05-13' does not match format '%Y%m%d'
2017-03-07 13:44:10 [guangdong] ERROR: save_time_error:time data '2015-05-07' does not match format '%Y%m%d'
2017-03-07 13:44:10 [guangdong] ERROR: save_time_error:time data '2015-05-14' does not match format '%Y%m%d'
2017-03-07 13:44:12 [guangdong] ERROR: save_time_error:time data '2015-05-13' does not match format '%Y%m%d'
2017-03-07 13:44:12 [guangdong] ERROR: save_time_error:time data '2015-05-05' does not match format '%Y%m%d'
2017-03-07 13:44:12 [guangdong] ERROR: save_time_error:time data '2015-05-13' does not match format '%Y%m%d'
2017-03-07 13:44:12 [guangdong] ERROR: save_time_error:time data '2015-05-12' does not match format '%Y%m%d'
2017-03-07 13:44:15 [guangdong] ERROR: save_time_error:time data '2015-04-30' does not match format '%Y%m%d'
2017-03-07 13:44:15 [guangdong] ERROR: save_time_error:time data '2015-04-30' does not match format '%Y%m%d'
2017-03-07 13:44:15 [guangdong] ERROR: save_time_error:time data '2015-04-30' does not match format '%Y%m%d'
2017-03-07 13:44:15 [guangdong] ERROR: save_time_error:time data '2015-05-05' does not match format '%Y%m%d'
2017-03-07 13:44:17 [guangdong] ERROR: save_time_error:time data '2015-04-30' does not match format '%Y%m%d'
2017-03-07 13:44:17 [guangdong] ERROR: save_time_error:time data '2015-05-05' does not match format '%Y%m%d'
2017-03-07 13:44:17 [guangdong] ERROR: save_time_error:time data '2015-04-30' does not match format '%Y%m%d'
2017-03-07 13:44:39 [guangdong] ERROR: save_time_error:time data '2015-04-29' does not match format '%Y%m%d'
2017-03-07 13:44:39 [guangdong] ERROR: save_time_error:time data '2015-04-24' does not match format '%Y%m%d'
2017-03-07 13:44:39 [guangdong] ERROR: save_time_error:time data '2015-04-29' does not match format '%Y%m%d'
2017-03-07 13:44:41 [guangdong] ERROR: save_time_error:time data '2015-05-05' does not match format '%Y%m%d'
2017-03-07 13:44:47 [scrapy.extensions.logstats] INFO: Crawled 862 pages (at 42 pages/min), scraped 861 items (at 45 items/min)
2017-03-07 13:45:44 [scrapy.extensions.logstats] INFO: Crawled 862 pages (at 0 pages/min), scraped 861 items (at 0 items/min)
2017-03-07 13:46:56 [scrapy.extensions.logstats] INFO: Crawled 862 pages (at 0 pages/min), scraped 861 items (at 0 items/min)
2017-03-07 13:47:09 [guangdong] ERROR: save_time_error:time data '2015-03-20' does not match format '%Y%m%d'
2017-03-07 13:47:10 [guangdong] ERROR: save_time_error:time data '2015-03-25' does not match format '%Y%m%d'
2017-03-07 13:47:10 [guangdong] ERROR: save_time_error:time data '2015-03-25' does not match format '%Y%m%d'
2017-03-07 13:47:10 [guangdong] ERROR: save_time_error:time data '2014-10-24' does not match format '%Y%m%d'
2017-03-07 13:47:10 [guangdong] ERROR: save_time_error:time data '2015-03-25' does not match format '%Y%m%d'
2017-03-07 13:47:10 [guangdong] ERROR: save_time_error:time data '2015-03-19' does not match format '%Y%m%d'
2017-03-07 13:47:10 [guangdong] ERROR: save_time_error:time data '2015-03-24' does not match format '%Y%m%d'
2017-03-07 13:47:15 [guangdong] ERROR: save_time_error:time data '2014-10-22' does not match format '%Y%m%d'
2017-03-07 13:47:16 [guangdong] ERROR: save_time_error:time data '2014-10-23' does not match format '%Y%m%d'
2017-03-07 13:47:16 [guangdong] ERROR: save_time_error:time data '2014-10-20' does not match format '%Y%m%d'
2017-03-07 13:47:16 [guangdong] ERROR: save_time_error:time data '2014-10-22' does not match format '%Y%m%d'
2017-03-07 13:47:16 [guangdong] ERROR: save_time_error:time data '2014-10-23' does not match format '%Y%m%d'
2017-03-07 13:47:16 [guangdong] ERROR: save_time_error:time data '2014-10-22' does not match format '%Y%m%d'
2017-03-07 13:47:16 [guangdong] ERROR: save_time_error:time data '2014-10-22' does not match format '%Y%m%d'
2017-03-07 13:47:18 [guangdong] ERROR: save_time_error:time data '2014-10-20' does not match format '%Y%m%d'
2017-03-07 13:47:19 [guangdong] ERROR: save_time_error:time data '2014-10-21' does not match format '%Y%m%d'
2017-03-07 13:47:20 [guangdong] ERROR: save_time_error:time data '2014-10-20' does not match format '%Y%m%d'
2017-03-07 13:47:21 [guangdong] ERROR: save_time_error:time data '2014-10-20' does not match format '%Y%m%d'
2017-03-07 13:47:21 [guangdong] ERROR: save_time_error:time data '2014-10-17' does not match format '%Y%m%d'
2017-03-07 13:47:21 [guangdong] ERROR: save_time_error:time data '2014-10-20' does not match format '%Y%m%d'
2017-03-07 13:47:21 [guangdong] ERROR: save_time_error:time data '2014-10-17' does not match format '%Y%m%d'
2017-03-07 13:47:22 [guangdong] ERROR: save_time_error:time data '2014-10-16' does not match format '%Y%m%d'
2017-03-07 13:47:22 [guangdong] ERROR: save_time_error:time data '2014-10-17' does not match format '%Y%m%d'
2017-03-07 13:47:24 [guangdong] ERROR: save_time_error:time data '2014-10-16' does not match format '%Y%m%d'
2017-03-07 13:47:24 [guangdong] ERROR: save_time_error:time data '2014-10-17' does not match format '%Y%m%d'
2017-03-07 13:47:24 [guangdong] ERROR: save_time_error:time data '2014-10-14' does not match format '%Y%m%d'
2017-03-07 13:47:24 [guangdong] ERROR: save_time_error:time data '2014-10-16' does not match format '%Y%m%d'
2017-03-07 13:47:24 [guangdong] ERROR: save_time_error:time data '2014-10-14' does not match format '%Y%m%d'
2017-03-07 13:47:31 [guangdong] ERROR: save_time_error:time data '2014-10-13' does not match format '%Y%m%d'
2017-03-07 13:47:31 [guangdong] ERROR: save_time_error:time data '2014-10-16' does not match format '%Y%m%d'
2017-03-07 13:47:31 [guangdong] ERROR: save_time_error:time data '2014-10-14' does not match format '%Y%m%d'
2017-03-07 13:47:31 [guangdong] ERROR: save_time_error:time data '2014-10-13' does not match format '%Y%m%d'
2017-03-07 13:47:31 [guangdong] ERROR: save_time_error:time data '2014-10-13' does not match format '%Y%m%d'
2017-03-07 13:47:31 [guangdong] ERROR: save_time_error:time data '2014-10-11' does not match format '%Y%m%d'
2017-03-07 13:47:31 [guangdong] ERROR: save_time_error:time data '2014-10-11' does not match format '%Y%m%d'
2017-03-07 13:47:35 [guangdong] ERROR: save_time_error:time data '2014-10-13' does not match format '%Y%m%d'
2017-03-07 13:47:37 [guangdong] ERROR: save_time_error:time data '2014-10-09' does not match format '%Y%m%d'
2017-03-07 13:47:37 [guangdong] ERROR: save_time_error:time data '2014-10-11' does not match format '%Y%m%d'
2017-03-07 13:47:37 [guangdong] ERROR: save_time_error:time data '2014-10-10' does not match format '%Y%m%d'
2017-03-07 13:47:37 [guangdong] ERROR: save_time_error:time data '2014-10-11' does not match format '%Y%m%d'
2017-03-07 13:47:37 [guangdong] ERROR: save_time_error:time data '2014-10-11' does not match format '%Y%m%d'
2017-03-07 13:47:49 [guangdong] ERROR: save_time_error:time data '2014-10-10' does not match format '%Y%m%d'
2017-03-07 13:47:49 [guangdong] ERROR: save_time_error:time data '2014-10-11' does not match format '%Y%m%d'
2017-03-07 13:47:49 [scrapy.extensions.logstats] INFO: Crawled 907 pages (at 45 pages/min), scraped 904 items (at 43 items/min)
2017-03-07 13:47:51 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:54 [guangdong] ERROR: save_time_error:time data '2014-10-08' does not match format '%Y%m%d'
2017-03-07 13:47:55 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:55 [guangdong] ERROR: save_time_error:time data '2014-10-09' does not match format '%Y%m%d'
2017-03-07 13:47:55 [guangdong] ERROR: save_time_error:time data '2014-10-08' does not match format '%Y%m%d'
2017-03-07 13:47:55 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:55 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:56 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:56 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:56 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:58 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:59 [guangdong] ERROR: save_time_error:time data '2014-07-25' does not match format '%Y%m%d'
2017-03-07 13:47:59 [guangdong] ERROR: save_time_error:time data '2015-04-23' does not match format '%Y%m%d'
2017-03-07 13:47:59 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:47:59 [guangdong] ERROR: save_time_error:time data '2014-07-25' does not match format '%Y%m%d'
2017-03-07 13:47:59 [guangdong] ERROR: save_time_error:time data '2014-09-30' does not match format '%Y%m%d'
2017-03-07 13:48:00 [guangdong] ERROR: save_time_error:time data '2014-07-25' does not match format '%Y%m%d'
2017-03-07 13:48:00 [guangdong] ERROR: save_time_error:time data '2015-04-21' does not match format '%Y%m%d'
2017-03-07 13:48:03 [guangdong] ERROR: save_time_error:time data '2015-03-03' does not match format '%Y%m%d'
2017-03-07 13:48:06 [guangdong] ERROR: save_time_error:time data '2015-04-20' does not match format '%Y%m%d'
2017-03-07 13:48:07 [guangdong] ERROR: save_time_error:time data '2015-04-21' does not match format '%Y%m%d'
2017-03-07 13:48:07 [guangdong] ERROR: save_time_error:time data '2015-06-08' does not match format '%Y%m%d'
2017-03-07 13:48:07 [guangdong] ERROR: save_time_error:time data '2015-04-16' does not match format '%Y%m%d'
2017-03-07 13:48:07 [guangdong] ERROR: save_time_error:time data '2015-04-20' does not match format '%Y%m%d'
2017-03-07 13:48:08 [guangdong] ERROR: save_time_error:time data '2015-04-21' does not match format '%Y%m%d'
2017-03-07 13:48:08 [guangdong] ERROR: save_time_error:time data '2015-07-08' does not match format '%Y%m%d'
2017-03-07 13:48:08 [guangdong] ERROR: save_time_error:time data '2015-06-05' does not match format '%Y%m%d'
2017-03-07 13:48:09 [guangdong] ERROR: save_time_error:time data '2015-06-02' does not match format '%Y%m%d'
2017-03-07 13:48:11 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-07 13:49:03 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-07 13:49:03 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-07 13:49:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-07 13:49:03 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:49:03 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:49:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-07 13:49:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-07 13:49:03 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-07 13:49:03 [scrapy.core.engine] INFO: Spider opened
2017-03-07 13:49:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 13:49:22 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.gdhrss.gov.cn/publicfiles/business/htmlfiles/tjzcw/sdgg/list.html>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-07 13:49:22 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-07 13:49:22 [guangdong] INFO: get_webpage_count:0
2017-03-07 13:49:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 7, 5, 49, 22, 127342),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 7, 5, 49, 3, 473713)}
2017-03-07 13:49:22 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-07 13:56:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-07 13:56:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-07 13:56:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-07 13:56:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:56:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:56:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-07 13:56:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-07 13:56:35 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-07 13:56:35 [scrapy.core.engine] INFO: Spider opened
2017-03-07 13:56:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 13:56:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index.shtml>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-07 13:56:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-07 13:56:37 [shanghai] INFO: get_webpage_count:0
2017-03-07 13:56:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1371,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 7, 5, 56, 37, 702303),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 7, 5, 56, 35, 894460)}
2017-03-07 13:56:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-07 13:57:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-07 13:57:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-07 13:57:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-07 13:57:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:57:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 13:57:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-07 13:57:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-07 13:57:47 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-07 13:57:47 [scrapy.core.engine] INFO: Spider opened
2017-03-07 13:57:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 13:57:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_499.shtml>: HTTP status code is not handled or not allowed
2017-03-07 13:58:48 [scrapy.extensions.logstats] INFO: Crawled 67 pages (at 67 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 13:59:47 [scrapy.extensions.logstats] INFO: Crawled 206 pages (at 139 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:00:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_498.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_497.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_496.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_495.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_494.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_492.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_493.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_490.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_491.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_489.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_488.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_487.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_486.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_485.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_484.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_483.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_482.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_481.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_480.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_479.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_477.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_476.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_475.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_474.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_472.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_473.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_470.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_471.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_469.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_468.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:00:47 [scrapy.extensions.logstats] INFO: Crawled 277 pages (at 71 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:01:47 [scrapy.extensions.logstats] INFO: Crawled 277 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:02:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_457.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_455.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_456.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_454.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_453.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_452.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_451.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_450.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_449.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_448.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_447.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_446.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_445.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_443.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_444.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_442.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_441.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_439.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_440.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_438.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_437.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_436.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_435.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_434.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_433.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_431.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_432.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_429.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_430.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:02:47 [scrapy.extensions.logstats] INFO: Crawled 306 pages (at 29 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:03:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_358.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_357.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_355.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_356.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_352.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_353.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_351.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_354.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_348.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_350.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_346.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_345.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_349.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_347.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_344.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_343.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_342.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_340.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_339.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_341.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_338.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_337.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_335.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_334.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_336.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_332.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_333.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_331.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_330.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_327.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_328.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_329.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_326.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_325.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_324.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_323.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_320.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_322.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_321.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_319.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_318.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_317.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_316.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_315.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_313.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_314.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_312.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_311.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_310.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_309.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_307.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_308.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_306.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_304.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_305.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_303.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_302.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_301.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_300.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:03:47 [scrapy.extensions.logstats] INFO: Crawled 371 pages (at 65 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:04:48 [scrapy.extensions.logstats] INFO: Crawled 453 pages (at 82 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:05:47 [scrapy.extensions.logstats] INFO: Crawled 557 pages (at 104 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:06:48 [scrapy.extensions.logstats] INFO: Crawled 605 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:07:48 [scrapy.extensions.logstats] INFO: Crawled 653 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:08:47 [scrapy.extensions.logstats] INFO: Crawled 700 pages (at 47 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:09:48 [scrapy.extensions.logstats] INFO: Crawled 797 pages (at 97 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:10:48 [scrapy.extensions.logstats] INFO: Crawled 872 pages (at 75 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:11:47 [scrapy.extensions.logstats] INFO: Crawled 872 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:13:38 [scrapy.extensions.logstats] INFO: Crawled 873 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:13:54 [scrapy.extensions.logstats] INFO: Crawled 873 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:14:47 [scrapy.extensions.logstats] INFO: Crawled 873 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:15:55 [scrapy.extensions.logstats] INFO: Crawled 915 pages (at 42 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:16:24 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-07 14:16:25 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-07 14:16:25 [shanghai] INFO: get_webpage_count:0
2017-03-07 14:16:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 395,
 'downloader/exception_type_count/requests.exceptions.ConnectionError': 1,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 322,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 35,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 14,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 2,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 21,
 'downloader/request_bytes': 742376,
 'downloader/request_count': 1360,
 'downloader/request_method_count/GET': 1360,
 'downloader/response_bytes': 15753649,
 'downloader/response_count': 966,
 'downloader/response_status_count/200': 847,
 'downloader/response_status_count/404': 119,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 7, 6, 16, 25, 631836),
 'log_count/INFO': 146,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 966,
 'scheduler/dequeued': 1361,
 'scheduler/dequeued/memory': 1361,
 'scheduler/enqueued': 2236,
 'scheduler/enqueued/memory': 2236,
 'start_time': datetime.datetime(2017, 3, 7, 5, 57, 47, 374217)}
2017-03-07 14:16:25 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-07 14:17:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-07 14:17:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-07 14:17:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-07 14:17:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 14:17:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 14:17:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-07 14:17:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-07 14:17:44 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-07 14:17:44 [scrapy.core.engine] INFO: Spider opened
2017-03-07 14:17:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:17:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_499.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:18:03 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-07 14:18:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-07 14:18:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-07 14:18:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-07 14:18:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 14:18:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-07 14:18:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-07 14:18:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-07 14:18:33 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-07 14:18:33 [scrapy.core.engine] INFO: Spider opened
2017-03-07 14:18:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:19:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_499.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:19:35 [scrapy.extensions.logstats] INFO: Crawled 60 pages (at 60 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:20:33 [scrapy.extensions.logstats] INFO: Crawled 148 pages (at 88 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:21:34 [scrapy.extensions.logstats] INFO: Crawled 283 pages (at 135 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:22:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_498.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_497.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_496.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_495.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_494.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_492.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_493.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_491.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_490.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_489.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_487.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_488.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_485.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_486.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_484.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_483.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_482.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_481.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_480.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_477.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_478.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_476.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_479.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_475.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_474.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_473.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_471.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_472.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_467.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_470.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_469.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_468.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_465.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_466.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_464.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_462.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_463.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_461.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_460.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_458.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_459.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_457.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_456.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_455.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_453.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_454.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_452.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_451.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_450.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_449.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:34 [scrapy.extensions.logstats] INFO: Crawled 388 pages (at 105 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:22:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_448.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_447.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_446.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_444.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_445.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_441.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_442.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_440.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_443.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_438.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_439.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_437.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_436.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_435.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_432.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_433.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_434.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_431.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_429.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_430.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_428.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_426.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_427.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_422.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_424.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_423.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_425.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_421.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_420.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_419.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_418.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_417.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_416.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_413.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_414.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_415.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_411.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_412.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_410.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_409.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_408.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_405.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_404.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_406.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_407.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_402.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_403.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_401.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_399.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_400.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_397.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_395.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_398.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_396.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_393.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_394.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:22:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_392.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_391.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_390.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_389.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_388.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_386.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_387.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_384.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_385.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_383.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_381.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_382.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_377.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_379.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_380.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_378.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_376.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_375.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_371.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_368.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_372.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_369.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_373.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_370.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_367.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_360.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_363.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_362.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_361.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_365.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_364.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_366.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_359.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_353.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_352.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_354.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_355.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_357.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_356.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_358.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_351.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_345.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_349.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_346.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_348.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_350.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_344.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_347.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_343.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_338.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_341.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_340.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_339.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_342.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_337.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_336.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:23 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_335.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_332.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_334.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_331.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_328.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_333.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_330.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_329.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_327.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_326.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_324.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_320.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_321.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_322.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_325.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_319.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_317.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_318.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_314.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_312.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_316.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_313.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_315.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:34 [scrapy.extensions.logstats] INFO: Crawled 522 pages (at 134 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_311.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_310.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_309.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_308.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_306.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_303.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_305.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_304.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_307.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_302.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_301.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:23:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_300.shtml>: HTTP status code is not handled or not allowed
2017-03-07 14:24:34 [scrapy.extensions.logstats] INFO: Crawled 629 pages (at 107 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:25:34 [scrapy.extensions.logstats] INFO: Crawled 765 pages (at 136 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:26:34 [scrapy.extensions.logstats] INFO: Crawled 878 pages (at 113 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:27:34 [scrapy.extensions.logstats] INFO: Crawled 1005 pages (at 127 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:28:33 [scrapy.extensions.logstats] INFO: Crawled 1121 pages (at 116 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:29:34 [scrapy.extensions.logstats] INFO: Crawled 1270 pages (at 149 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:30:34 [scrapy.extensions.logstats] INFO: Crawled 1386 pages (at 116 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:31:34 [scrapy.extensions.logstats] INFO: Crawled 1471 pages (at 85 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:32:35 [scrapy.extensions.logstats] INFO: Crawled 1590 pages (at 119 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:33:33 [scrapy.extensions.logstats] INFO: Crawled 1731 pages (at 141 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:34:34 [scrapy.extensions.logstats] INFO: Crawled 1838 pages (at 107 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:35:33 [scrapy.extensions.logstats] INFO: Crawled 1955 pages (at 117 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:36:33 [scrapy.extensions.logstats] INFO: Crawled 2079 pages (at 124 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:37:33 [scrapy.extensions.logstats] INFO: Crawled 2144 pages (at 65 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:38:39 [scrapy.extensions.logstats] INFO: Crawled 2260 pages (at 116 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:39:33 [scrapy.extensions.logstats] INFO: Crawled 2351 pages (at 91 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:40:35 [scrapy.extensions.logstats] INFO: Crawled 2461 pages (at 110 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:41:34 [scrapy.extensions.logstats] INFO: Crawled 2563 pages (at 102 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:42:33 [scrapy.extensions.logstats] INFO: Crawled 2697 pages (at 134 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:43:33 [scrapy.extensions.logstats] INFO: Crawled 2843 pages (at 146 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:44:36 [scrapy.extensions.logstats] INFO: Crawled 2967 pages (at 124 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:45:34 [scrapy.extensions.logstats] INFO: Crawled 3032 pages (at 65 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:46:35 [scrapy.extensions.logstats] INFO: Crawled 3089 pages (at 57 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:47:34 [scrapy.extensions.logstats] INFO: Crawled 3211 pages (at 122 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:48:34 [scrapy.extensions.logstats] INFO: Crawled 3355 pages (at 144 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:49:35 [scrapy.extensions.logstats] INFO: Crawled 3478 pages (at 123 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:50:33 [scrapy.extensions.logstats] INFO: Crawled 3620 pages (at 142 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:51:33 [scrapy.extensions.logstats] INFO: Crawled 3760 pages (at 140 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:52:33 [scrapy.extensions.logstats] INFO: Crawled 3905 pages (at 145 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:53:33 [scrapy.extensions.logstats] INFO: Crawled 4062 pages (at 157 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:54:44 [scrapy.extensions.logstats] INFO: Crawled 4162 pages (at 100 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:55:35 [scrapy.extensions.logstats] INFO: Crawled 4246 pages (at 84 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:56:37 [scrapy.extensions.logstats] INFO: Crawled 4352 pages (at 106 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:57:34 [scrapy.extensions.logstats] INFO: Crawled 4485 pages (at 133 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:58:35 [scrapy.extensions.logstats] INFO: Crawled 4591 pages (at 106 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 14:59:34 [scrapy.extensions.logstats] INFO: Crawled 4739 pages (at 148 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 15:00:34 [scrapy.extensions.logstats] INFO: Crawled 4851 pages (at 112 pages/min), scraped 0 items (at 0 items/min)
2017-03-07 15:01:34 [scrapy.extensions.logstats] INFO: Crawled 4889 pages (at 38 pages/min), scraped 1 items (at 1 items/min)
2017-03-07 15:02:35 [scrapy.extensions.logstats] INFO: Crawled 4972 pages (at 83 pages/min), scraped 20 items (at 19 items/min)
2017-03-07 15:03:33 [scrapy.extensions.logstats] INFO: Crawled 5081 pages (at 109 pages/min), scraped 22 items (at 2 items/min)
2017-03-07 15:04:35 [scrapy.extensions.logstats] INFO: Crawled 5197 pages (at 116 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:05:34 [scrapy.extensions.logstats] INFO: Crawled 5348 pages (at 151 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:06:34 [scrapy.extensions.logstats] INFO: Crawled 5463 pages (at 115 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:07:37 [scrapy.extensions.logstats] INFO: Crawled 5506 pages (at 43 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:08:34 [scrapy.extensions.logstats] INFO: Crawled 5549 pages (at 43 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:09:34 [scrapy.extensions.logstats] INFO: Crawled 5596 pages (at 47 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:10:39 [scrapy.extensions.logstats] INFO: Crawled 5664 pages (at 68 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:11:36 [scrapy.extensions.logstats] INFO: Crawled 5710 pages (at 46 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:12:33 [scrapy.extensions.logstats] INFO: Crawled 5767 pages (at 57 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:13:33 [scrapy.extensions.logstats] INFO: Crawled 5830 pages (at 63 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:14:37 [scrapy.extensions.logstats] INFO: Crawled 5884 pages (at 54 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:15:35 [scrapy.extensions.logstats] INFO: Crawled 5938 pages (at 54 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:16:41 [scrapy.extensions.logstats] INFO: Crawled 5978 pages (at 40 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:17:34 [scrapy.extensions.logstats] INFO: Crawled 6028 pages (at 50 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:18:36 [scrapy.extensions.logstats] INFO: Crawled 6062 pages (at 34 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:19:37 [scrapy.extensions.logstats] INFO: Crawled 6120 pages (at 58 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:20:37 [scrapy.extensions.logstats] INFO: Crawled 6156 pages (at 36 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:21:39 [scrapy.extensions.logstats] INFO: Crawled 6180 pages (at 24 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:22:38 [scrapy.extensions.logstats] INFO: Crawled 6259 pages (at 79 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:23:36 [scrapy.extensions.logstats] INFO: Crawled 6299 pages (at 40 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:24:44 [scrapy.extensions.logstats] INFO: Crawled 6329 pages (at 30 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:25:34 [scrapy.extensions.logstats] INFO: Crawled 6374 pages (at 45 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:26:34 [scrapy.extensions.logstats] INFO: Crawled 6421 pages (at 47 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:27:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_374.shtml>: HTTP status code is not handled or not allowed
2017-03-07 15:27:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_323.shtml>: HTTP status code is not handled or not allowed
2017-03-07 15:27:36 [scrapy.extensions.logstats] INFO: Crawled 6481 pages (at 60 pages/min), scraped 22 items (at 0 items/min)
2017-03-07 15:27:50 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-07 15:27:50 [shanghai] INFO: get_webpage_count:22
2017-03-07 15:27:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 220,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 154,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 6,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 55,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 5,
 'downloader/request_bytes': 3697871,
 'downloader/request_count': 6739,
 'downloader/request_method_count/GET': 6739,
 'downloader/response_bytes': 110844851,
 'downloader/response_count': 6519,
 'downloader/response_status_count/200': 6301,
 'downloader/response_status_count/404': 200,
 'downloader/response_status_count/502': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 7, 7, 27, 50, 999540),
 'item_scraped_count': 22,
 'log_count/INFO': 277,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 6501,
 'scheduler/dequeued': 6739,
 'scheduler/dequeued/memory': 6739,
 'scheduler/enqueued': 6739,
 'scheduler/enqueued/memory': 6739,
 'start_time': datetime.datetime(2017, 3, 7, 6, 18, 33, 375933)}
2017-03-07 15:27:51 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-08 16:52:25 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-08 16:52:25 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-08 16:52:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-08 16:52:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-08 16:52:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-08 16:52:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-08 16:52:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-08 16:52:26 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-08 16:52:26 [scrapy.core.engine] INFO: Spider opened
2017-03-08 16:52:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-08 16:53:26 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 0 items (at 0 items/min)
2017-03-08 16:53:58 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-08 16:54:52 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-08 16:54:52 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-08 16:54:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-08 16:54:52 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-08 16:54:52 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-08 16:54:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-08 16:54:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-08 16:54:52 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-08 16:54:52 [scrapy.core.engine] INFO: Spider opened
2017-03-08 16:54:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-08 17:09:33 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-08 17:10:58 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-08 17:10:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-08 17:10:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-08 17:10:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-08 17:10:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-08 17:10:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-08 17:10:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-08 17:10:59 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-08 17:10:59 [scrapy.core.engine] INFO: Spider opened
2017-03-08 17:10:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-08 17:12:05 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 11:21:09 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 11:21:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 11:21:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 11:21:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 11:21:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 11:21:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 11:21:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 11:21:09 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 11:21:09 [scrapy.core.engine] INFO: Spider opened
2017-03-09 11:21:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 11:22:10 [scrapy.extensions.logstats] INFO: Crawled 81 pages (at 81 pages/min), scraped 240 items (at 240 items/min)
2017-03-09 11:23:04 [zhejiang] ERROR: save_time_error:time data ' ' does not match format '%Y-%m-%d'
2017-03-09 11:23:05 [zhejiang] ERROR: save_time_error:time data ' ' does not match format '%Y-%m-%d'
2017-03-09 11:23:52 [scrapy.extensions.logstats] INFO: Crawled 194 pages (at 113 pages/min), scraped 396 items (at 156 items/min)
2017-03-09 11:24:10 [scrapy.extensions.logstats] INFO: Crawled 232 pages (at 38 pages/min), scraped 930 items (at 534 items/min)
2017-03-09 11:25:10 [scrapy.extensions.logstats] INFO: Crawled 306 pages (at 74 pages/min), scraped 2037 items (at 1107 items/min)
2017-03-09 11:26:11 [scrapy.extensions.logstats] INFO: Crawled 376 pages (at 70 pages/min), scraped 3107 items (at 1070 items/min)
2017-03-09 11:26:19 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 11:27:20 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 11:27:20 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 11:27:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 11:27:20 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 11:27:20 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 11:27:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 11:27:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 11:27:20 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 11:27:20 [scrapy.core.engine] INFO: Spider opened
2017-03-09 11:27:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 11:32:23 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 1 items (at 1 items/min)
2017-03-09 11:38:41 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 13:37:32 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 13:37:32 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 13:37:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 13:37:32 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:37:32 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:37:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 13:37:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 13:37:32 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 13:37:32 [scrapy.core.engine] INFO: Spider opened
2017-03-09 13:37:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 13:39:22 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 13:43:43 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 13:43:43 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 13:43:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 13:43:43 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:43:43 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:43:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 13:43:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 13:43:44 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 13:43:44 [scrapy.core.engine] INFO: Spider opened
2017-03-09 13:43:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 13:44:50 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 13:45:57 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 13:45:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 13:45:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 13:45:57 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:45:57 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:45:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 13:45:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 13:45:57 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 13:45:57 [scrapy.core.engine] INFO: Spider opened
2017-03-09 13:45:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 13:46:31 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 13:46:32 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-09 13:47:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 13:47:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 13:47:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 13:47:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:47:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:47:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 13:47:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 13:47:36 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 13:47:36 [scrapy.core.engine] INFO: Spider opened
2017-03-09 13:47:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 13:48:20 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 13:48:27 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 13:48:27 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 13:48:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 13:48:27 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:48:27 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:48:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 13:48:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 13:48:27 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 13:48:27 [scrapy.core.engine] INFO: Spider opened
2017-03-09 13:48:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 13:49:28 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 13:59:20 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 13:59:30 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 13:59:30 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 13:59:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 13:59:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:59:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 13:59:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 13:59:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 13:59:30 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 13:59:30 [scrapy.core.engine] INFO: Spider opened
2017-03-09 13:59:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 14:04:16 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 1 items (at 1 items/min)
2017-03-09 14:09:02 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 14:09:30 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 14:09:30 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 14:09:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 14:09:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:09:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:09:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 14:09:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 14:09:31 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 14:09:31 [scrapy.core.engine] INFO: Spider opened
2017-03-09 14:09:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 14:09:55 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 14:12:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 14:12:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 14:12:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 14:12:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:12:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:12:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 14:12:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 14:12:08 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 14:12:08 [scrapy.core.engine] INFO: Spider opened
2017-03-09 14:12:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 14:12:51 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 14:13:46 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 14:13:46 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 14:13:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 14:13:46 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:13:46 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:13:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 14:13:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 14:13:46 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 14:13:46 [scrapy.core.engine] INFO: Spider opened
2017-03-09 14:13:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 14:35:34 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 1 items (at 1 items/min)
2017-03-09 14:36:03 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 0 pages/min), scraped 5 items (at 4 items/min)
2017-03-09 14:36:23 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 14:36:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 14:36:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 14:36:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 14:36:34 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:36:34 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:36:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 14:36:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 14:36:34 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 14:36:34 [scrapy.core.engine] INFO: Spider opened
2017-03-09 14:36:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 14:37:03 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 14:37:52 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 14:37:52 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 14:37:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 14:37:52 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:37:52 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:37:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 14:37:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 14:37:52 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 14:37:52 [scrapy.core.engine] INFO: Spider opened
2017-03-09 14:37:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 14:39:54 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 14:41:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 14:41:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 14:41:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 14:41:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:41:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:41:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 14:41:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 14:41:34 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 14:41:34 [scrapy.core.engine] INFO: Spider opened
2017-03-09 14:41:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 14:53:45 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 11 pages/min), scraped 5 items (at 5 items/min)
2017-03-09 14:53:54 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 14:54:01 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 14:54:01 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 14:54:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 14:54:01 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:54:01 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 14:54:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 14:54:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 14:54:01 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 14:54:01 [scrapy.core.engine] INFO: Spider opened
2017-03-09 14:54:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 15:05:17 [scrapy.extensions.logstats] INFO: Crawled 9 pages (at 9 pages/min), scraped 1 items (at 1 items/min)
2017-03-09 15:05:34 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 15:08:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 15:08:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 15:08:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 15:08:48 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 15:08:48 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 15:08:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 15:08:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 15:08:48 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 15:08:48 [scrapy.core.engine] INFO: Spider opened
2017-03-09 15:08:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 15:09:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://www.12333sh.gov.cn/201412333/xxgk/zcgg/index_313.shtml>: HTTP status code is not handled or not allowed
2017-03-09 15:17:50 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-09 15:27:40 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-09 15:27:40 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-09 15:27:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-09 15:27:40 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 15:27:40 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-09 15:27:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-09 15:27:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-09 15:27:40 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-09 15:27:40 [scrapy.core.engine] INFO: Spider opened
2017-03-09 15:27:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-09 15:28:34 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-20 18:05:22 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-20 18:05:22 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-20 18:05:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-20 18:05:22 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:05:22 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:05:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-20 18:05:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-20 18:05:23 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-20 18:05:23 [scrapy.core.engine] INFO: Spider opened
2017-03-20 18:05:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:05:38 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-20 18:05:38 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-20 18:06:00 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-20 18:06:00 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-20 18:06:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-20 18:06:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:06:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:06:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-20 18:06:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-20 18:06:00 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-20 18:06:00 [scrapy.core.engine] INFO: Spider opened
2017-03-20 18:06:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:06:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-20 18:06:01 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-20 18:06:01 [jiangsu] INFO: get_webpage_count:0
2017-03-20 18:06:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1557,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 20, 10, 6, 1, 141087),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 20, 10, 6, 0, 657032)}
2017-03-20 18:06:01 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-20 18:07:05 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-20 18:07:05 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-20 18:07:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-20 18:07:05 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:07:05 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:07:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-20 18:07:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-20 18:07:05 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-20 18:07:05 [scrapy.core.engine] INFO: Spider opened
2017-03-20 18:07:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:07:07 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:07 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:08 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:08 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-20 18:07:17 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:07:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:07:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:06 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-20 18:10:06 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-20 18:10:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-20 18:10:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:10:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:10:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-20 18:10:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-20 18:10:06 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-20 18:10:06 [scrapy.core.engine] INFO: Spider opened
2017-03-20 18:10:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:09 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:09 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-20 18:10:21 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:21 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:21 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:22 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:22 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:22 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:22 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:22 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:22 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:22 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:22 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:22 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:10:22 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:10:22 [jiangsu] INFO: get_webpage_count:0
2017-03-20 18:10:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 251521,
 'downloader/request_count': 312,
 'downloader/request_method_count/GET': 312,
 'downloader/response_bytes': 617447,
 'downloader/response_count': 312,
 'downloader/response_status_count/200': 312,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 20, 10, 10, 22, 94462),
 'log_count/ERROR': 480,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 312,
 'scheduler/dequeued': 312,
 'scheduler/dequeued/memory': 312,
 'scheduler/enqueued': 1220,
 'scheduler/enqueued/memory': 1220,
 'start_time': datetime.datetime(2017, 3, 20, 10, 10, 6, 881245)}
2017-03-20 18:10:22 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-20 18:10:40 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-20 18:10:40 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-20 18:10:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-20 18:10:40 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:10:40 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:10:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-20 18:10:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-20 18:10:40 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-20 18:10:40 [scrapy.core.engine] INFO: Spider opened
2017-03-20 18:10:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:10:52 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-20 18:10:52 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-20 18:10:59 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-20 18:10:59 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-20 18:10:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-20 18:10:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:10:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:10:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-20 18:10:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-20 18:10:59 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-20 18:10:59 [scrapy.core.engine] INFO: Spider opened
2017-03-20 18:10:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:11:30 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-20 18:11:30 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-20 18:11:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-20 18:11:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-20 18:11:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-20 18:11:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:11:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:11:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-20 18:11:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-20 18:11:34 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-20 18:11:34 [scrapy.core.engine] INFO: Spider opened
2017-03-20 18:11:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:11:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:38 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:38 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:39 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:39 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:40 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:40 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:41 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:41 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:42 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:42 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:43 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:43 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:44 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:44 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:45 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:45 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:46 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:46 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:47 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:47 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:48 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:48 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:49 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:49 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:11:50 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:11:50 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:20 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:12:20 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:12:49 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-20 18:13:52 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-20 18:13:52 [scrapy.extensions.logstats] INFO: Crawled 653 pages (at 653 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:13:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:13:52 [jiangsu] INFO: get_webpage_count:0
2017-03-20 18:13:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 530793,
 'downloader/request_count': 662,
 'downloader/request_method_count/GET': 662,
 'downloader/response_bytes': 1272155,
 'downloader/response_count': 662,
 'downloader/response_status_count/200': 662,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 20, 10, 13, 52, 358754),
 'log_count/ERROR': 728,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 2,
 'response_received_count': 662,
 'scheduler/dequeued': 662,
 'scheduler/dequeued/memory': 662,
 'scheduler/enqueued': 1564,
 'scheduler/enqueued/memory': 1564,
 'start_time': datetime.datetime(2017, 3, 20, 10, 11, 34, 140330)}
2017-03-20 18:13:52 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-20 18:14:06 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-20 18:14:06 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-20 18:14:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-20 18:14:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:14:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-20 18:14:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-20 18:14:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-20 18:14:06 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-20 18:14:06 [scrapy.core.engine] INFO: Spider opened
2017-03-20 18:14:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:10 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:10 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:11 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:11 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:12 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:12 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:13 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:13 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:14 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:14 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:15 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:15 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:16 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:16 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:17 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:17 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:18 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:18 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:19 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:19 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:52 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:53 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:53 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:54 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:54 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:55 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:55 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:56 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:56 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:57 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:57 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:58 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:58 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:14:59 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:14:59 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:00 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:00 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:01 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:01 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:02 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:02 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:02 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:02 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:02 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:02 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:02 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:02 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:02 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:02 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:02 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:02 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:03 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:03 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:04 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:04 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:15:05 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-20 18:15:05 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-20 18:40:37 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 09:57:27 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 09:57:27 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 09:57:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 09:57:27 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 09:57:27 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 09:57:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 09:57:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 09:57:27 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 09:57:27 [scrapy.core.engine] INFO: Spider opened
2017-03-21 09:57:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 09:57:30 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:30 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:30 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:30 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:30 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:30 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:30 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:30 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:30 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:30 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:31 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:31 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:32 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:32 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:33 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:33 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:34 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:34 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:35 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:35 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:36 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:36 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 09:57:37 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:37 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:57:37 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:57:52 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 09:57:52 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 09:57:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 09:57:52 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 09:57:52 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 09:57:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 09:57:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 09:57:52 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 09:57:52 [scrapy.core.engine] INFO: Spider opened
2017-03-21 09:57:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 09:58:52 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 09:59:29 [jiangsu] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 09:59:29 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 26 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 10:00:26 [jiangsu] ERROR: save_time_error:unconverted data remains:  
2017-03-21 10:05:01 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 10:05:12 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 10:05:12 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 10:05:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 10:05:12 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 10:05:12 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 10:05:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 10:05:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 10:05:12 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 10:05:12 [scrapy.core.engine] INFO: Spider opened
2017-03-21 10:05:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 10:06:12 [scrapy.extensions.logstats] INFO: Crawled 421 pages (at 421 pages/min), scraped 225 items (at 225 items/min)
2017-03-21 10:07:12 [scrapy.extensions.logstats] INFO: Crawled 421 pages (at 0 pages/min), scraped 225 items (at 0 items/min)
2017-03-21 10:08:12 [scrapy.extensions.logstats] INFO: Crawled 421 pages (at 0 pages/min), scraped 225 items (at 0 items/min)
2017-03-21 10:09:12 [scrapy.extensions.logstats] INFO: Crawled 1102 pages (at 681 pages/min), scraped 865 items (at 640 items/min)
2017-03-21 10:10:12 [scrapy.extensions.logstats] INFO: Crawled 2186 pages (at 1084 pages/min), scraped 1890 items (at 1025 items/min)
2017-03-21 10:11:12 [scrapy.extensions.logstats] INFO: Crawled 2504 pages (at 318 pages/min), scraped 2190 items (at 300 items/min)
2017-03-21 10:12:12 [scrapy.extensions.logstats] INFO: Crawled 2504 pages (at 0 pages/min), scraped 2190 items (at 0 items/min)
2017-03-21 10:13:12 [scrapy.extensions.logstats] INFO: Crawled 2504 pages (at 0 pages/min), scraped 2190 items (at 0 items/min)
2017-03-21 10:14:13 [scrapy.extensions.logstats] INFO: Crawled 2564 pages (at 60 pages/min), scraped 2225 items (at 35 items/min)
2017-03-21 10:15:13 [scrapy.extensions.logstats] INFO: Crawled 2863 pages (at 299 pages/min), scraped 2528 items (at 303 items/min)
2017-03-21 10:16:12 [scrapy.extensions.logstats] INFO: Crawled 3097 pages (at 234 pages/min), scraped 2742 items (at 214 items/min)
2017-03-21 10:17:12 [scrapy.extensions.logstats] INFO: Crawled 3461 pages (at 364 pages/min), scraped 3083 items (at 341 items/min)
2017-03-21 10:18:12 [scrapy.extensions.logstats] INFO: Crawled 3824 pages (at 363 pages/min), scraped 3437 items (at 354 items/min)
2017-03-21 10:19:12 [scrapy.extensions.logstats] INFO: Crawled 4276 pages (at 452 pages/min), scraped 3860 items (at 423 items/min)
2017-03-21 10:20:14 [scrapy.extensions.logstats] INFO: Crawled 5018 pages (at 742 pages/min), scraped 4559 items (at 699 items/min)
2017-03-21 10:21:12 [scrapy.extensions.logstats] INFO: Crawled 5272 pages (at 254 pages/min), scraped 4797 items (at 238 items/min)
2017-03-21 10:22:12 [scrapy.extensions.logstats] INFO: Crawled 5272 pages (at 0 pages/min), scraped 4797 items (at 0 items/min)
2017-03-21 10:23:12 [scrapy.extensions.logstats] INFO: Crawled 5525 pages (at 253 pages/min), scraped 5047 items (at 250 items/min)
2017-03-21 10:24:12 [scrapy.extensions.logstats] INFO: Crawled 6118 pages (at 593 pages/min), scraped 5598 items (at 551 items/min)
2017-03-21 10:25:13 [scrapy.extensions.logstats] INFO: Crawled 6533 pages (at 415 pages/min), scraped 5998 items (at 400 items/min)
2017-03-21 10:26:37 [scrapy.extensions.logstats] INFO: Crawled 6675 pages (at 142 pages/min), scraped 6142 items (at 144 items/min)
2017-03-21 10:27:12 [scrapy.extensions.logstats] INFO: Crawled 6977 pages (at 302 pages/min), scraped 6417 items (at 275 items/min)
2017-03-21 10:28:12 [scrapy.extensions.logstats] INFO: Crawled 7903 pages (at 926 pages/min), scraped 7304 items (at 887 items/min)
2017-03-21 10:29:12 [scrapy.extensions.logstats] INFO: Crawled 8897 pages (at 994 pages/min), scraped 8257 items (at 953 items/min)
2017-03-21 10:30:12 [scrapy.extensions.logstats] INFO: Crawled 9944 pages (at 1047 pages/min), scraped 9246 items (at 989 items/min)
2017-03-21 10:31:12 [scrapy.extensions.logstats] INFO: Crawled 10394 pages (at 450 pages/min), scraped 9678 items (at 432 items/min)
2017-03-21 10:32:12 [scrapy.extensions.logstats] INFO: Crawled 11048 pages (at 654 pages/min), scraped 10308 items (at 630 items/min)
2017-03-21 10:33:12 [scrapy.extensions.logstats] INFO: Crawled 11414 pages (at 366 pages/min), scraped 10662 items (at 354 items/min)
2017-03-21 10:34:12 [scrapy.extensions.logstats] INFO: Crawled 11895 pages (at 481 pages/min), scraped 11118 items (at 456 items/min)
2017-03-21 10:35:12 [scrapy.extensions.logstats] INFO: Crawled 12731 pages (at 836 pages/min), scraped 11850 items (at 732 items/min)
2017-03-21 10:36:12 [scrapy.extensions.logstats] INFO: Crawled 13103 pages (at 372 pages/min), scraped 12212 items (at 362 items/min)
2017-03-21 10:37:12 [scrapy.extensions.logstats] INFO: Crawled 13103 pages (at 0 pages/min), scraped 12212 items (at 0 items/min)
2017-03-21 10:38:12 [scrapy.extensions.logstats] INFO: Crawled 13103 pages (at 0 pages/min), scraped 12212 items (at 0 items/min)
2017-03-21 10:39:12 [scrapy.extensions.logstats] INFO: Crawled 13462 pages (at 359 pages/min), scraped 12561 items (at 349 items/min)
2017-03-21 10:39:31 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 10:39:31 [jiangsu] INFO: get_webpage_count:12707
2017-03-21 10:39:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2129,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 2018,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 50,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 36,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 25,
 'downloader/request_bytes': 12794650,
 'downloader/request_count': 15736,
 'downloader/request_method_count/GET': 15736,
 'downloader/response_bytes': 27850428,
 'downloader/response_count': 13607,
 'downloader/response_status_count/200': 13607,
 'dupefilter/filtered': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 2, 39, 31, 624596),
 'item_scraped_count': 12707,
 'log_count/INFO': 42,
 'log_count/WARNING': 2,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 2,
 'response_received_count': 13607,
 'scheduler/dequeued': 15736,
 'scheduler/dequeued/memory': 15736,
 'scheduler/enqueued': 15736,
 'scheduler/enqueued/memory': 15736,
 'start_time': datetime.datetime(2017, 3, 21, 2, 5, 12, 664421)}
2017-03-21 10:39:31 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 11:11:52 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 11:11:52 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 11:11:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 11:11:52 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 11:11:52 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 11:11:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 11:11:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 11:11:52 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 11:11:52 [scrapy.core.engine] INFO: Spider opened
2017-03-21 11:11:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 11:12:50 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 11:12:50 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 11:18:23 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 11:18:23 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 11:18:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 11:18:23 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 11:18:23 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 11:18:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 11:18:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 11:18:23 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 11:18:23 [scrapy.core.engine] INFO: Spider opened
2017-03-21 11:18:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 11:18:51 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 11:18:51 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 11:21:16 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 11:21:16 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 11:21:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 11:21:17 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 11:21:17 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 11:21:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 11:21:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 11:21:17 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 11:21:17 [scrapy.core.engine] INFO: Spider opened
2017-03-21 11:21:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 11:22:17 [scrapy.extensions.logstats] INFO: Crawled 685 pages (at 685 pages/min), scraped 381 items (at 381 items/min)
2017-03-21 11:23:17 [scrapy.extensions.logstats] INFO: Crawled 1358 pages (at 673 pages/min), scraped 1018 items (at 637 items/min)
2017-03-21 11:24:17 [scrapy.extensions.logstats] INFO: Crawled 2033 pages (at 675 pages/min), scraped 1673 items (at 655 items/min)
2017-03-21 11:25:17 [scrapy.extensions.logstats] INFO: Crawled 2635 pages (at 602 pages/min), scraped 2233 items (at 560 items/min)
2017-03-21 11:26:17 [scrapy.extensions.logstats] INFO: Crawled 2936 pages (at 301 pages/min), scraped 2542 items (at 309 items/min)
2017-03-21 11:27:17 [scrapy.extensions.logstats] INFO: Crawled 2936 pages (at 0 pages/min), scraped 2542 items (at 0 items/min)
2017-03-21 11:28:17 [scrapy.extensions.logstats] INFO: Crawled 2936 pages (at 0 pages/min), scraped 2542 items (at 0 items/min)
2017-03-21 11:29:19 [scrapy.extensions.logstats] INFO: Crawled 3200 pages (at 264 pages/min), scraped 2768 items (at 226 items/min)
2017-03-21 11:30:17 [scrapy.extensions.logstats] INFO: Crawled 3675 pages (at 475 pages/min), scraped 3234 items (at 466 items/min)
2017-03-21 11:31:17 [scrapy.extensions.logstats] INFO: Crawled 3929 pages (at 254 pages/min), scraped 3471 items (at 237 items/min)
2017-03-21 11:32:17 [scrapy.extensions.logstats] INFO: Crawled 3929 pages (at 0 pages/min), scraped 3471 items (at 0 items/min)
2017-03-21 11:33:17 [scrapy.extensions.logstats] INFO: Crawled 4365 pages (at 436 pages/min), scraped 3888 items (at 417 items/min)
2017-03-21 11:34:17 [scrapy.extensions.logstats] INFO: Crawled 5097 pages (at 732 pages/min), scraped 4585 items (at 697 items/min)
2017-03-21 11:35:17 [scrapy.extensions.logstats] INFO: Crawled 6014 pages (at 917 pages/min), scraped 5464 items (at 879 items/min)
2017-03-21 11:36:17 [scrapy.extensions.logstats] INFO: Crawled 6259 pages (at 245 pages/min), scraped 5694 items (at 230 items/min)
2017-03-21 12:57:07 [scrapy.extensions.logstats] INFO: Crawled 6259 pages (at 0 pages/min), scraped 5694 items (at 0 items/min)
2017-03-21 12:57:17 [scrapy.extensions.logstats] INFO: Crawled 6259 pages (at 0 pages/min), scraped 5694 items (at 0 items/min)
2017-03-21 12:58:17 [scrapy.extensions.logstats] INFO: Crawled 6259 pages (at 0 pages/min), scraped 5694 items (at 0 items/min)
2017-03-21 12:59:21 [scrapy.extensions.logstats] INFO: Crawled 6956 pages (at 697 pages/min), scraped 6344 items (at 650 items/min)
2017-03-21 13:00:17 [scrapy.extensions.logstats] INFO: Crawled 7745 pages (at 789 pages/min), scraped 7108 items (at 764 items/min)
2017-03-21 13:01:17 [scrapy.extensions.logstats] INFO: Crawled 8030 pages (at 285 pages/min), scraped 7383 items (at 275 items/min)
2017-03-21 13:02:17 [scrapy.extensions.logstats] INFO: Crawled 8342 pages (at 312 pages/min), scraped 7675 items (at 292 items/min)
2017-03-21 13:03:17 [scrapy.extensions.logstats] INFO: Crawled 8734 pages (at 392 pages/min), scraped 8049 items (at 374 items/min)
2017-03-21 13:04:17 [scrapy.extensions.logstats] INFO: Crawled 9270 pages (at 536 pages/min), scraped 8555 items (at 506 items/min)
2017-03-21 13:05:17 [scrapy.extensions.logstats] INFO: Crawled 10178 pages (at 908 pages/min), scraped 9415 items (at 860 items/min)
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005673>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005674>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005670>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005671>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005672>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005652>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005669>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005667>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005668>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005655>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005665>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005651>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005664>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005666>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005663>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005653>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005660>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010005513>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005650>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010005529>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005675>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005676>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010005514>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010005511>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010005532>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010005494>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010005530>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010005535>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010005539>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010005534>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010005533>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010005531>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010005540>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010005544>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010005538>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010005537>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32030010005542>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010005545>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:06:17 [scrapy.extensions.logstats] INFO: Crawled 10573 pages (at 395 pages/min), scraped 9791 items (at 376 items/min)
2017-03-21 13:07:17 [scrapy.extensions.logstats] INFO: Crawled 10573 pages (at 0 pages/min), scraped 9791 items (at 0 items/min)
2017-03-21 13:08:17 [scrapy.extensions.logstats] INFO: Crawled 10573 pages (at 0 pages/min), scraped 9791 items (at 0 items/min)
2017-03-21 13:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010005470>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010005470 took longer than 180.0 seconds..
2017-03-21 13:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005662>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005662 took longer than 180.0 seconds..
2017-03-21 13:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005546>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005546 took longer than 180.0 seconds..
2017-03-21 13:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010005549>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010005549 took longer than 180.0 seconds..
2017-03-21 13:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010005547>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010005547 took longer than 180.0 seconds..
2017-03-21 13:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010005548>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010005548 took longer than 180.0 seconds..
2017-03-21 13:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010005553>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010005553 took longer than 180.0 seconds..
2017-03-21 13:09:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005661>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010005661 took longer than 180.0 seconds..
2017-03-21 13:09:17 [scrapy.extensions.logstats] INFO: Crawled 10798 pages (at 225 pages/min), scraped 10013 items (at 222 items/min)
2017-03-21 13:10:17 [scrapy.extensions.logstats] INFO: Crawled 11320 pages (at 522 pages/min), scraped 10495 items (at 482 items/min)
2017-03-21 13:11:17 [scrapy.extensions.logstats] INFO: Crawled 11624 pages (at 304 pages/min), scraped 10801 items (at 306 items/min)
2017-03-21 13:12:17 [scrapy.extensions.logstats] INFO: Crawled 11624 pages (at 0 pages/min), scraped 10801 items (at 0 items/min)
2017-03-21 13:13:17 [scrapy.extensions.logstats] INFO: Crawled 11624 pages (at 0 pages/min), scraped 10801 items (at 0 items/min)
2017-03-21 13:14:17 [scrapy.extensions.logstats] INFO: Crawled 11624 pages (at 0 pages/min), scraped 10801 items (at 0 items/min)
2017-03-21 13:15:17 [scrapy.extensions.logstats] INFO: Crawled 11976 pages (at 352 pages/min), scraped 11134 items (at 333 items/min)
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007270>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007274>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007273>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007271>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007272>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010007280>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007269>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007263>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007268>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010007279>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007265>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007267>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010007151>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007154>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010007149>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007155>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007153>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007266>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007150>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010007156>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007157>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007159>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007163>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007264>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010007162>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010007165>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007164>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007168>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007167>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007169>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007166>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007197>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007160>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007170>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007171>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007199>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007202>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007203>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007201>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007204>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007207>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007205>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32030010007210>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007211>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010007206>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010006098>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007213>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007214>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007216>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010007215>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010006099>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010007172>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007218>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007217>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007174>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007161>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007173>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007177>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007175>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007180>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007176>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007183>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007178>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007182>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010007187>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010007188>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010007190>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010007189>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007186>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007179>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007191>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007226>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010007195>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007223>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010007192>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007220>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007219>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007227>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007221>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007224>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007198>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007230>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007229>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007212>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007231>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007228>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007232>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010007234>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010007233>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007235>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007236>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007239>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007237>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010007244>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007242>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32030010007241>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010007245>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007184>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007185>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007247>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007243>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007248>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007246>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007249>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007254>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007250>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007251>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010007256>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007252>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007253>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007209>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007208>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007129>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007128>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007130>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007132>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007131>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010007139>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007134>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007136>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007138>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007133>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007135>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007140>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007142>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007137>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010007143>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010007141>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010007144>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007084>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010007148>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007085>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007146>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007086>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007110>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010007147>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007087>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010007089>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007112>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007114>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010007111>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010007116>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007113>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010007117>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007119>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007123>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007115>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007124>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007118>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007125>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010007062>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007127>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007126>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007068>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007067>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007024>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007070>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007073>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007069>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007076>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010007072>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007075>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007078>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007077>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007080>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010007079>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007071>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007083>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007082>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007000>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007081>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010006998>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010007011>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007013>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007009>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007010>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010006999>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010006996>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007007>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010007008>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010007002>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007004>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010007005>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010007001>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007003>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=308>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=303>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=311>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=306>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=305>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=304>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=310>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=302>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=301>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=298>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=300>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=299>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=295>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=296>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=297>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=292>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=293>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=294>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=287>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=289>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=290>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=288>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=291>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=285>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=286>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=282>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=283>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=281>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=284>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=280>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=278>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=279>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=276>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=275>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=277>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=273>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=270>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=274>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=272>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008434>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=271>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticeList.action?page.page=269>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008440>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008469>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010008426>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008441>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008436>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008437>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008442>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008472>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008435>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008470>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008476>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008477>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008439>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008473>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008528>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008459>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008479>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008478>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008485>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008480>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008482>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008530>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008481>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008529>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010008533>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008532>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008534>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008531>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010007806>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008539>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008540>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008538>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008541>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010008537>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008197>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010008535>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008196>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008544>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010008536>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008543>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010008545>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:15:59 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008542>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008443>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008446>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008445>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008444>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010008448>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008450>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010008453>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010008454>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010008449>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010008455>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010008447>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010008457>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010008456>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008452>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010008458>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008464>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008463>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008461>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008460>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008462>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008644>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008636>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008616>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008656>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008659>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008615>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008657>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008617>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008638>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008660>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008630>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008640>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008661>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008637>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008632>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008639>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008647>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008646>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008642>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008549>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:00 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008548>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008648>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008546>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008552>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010008547>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008550>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008551>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008553>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008557>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008555>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008554>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008562>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008558>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008556>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010008567>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32100010008568>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010008566>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008570>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010008592>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008563>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010008591>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008569>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010008593>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008596>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010008590>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008597>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008595>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008598>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008603>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010008600>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008604>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008606>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008599>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32090010008608>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008605>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008609>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008574>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010008612>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:02 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008611>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008575>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008573>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010008614>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32110010008613>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008577>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008576>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008579>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008578>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008583>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008581>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008584>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008582>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008586>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008585>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008580>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008621>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008588>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010008623>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008587>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008594>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008624>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008619>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32120010008589>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008634>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008631>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008618>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32060010008625>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010008633>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32070010008622>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010008626>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010008627>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008652>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008654>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32130010008629>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008645>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32140010008653>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32040010008655>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008643>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008717>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008635>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32080010008715>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 13:16:17 [scrapy.extensions.logstats] INFO: Crawled 12373 pages (at 397 pages/min), scraped 11514 items (at 380 items/min)
2017-03-21 13:17:17 [scrapy.extensions.logstats] INFO: Crawled 12373 pages (at 0 pages/min), scraped 11514 items (at 0 items/min)
2017-03-21 13:18:17 [scrapy.extensions.logstats] INFO: Crawled 12373 pages (at 0 pages/min), scraped 11514 items (at 0 items/min)
2017-03-21 13:19:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008665>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008665 took longer than 180.0 seconds..
2017-03-21 13:19:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008711>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32020010008711 took longer than 180.0 seconds..
2017-03-21 13:19:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008714>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/handlers/http11.py", line 306, in _cb_timeout
    raise TimeoutError("Getting %s took longer than %s seconds." % (url, timeout))
twisted.internet.error.TimeoutError: User timeout caused connection failure: Getting http://ggfw.jshrss.gov.cn/UnifiedPublicServicePlatform/business/ldjc/toArbitrationNoticePage.action?arbitrationNoticeVO.eed800=32050010008714 took longer than 180.0 seconds..
2017-03-21 13:19:04 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 13:19:04 [jiangsu] INFO: get_webpage_count:11518
2017-03-21 13:19:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2913,
 'downloader/exception_type_count/requests.exceptions.ConnectionError': 30,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 2786,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 29,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 46,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 22,
 'downloader/request_bytes': 12405291,
 'downloader/request_count': 15260,
 'downloader/request_method_count/GET': 15260,
 'downloader/response_bytes': 25240506,
 'downloader/response_count': 12377,
 'downloader/response_status_count/200': 12377,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 5, 19, 4, 121821),
 'item_scraped_count': 11518,
 'log_count/ERROR': 438,
 'log_count/INFO': 46,
 'log_count/WARNING': 2,
 'offsite/domains': 1,
 'offsite/filtered': 1,
 'request_depth_max': 2,
 'response_received_count': 12377,
 'scheduler/dequeued': 15290,
 'scheduler/dequeued/memory': 15290,
 'scheduler/enqueued': 15290,
 'scheduler/enqueued/memory': 15290,
 'start_time': datetime.datetime(2017, 3, 21, 3, 21, 17, 231386)}
2017-03-21 13:19:04 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:08:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:08:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:08:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:08:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:08:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:08:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:08:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:08:09 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:08:09 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:08:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:08:10 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 15:08:10 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:08:10 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:08:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1437,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 8, 10, 829199),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 7, 8, 9, 130338)}
2017-03-21 15:08:10 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:08:59 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:08:59 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:08:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:08:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:08:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:09:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:09:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:09:00 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:09:00 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:09:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:09:05 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:09:05 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:09:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 31230,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 823973,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 9, 5, 399468),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 9, 0, 176029)}
2017-03-21 15:09:05 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:11:09 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:11:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:11:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:11:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:11:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:11:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:11:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:11:09 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:11:09 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:11:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:11:21 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:11:21 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 15:11:27 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:11:27 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:11:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:11:27 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:11:27 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:11:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:11:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:11:28 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:11:28 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:11:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:11:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:11:32 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:11:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 31233,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 823973,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 11, 32, 280211),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 11, 28, 31500)}
2017-03-21 15:11:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:14:12 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:14:12 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:14:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:14:12 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:14:12 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:14:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:14:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:14:12 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:14:12 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:14:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:15:13 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:15:16 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:15:38 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:15:38 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:15:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:15:39 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:15:39 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:15:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:15:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:15:39 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:15:39 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:15:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:15:43 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 15:15:44 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:15:44 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:15:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1464,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 15, 44, 18020),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 7, 15, 39, 477220)}
2017-03-21 15:15:44 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:16:00 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:16:00 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:16:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:16:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:16:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:16:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:16:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:16:00 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:16:00 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:16:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:16:44 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:16:44 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 15:16:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:16:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:16:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:16:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:16:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:16:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:16:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:16:48 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:16:48 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:16:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:17:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:17:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:18:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:18:22 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:18:22 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:18:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 31246,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 823973,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 18, 22, 722243),
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 16, 48, 236269)}
2017-03-21 15:18:22 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:18:55 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:18:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:18:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:18:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:18:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:18:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:18:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:18:55 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:18:55 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:18:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:18:59 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:18:59 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:18:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 29798,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 824764,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 18, 59, 144621),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 18, 55, 370583)}
2017-03-21 15:18:59 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:19:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:19:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:19:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:19:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:19:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:19:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:19:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:19:08 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:19:08 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:19:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:19:11 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:19:11 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:19:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 28198,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 800488,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 19, 11, 252513),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 19, 8, 521815)}
2017-03-21 15:19:11 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:20:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:20:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:20:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:20:48 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:20:48 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:20:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:20:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:20:48 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:20:48 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:20:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:20:48 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 15:20:48 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:20:48 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:20:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1185,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 20, 48, 730526),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 7, 20, 48, 190136)}
2017-03-21 15:20:48 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:20:55 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:20:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:20:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:20:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:20:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:20:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:20:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:20:55 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:20:55 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:20:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:20:56 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-03-21 15:20:56 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:20:56 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:20:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1206,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 20, 56, 263606),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 7, 20, 55, 613653)}
2017-03-21 15:20:56 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:21:07 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:21:07 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:21:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:21:07 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:21:07 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:21:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:21:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:21:07 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:21:07 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:21:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:21:32 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:21:32 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 15:21:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:21:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:21:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:21:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:21:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:21:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:21:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:21:37 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:21:37 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:21:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:21:43 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:21:43 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:21:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 28049,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 800488,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 21, 43, 133063),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 21, 37, 65609)}
2017-03-21 15:21:43 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:22:03 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:22:03 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:22:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:22:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:22:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:22:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:22:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:22:04 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:22:04 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:22:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:22:07 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:22:07 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:22:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 26977,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 800488,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 22, 7, 368467),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 22, 4, 151939)}
2017-03-21 15:22:07 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:24:58 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:24:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:24:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:24:58 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:24:58 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:24:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:24:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:24:59 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:24:59 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:24:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:25:01 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:25:01 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:25:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 26987,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 800488,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 25, 1, 923908),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 24, 59, 124616)}
2017-03-21 15:25:01 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:25:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:25:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:25:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:25:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:25:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:25:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:25:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:25:33 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:25:33 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:25:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:25:36 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:25:36 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:25:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 27999,
 'downloader/request_count': 50,
 'downloader/request_method_count/GET': 50,
 'downloader/response_bytes': 800488,
 'downloader/response_count': 50,
 'downloader/response_status_count/200': 50,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 25, 36, 33184),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 50,
 'scheduler/dequeued': 50,
 'scheduler/dequeued/memory': 50,
 'scheduler/enqueued': 50,
 'scheduler/enqueued/memory': 50,
 'start_time': datetime.datetime(2017, 3, 21, 7, 25, 33, 567596)}
2017-03-21 15:25:36 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:26:04 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:26:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:26:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:26:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:26:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:26:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:26:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:26:04 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:26:04 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:26:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:26:50 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:26:50 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 15:26:53 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:26:53 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:26:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:26:53 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:26:53 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:26:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:26:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:26:53 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:26:53 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:26:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:27:54 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:28:47 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:28:47 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 15:31:51 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:31:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:31:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:31:51 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:31:51 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:31:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:31:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:31:52 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:31:52 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:31:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:31:54 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 15:31:54 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:31:54 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:31:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1446,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 31, 54, 887623),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 7, 31, 52, 69605)}
2017-03-21 15:31:54 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:31:58 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:31:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:31:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:31:58 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:31:58 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:31:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:31:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:31:58 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:31:58 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:31:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:32:01 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 15:32:01 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:32:01 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:32:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 32, 1, 235338),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 7, 31, 58, 604596)}
2017-03-21 15:32:01 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:32:05 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:32:05 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:32:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:32:05 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:32:05 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:32:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:32:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:32:05 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:32:05 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:32:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:32:21 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:32:21 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 15:32:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:32:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:32:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:32:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:32:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:32:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:32:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:32:25 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:32:25 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:32:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:32:34 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:32:34 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 15:32:42 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:32:42 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:32:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:32:42 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:32:42 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:32:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:32:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:32:43 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:32:43 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:32:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:32:46 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 15:32:46 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:32:46 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:32:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 32, 46, 317011),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 7, 32, 43, 92388)}
2017-03-21 15:32:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:33:00 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:33:00 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:33:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:33:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:33:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:33:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:33:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:33:00 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:33:00 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:33:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:33:03 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 15:33:03 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 15:33:03 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 15:33:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1434,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 7, 33, 3, 487038),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 7, 33, 0, 326096)}
2017-03-21 15:33:03 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 15:38:55 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:38:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:38:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:38:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:38:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:38:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:38:55 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:38:55 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:38:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:39:49 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 15:39:49 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 15:40:00 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 15:40:00 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 15:40:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 15:40:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 15:40:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 15:40:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 15:40:01 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 15:40:01 [scrapy.core.engine] INFO: Spider opened
2017-03-21 15:40:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:47:15 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 2 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 15:48:19 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:14:57 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:15:00 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:15:00 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:15:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:15:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:15:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:15:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:15:00 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:15:00 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:15:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:15:18 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:15:18 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 16:15:22 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:15:22 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:15:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:15:22 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:15:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:15:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:15:23 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:15:23 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:15:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:15:25 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:15:25 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 16:15:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:15:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:15:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:15:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:15:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:15:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:15:36 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:15:36 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:15:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:15:42 [heilongjiang] ERROR: save_time_error:time data '' does not match format '%Y-%m-%d'
2017-03-21 16:15:42 [heilongjiang] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 16:15:43 [heilongjiang] ERROR: save_time_error:time data '' does not match format '%Y-%m-%d'
2017-03-21 16:15:43 [heilongjiang] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 16:15:44 [heilongjiang] ERROR: save_time_error:time data '' does not match format '%Y-%m-%d'
2017-03-21 16:15:44 [heilongjiang] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 16:15:45 [heilongjiang] ERROR: save_time_error:time data '' does not match format '%Y-%m-%d'
2017-03-21 16:15:45 [heilongjiang] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 16:15:46 [heilongjiang] ERROR: save_time_error:time data '' does not match format '%Y-%m-%d'
2017-03-21 16:15:46 [heilongjiang] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 16:15:50 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:15:50 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 16:16:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:16:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:16:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:16:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:16:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:16:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:16:09 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:16:09 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:16:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:31:42 [heilongjiang] ERROR: save_time_error:time data '' does not match format '%Y-%m-%d'
2017-03-21 16:31:42 [heilongjiang] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 16:31:42 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:32:04 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:32:04 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 16:32:10 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:32:10 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:32:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:32:10 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:32:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:32:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:32:11 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:32:11 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:32:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:36:42 [heilongjiang] ERROR: save_time_error:time data '' does not match format '%Y-%m-%d'
2017-03-21 16:36:51 [heilongjiang] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 16:36:51 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:38:20 [heilongjiang] ERROR: save_time_error:time data '' does not match format '%Y-%m-%d'
2017-03-21 16:38:20 [heilongjiang] ERROR: parse_webpage_error:local variable 'time_get' referenced before assignment
2017-03-21 16:38:20 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:38:31 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:38:31 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 16:38:38 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:38:38 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:38:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:38:38 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:38:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:38:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:38:38 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:38:38 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:38:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:38:41 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 16:38:41 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 16:38:41 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 16:38:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1446,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 8, 38, 41, 720522),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 8, 38, 38, 732605)}
2017-03-21 16:38:41 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 16:38:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:38:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:38:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:38:49 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:38:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:38:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:38:50 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:38:50 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:38:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:38:52 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 16:38:53 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 16:38:53 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 16:38:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 8, 38, 53, 3772),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 8, 38, 50, 38988)}
2017-03-21 16:38:53 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 16:39:29 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:39:29 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:39:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:39:29 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:39:29 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:39:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:39:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:39:29 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:39:29 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:39:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:39:33 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 16:39:33 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 16:39:33 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 16:39:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1446,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 8, 39, 33, 225173),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 8, 39, 29, 788986)}
2017-03-21 16:39:33 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 16:39:53 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:39:53 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:39:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:39:53 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:39:53 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:39:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:39:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:39:54 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:39:54 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:39:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:39:57 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-21 16:39:57 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 16:39:57 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 16:39:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1434,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 8, 39, 57, 207985),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 21, 8, 39, 54, 12030)}
2017-03-21 16:39:57 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 16:40:11 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:40:11 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:40:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:40:11 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:40:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:40:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:40:11 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:40:11 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:40:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:53:07 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:53:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:53:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:53:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:53:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:53:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:53:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:53:14 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:53:14 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:53:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:53:57 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:53:57 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 16:56:21 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:56:21 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'CONCURRENT_REQUESTS_PER_DOMAIN': 1, 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:56:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:56:21 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:56:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:56:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:56:22 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:56:22 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:56:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:56:22 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 16:56:22 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 16:56:45 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 16:56:45 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 16:56:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 16:56:45 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 16:56:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 16:56:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 16:56:45 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 16:56:45 [scrapy.core.engine] INFO: Spider opened
2017-03-21 16:56:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 16:56:53 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-21 16:56:53 [heilongjiang] INFO: get_webpage_count:93
2017-03-21 16:56:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 57603,
 'downloader/request_count': 98,
 'downloader/request_method_count/GET': 98,
 'downloader/response_bytes': 1051430,
 'downloader/response_count': 98,
 'downloader/response_status_count/200': 98,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 21, 8, 56, 53, 328065),
 'item_scraped_count': 93,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 98,
 'scheduler/dequeued': 98,
 'scheduler/dequeued/memory': 98,
 'scheduler/enqueued': 98,
 'scheduler/enqueued/memory': 98,
 'start_time': datetime.datetime(2017, 3, 21, 8, 56, 45, 756034)}
2017-03-21 16:56:53 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-21 17:10:55 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 17:10:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 17:10:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 17:10:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 17:10:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 17:10:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 17:10:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 17:10:55 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 17:10:55 [scrapy.core.engine] INFO: Spider opened
2017-03-21 17:10:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 17:11:21 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 17:11:21 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 17:11:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 17:11:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 17:11:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 17:11:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 17:11:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 17:11:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 17:11:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 17:11:24 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 17:11:24 [scrapy.core.engine] INFO: Spider opened
2017-03-21 17:11:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 17:11:30 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 17:11:30 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-21 17:11:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 17:12:12 [heilongjiang] INFO: get_webpage_count:0
2017-03-21 17:12:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 1,
 'downloader/request_bytes': 475,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 21, 9, 12, 12, 50936),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 3, 21, 9, 10, 55, 568148)}
2017-03-21 17:12:12 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-21 17:42:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-21 17:42:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-21 17:42:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-21 17:42:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 17:42:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-21 17:42:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-21 17:42:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-21 17:42:47 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-21 17:42:47 [scrapy.core.engine] INFO: Spider opened
2017-03-21 17:42:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-21 17:42:59 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-21 17:42:59 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-23 16:44:54 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:44:54 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:44:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:44:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:44:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:44:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:44:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:44:55 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:44:55 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:44:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:45:07 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-23 16:45:07 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-23 16:45:10 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:45:10 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:45:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:45:10 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:45:10 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:45:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:45:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:45:10 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:45:10 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:45:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:46:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:46:22 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-23 16:46:22 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-23 16:46:28 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:46:28 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:46:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:46:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:46:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:46:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:46:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:46:28 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:46:28 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:46:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:47:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:48:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:49:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:50:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.TCPTimedOutError: TCP connection timed out: 60: Operation timed out.
2017-03-23 16:50:14 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:50:14 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:50:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 3,
 'downloader/request_bytes': 1428,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 50, 14, 5246),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 46, 28, 427016)}
2017-03-23 16:50:14 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 16:51:17 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:51:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:51:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:51:17 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:51:17 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:51:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:51:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:51:17 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:51:17 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:51:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:51:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-23 16:51:18 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:51:18 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:51:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1446,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 51, 18, 886189),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 51, 17, 349623)}
2017-03-23 16:51:18 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 16:51:30 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:51:30 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:51:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:51:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:51:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:51:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:51:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:51:30 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:51:30 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:51:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:51:32 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-23 16:51:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:51:32 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:51:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 51, 32, 292881),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 51, 30, 721522)}
2017-03-23 16:51:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 16:52:25 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:52:25 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:52:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:52:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:52:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:52:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:52:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:52:25 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:52:25 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:52:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:52:27 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-23 16:52:27 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:52:27 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:52:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 52, 27, 914510),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 52, 25, 830235)}
2017-03-23 16:52:27 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 16:53:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:53:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:53:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:53:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:53:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:53:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:53:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:53:33 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:53:33 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:53:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:53:34 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljhrss/indexNew.jsp>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-23 16:53:34 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:53:34 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:53:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1329,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 53, 34, 608542),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 53, 33, 424438)}
2017-03-23 16:53:34 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 16:54:07 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:54:07 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:54:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:54:07 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:54:07 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:54:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:54:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:54:07 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:54:07 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:54:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:54:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljhrss/indexNew.jsp>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-23 16:54:09 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:54:09 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:54:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1308,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 54, 9, 370736),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 54, 7, 424812)}
2017-03-23 16:54:09 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 16:55:42 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:55:42 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:55:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:55:42 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:55:42 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:55:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:55:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:55:43 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:55:43 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:55:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:55:44 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljhrss/indexNew.jsp>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-23 16:55:44 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:55:44 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:55:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1308,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 55, 44, 204146),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 55, 43, 62364)}
2017-03-23 16:55:44 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 16:56:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:56:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:56:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:56:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:56:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:56:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:56:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:56:35 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:56:35 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:56:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:56:38 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljhrss/indexNew.jsp>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-23 16:56:38 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:56:38 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:56:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1329,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 56, 38, 173565),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 56, 35, 603894)}
2017-03-23 16:56:38 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 16:57:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 16:57:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 16:57:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 16:57:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:57:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 16:57:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 16:57:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 16:57:36 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 16:57:36 [scrapy.core.engine] INFO: Spider opened
2017-03-23 16:57:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 16:57:37 [scrapy.core.scraper] ERROR: Error downloading <GET http://hl.lss.gov.cn/hljszc/more.jsp?type=005.001&key1=&key2=&key3=&key4=&page=1>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.web._newclient.ResponseFailed: [<twisted.python.failure.Failure builtins.ValueError: invalid literal for int() with base 10: b'0;'>]
2017-03-23 16:57:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 16:57:37 [heilongjiang] INFO: get_webpage_count:0
2017-03-23 16:57:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.web._newclient.ResponseFailed': 3,
 'downloader/request_bytes': 1425,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 8, 57, 37, 418402),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 3, 23, 8, 57, 36, 149794)}
2017-03-23 16:57:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 17:02:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 17:02:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 17:02:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 17:02:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 17:02:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 17:02:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 17:02:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 17:02:48 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 17:02:48 [scrapy.core.engine] INFO: Spider opened
2017-03-23 17:02:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 17:05:20 [heilongjiang] ERROR: parse_webpage_error:Error 60 connecting to 192.168.1.150:6379. Operation timed out.
2017-03-23 17:06:07 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-23 17:06:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 17:06:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 17:06:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 17:06:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 17:06:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 17:06:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 17:06:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 17:06:14 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 17:06:14 [scrapy.core.engine] INFO: Spider opened
2017-03-23 17:06:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 17:06:24 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 17:06:24 [heilongjiang] INFO: get_webpage_count:93
2017-03-23 17:06:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 57519,
 'downloader/request_count': 98,
 'downloader/request_method_count/GET': 98,
 'downloader/response_bytes': 1065469,
 'downloader/response_count': 98,
 'downloader/response_status_count/200': 98,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 9, 6, 24, 119633),
 'item_scraped_count': 93,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 98,
 'scheduler/dequeued': 98,
 'scheduler/dequeued/memory': 98,
 'scheduler/enqueued': 98,
 'scheduler/enqueued/memory': 98,
 'start_time': datetime.datetime(2017, 3, 23, 9, 6, 14, 463267)}
2017-03-23 17:06:24 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 17:07:03 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 17:07:03 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 17:07:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 17:07:03 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 17:07:03 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 17:07:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 17:07:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 17:07:04 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 17:07:04 [scrapy.core.engine] INFO: Spider opened
2017-03-23 17:07:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 17:07:12 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 17:07:12 [heilongjiang] INFO: get_webpage_count:88
2017-03-23 17:07:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 57459,
 'downloader/request_count': 98,
 'downloader/request_method_count/GET': 98,
 'downloader/response_bytes': 1065469,
 'downloader/response_count': 98,
 'downloader/response_status_count/200': 98,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 9, 7, 12, 194299),
 'item_scraped_count': 88,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 98,
 'scheduler/dequeued': 98,
 'scheduler/dequeued/memory': 98,
 'scheduler/enqueued': 98,
 'scheduler/enqueued/memory': 98,
 'start_time': datetime.datetime(2017, 3, 23, 9, 7, 4, 48536)}
2017-03-23 17:07:12 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-23 17:08:09 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: arbitration_spider)
2017-03-23 17:08:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'arbitration_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'arbitration_spider.spiders', 'SPIDER_MODULES': ['arbitration_spider.spiders']}
2017-03-23 17:08:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-23 17:08:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 17:08:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-23 17:08:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['arbitration_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'arbitration_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-23 17:08:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-23 17:08:09 [scrapy.middleware] INFO: Enabled item pipelines:
['arbitration_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-23 17:08:09 [scrapy.core.engine] INFO: Spider opened
2017-03-23 17:08:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-23 17:08:50 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-23 17:08:50 [heilongjiang] INFO: get_webpage_count:5
2017-03-23 17:08:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 57543,
 'downloader/request_count': 98,
 'downloader/request_method_count/GET': 98,
 'downloader/response_bytes': 1065469,
 'downloader/response_count': 98,
 'downloader/response_status_count/200': 98,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 23, 9, 8, 50, 805768),
 'item_scraped_count': 5,
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 98,
 'scheduler/dequeued': 98,
 'scheduler/dequeued/memory': 98,
 'scheduler/enqueued': 98,
 'scheduler/enqueued/memory': 98,
 'start_time': datetime.datetime(2017, 3, 23, 9, 8, 9, 402898)}
2017-03-23 17:08:50 [scrapy.core.engine] INFO: Spider closed (finished)
