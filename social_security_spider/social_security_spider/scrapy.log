2017-03-30 11:30:01 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 11:30:01 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 11:31:28 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 11:31:28 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 11:32:23 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 11:32:23 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 11:32:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 11:32:23 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 11:32:23 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 11:32:23 [twisted] CRITICAL: Unhandled error in Deferred:
2017-03-30 11:32:23 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/midle.py", line 7, in <module>
    import arbitration_spider.Environmental_parameters as Environmental_parameters
ModuleNotFoundError: No module named 'arbitration_spider.Environmental_parameters'
2017-03-30 11:33:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 11:33:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 11:33:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 11:33:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 11:33:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 11:33:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 11:33:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 11:33:24 [twisted] CRITICAL: Unhandled error in Deferred:
2017-03-30 11:33:24 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'social_security_spider.pipelines' has no attribute 'JsonWithEncodingCnblogsPipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'social_security_spider.pipelines' doesn't define any object named 'JsonWithEncodingCnblogsPipeline'
2017-03-30 13:01:07 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 13:01:07 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 13:01:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 13:01:07 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:01:07 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:01:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 13:01:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 13:01:07 [twisted] CRITICAL: Unhandled error in Deferred:
2017-03-30 13:01:07 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'social_security_spider.pipelines' has no attribute 'JsonWithEncodingCnblogsPipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'social_security_spider.pipelines' doesn't define any object named 'JsonWithEncodingCnblogsPipeline'
2017-03-30 13:01:58 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 13:01:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 13:01:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 13:01:58 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:01:58 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:01:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 13:01:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 13:01:59 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 13:01:59 [scrapy.core.engine] INFO: Spider opened
2017-03-30 13:01:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 13:02:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-03-30 13:02:05 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 13:02:05 [hangzhou] INFO: get_webpage_count:0
2017-03-30 13:02:05 [hangzhou] INFO: success
2017-03-30 13:02:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 423,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 694,
 'downloader/response_count': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 5, 2, 5, 416925),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 3, 30, 5, 1, 59, 232328)}
2017-03-30 13:02:05 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 13:07:42 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 13:07:42 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 13:07:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 13:07:42 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:07:42 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:07:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 13:07:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 13:07:43 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 13:07:43 [scrapy.core.engine] INFO: Spider opened
2017-03-30 13:07:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 13:07:51 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-03-30 13:07:51 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 13:07:51 [hangzhou] INFO: get_webpage_count:0
2017-03-30 13:07:51 [hangzhou] INFO: success
2017-03-30 13:07:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 423,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 694,
 'downloader/response_count': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 5, 7, 51, 836117),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 3, 30, 5, 7, 43, 156882)}
2017-03-30 13:07:51 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 13:08:54 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 13:08:54 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 13:08:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 13:08:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:08:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:08:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 13:08:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 13:08:55 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 13:08:55 [scrapy.core.engine] INFO: Spider opened
2017-03-30 13:08:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 13:09:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-03-30 13:09:02 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 13:09:02 [hangzhou] INFO: get_webpage_count:0
2017-03-30 13:09:02 [hangzhou] INFO: success
2017-03-30 13:09:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 416,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 694,
 'downloader/response_count': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 5, 9, 2, 31022),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 3, 30, 5, 8, 55, 759368)}
2017-03-30 13:09:02 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 13:16:23 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 13:16:23 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 13:16:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 13:16:23 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:16:23 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:16:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 13:16:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 13:16:23 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 13:16:23 [scrapy.core.engine] INFO: Spider opened
2017-03-30 13:16:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 13:16:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-03-30 13:16:42 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 13:16:42 [hangzhou] INFO: get_webpage_count:0
2017-03-30 13:16:42 [hangzhou] INFO: success
2017-03-30 13:16:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 416,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 694,
 'downloader/response_count': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 5, 16, 42, 69589),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 3, 30, 5, 16, 23, 591819)}
2017-03-30 13:16:42 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 13:17:30 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 13:17:30 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 13:17:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 13:17:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:17:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:17:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 13:17:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 13:17:30 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 13:17:30 [scrapy.core.engine] INFO: Spider opened
2017-03-30 13:17:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 13:20:49 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 13:20:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 103, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh&goto=http%3a%2f%2fpuser.zjzwfw.gov.cn%2fsso%2fusp.do%3faction%3dzfRedirect%26servicecode%3drlsbcx&tabid=26993")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-03-30 13:20:57 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 13:20:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 13:20:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 13:20:57 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:20:57 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 13:20:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 13:20:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 13:20:58 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 13:20:58 [scrapy.core.engine] INFO: Spider opened
2017-03-30 13:20:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 13:21:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 13:50:46 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 14:15:11 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:15:11 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:15:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:15:11 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:15:11 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:15:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:15:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:15:12 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:15:12 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:15:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:18:55 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 14:18:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 103, in parse
    driver.set_window_size(240, 320)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-03-30 14:18:55 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 14:18:55 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:18:55 [hangzhou] INFO: get_webpage_count:0
2017-03-30 14:18:55 [hangzhou] INFO: success
2017-03-30 14:18:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 425,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 30, 6, 18, 55, 107604),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 3, 30, 6, 15, 12, 293387)}
2017-03-30 14:18:55 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-30 14:19:04 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:19:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:19:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:19:05 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:19:05 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:19:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:19:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:19:05 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:19:05 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:19:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:21:15 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 14:21:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:21:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:21:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:21:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:21:24 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:21:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:21:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:21:25 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:21:25 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:21:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:22:57 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 14:22:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-03-30 14:23:48 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:23:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:23:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:23:49 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:23:49 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:23:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:23:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:23:49 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:23:49 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:23:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:25:24 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 14:25:40 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:25:40 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:25:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:25:40 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:25:40 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:25:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:25:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:25:40 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:25:40 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:26:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 964, in send
    self.connect()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 936, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 722, in create_connection
    raise err
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 713, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 113, in parse
    elem_user = driver.find_element_by_name("username")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 367, in find_element_by_name
    return self.find_element(by=By.NAME, value=name)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 61] Connection refused>
2017-03-30 14:26:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 14:26:32 [hangzhou] INFO: get_webpage_count:0
2017-03-30 14:26:32 [hangzhou] INFO: success
2017-03-30 14:26:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 6, 26, 32, 536448),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/URLError': 1,
 'start_time': datetime.datetime(2017, 3, 30, 6, 25, 40, 556730)}
2017-03-30 14:26:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 14:30:31 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:30:31 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:30:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:30:31 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:30:31 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:30:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:30:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:30:31 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:30:31 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:30:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:30:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 113, in parse
    elem_user = driver.find_element_by_name("username")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 367, in find_element_by_name
    return self.find_element(by=By.NAME, value=name)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with name 'username'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"91","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:61464","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"name\", \"value\": \"username\", \"sessionId\": \"686dcb30-1512-11e7-a140-6fd15e121a57\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/686dcb30-1512-11e7-a140-6fd15e121a57/element"}}
Screenshot: available via screen

2017-03-30 14:30:53 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 14:30:53 [hangzhou] INFO: get_webpage_count:0
2017-03-30 14:30:53 [hangzhou] INFO: success
2017-03-30 14:30:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 6, 30, 53, 547550),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 6, 30, 31, 720266)}
2017-03-30 14:30:53 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 14:31:13 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:31:13 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:31:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:31:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:31:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:31:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:31:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:31:14 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:31:14 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:31:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:32:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:33:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:33:28 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 14:33:28 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 14:33:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:33:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:33:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:33:34 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:33:34 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:33:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:33:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:33:34 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:33:34 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:33:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:34:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 113, in parse
    elem_user = driver.find_element_by_name("username")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 367, in find_element_by_name
    return self.find_element(by=By.NAME, value=name)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with name 'username'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"91","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:62200","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"name\", \"value\": \"username\", \"sessionId\": \"d09fd5e0-1512-11e7-9857-81ccd0434005\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/d09fd5e0-1512-11e7-9857-81ccd0434005/element"}}
Screenshot: available via screen

2017-03-30 14:34:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:34:14 [hangzhou] INFO: get_webpage_count:0
2017-03-30 14:34:14 [hangzhou] INFO: success
2017-03-30 14:34:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 1,
 'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 30, 6, 34, 14, 966062),
 'log_count/INFO': 13,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 3, 30, 6, 31, 14, 698698)}
2017-03-30 14:34:14 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-30 14:34:20 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 14:34:20 [hangzhou] INFO: get_webpage_count:0
2017-03-30 14:34:20 [hangzhou] INFO: success
2017-03-30 14:34:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 6, 34, 20, 126919),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 6, 33, 34, 757449)}
2017-03-30 14:34:20 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 14:36:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:36:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:36:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:36:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:36:47 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:36:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:36:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:36:47 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:36:47 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:36:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:37:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 127, in parse
    int_pages = int(temp)
ValueError: invalid literal for int() with base 10: ''
2017-03-30 14:37:23 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 14:37:23 [hangzhou] INFO: get_webpage_count:0
2017-03-30 14:37:23 [hangzhou] INFO: success
2017-03-30 14:37:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 6, 37, 23, 497037),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2017, 3, 30, 6, 36, 47, 620832)}
2017-03-30 14:37:23 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 14:45:20 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:45:20 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:45:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:45:20 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:45:20 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:45:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:45:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:45:20 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:45:20 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:45:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:45:28 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 14:45:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-03-30 14:45:28 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 14:45:28 [hangzhou] INFO: get_webpage_count:0
2017-03-30 14:45:28 [hangzhou] INFO: success
2017-03-30 14:45:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 423,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 30, 6, 45, 28, 387569),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 3, 30, 6, 45, 20, 448791)}
2017-03-30 14:45:28 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-30 14:45:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 14:45:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 14:45:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 14:45:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:45:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 14:45:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 14:45:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 14:45:45 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 14:45:45 [scrapy.core.engine] INFO: Spider opened
2017-03-30 14:45:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 14:45:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 127, in parse
    int_pages = int(temp)
ValueError: invalid literal for int() with base 10: ''
2017-03-30 14:45:56 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 14:45:56 [hangzhou] INFO: get_webpage_count:0
2017-03-30 14:45:56 [hangzhou] INFO: success
2017-03-30 14:45:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 6, 45, 56, 625171),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2017, 3, 30, 6, 45, 45, 7353)}
2017-03-30 14:45:56 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 15:00:41 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 15:00:41 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 15:00:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 15:00:41 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:00:41 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:00:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 15:00:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 15:00:41 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 15:00:41 [scrapy.core.engine] INFO: Spider opened
2017-03-30 15:00:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:03:40 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 15:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-03-30 15:03:41 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 15:03:41 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:03:41 [hangzhou] INFO: get_webpage_count:0
2017-03-30 15:03:41 [hangzhou] INFO: success
2017-03-30 15:03:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 429,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 30, 7, 3, 41, 28891),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 3, 30, 7, 0, 41, 375078)}
2017-03-30 15:03:41 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-30 15:03:50 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 15:03:50 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 15:03:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 15:03:50 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:03:50 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:03:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 15:03:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 15:03:50 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 15:03:50 [scrapy.core.engine] INFO: Spider opened
2017-03-30 15:03:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:04:26 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 15:04:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-03-30 15:04:26 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 15:04:26 [hangzhou] INFO: get_webpage_count:0
2017-03-30 15:04:26 [hangzhou] INFO: success
2017-03-30 15:04:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 30, 7, 4, 26, 939918),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 3, 30, 7, 3, 50, 900629)}
2017-03-30 15:04:26 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-30 15:04:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 15:04:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 15:04:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 15:04:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:04:33 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:04:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 15:04:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 15:04:33 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 15:04:33 [scrapy.core.engine] INFO: Spider opened
2017-03-30 15:04:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 127, in parse
    int_pages = int(temp)
ValueError: invalid literal for int() with base 10: ''
2017-03-30 15:05:07 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 15:05:07 [hangzhou] INFO: get_webpage_count:0
2017-03-30 15:05:07 [hangzhou] INFO: success
2017-03-30 15:05:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 7, 5, 7, 999512),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2017, 3, 30, 7, 4, 33, 791095)}
2017-03-30 15:05:08 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 15:26:03 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 15:26:03 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 15:26:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 15:26:03 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:26:03 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:26:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 15:26:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 15:26:03 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 15:26:03 [scrapy.core.engine] INFO: Spider opened
2017-03-30 15:26:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:26:06 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 15:26:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-03-30 15:26:06 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 15:26:06 [hangzhou] INFO: get_webpage_count:0
2017-03-30 15:26:06 [hangzhou] INFO: success
2017-03-30 15:26:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 423,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 3, 30, 7, 26, 6, 959230),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 3, 30, 7, 26, 3, 621932)}
2017-03-30 15:26:06 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-03-30 15:26:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 15:26:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 15:26:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 15:26:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:26:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:26:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 15:26:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 15:26:14 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 15:26:14 [scrapy.core.engine] INFO: Spider opened
2017-03-30 15:26:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:27:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 122, in parse
    dd.until(EC.presence_of_element_located((By.ID, "defaultLocal")))
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/support/wait.py", line 80, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Screenshot: available via screen

2017-03-30 15:27:32 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:27:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 15:27:32 [hangzhou] INFO: get_webpage_count:0
2017-03-30 15:27:32 [hangzhou] INFO: success
2017-03-30 15:27:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 426,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 7, 27, 32, 688488),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TimeoutException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 7, 26, 14, 919412)}
2017-03-30 15:27:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 15:27:50 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 15:27:50 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 15:27:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 15:27:50 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:27:50 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:27:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 15:27:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 15:27:51 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 15:27:51 [scrapy.core.engine] INFO: Spider opened
2017-03-30 15:27:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:28:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 122, in parse
    dt = dd.until(EC.presence_of_element_located((By.ID, "defaultLocal")))
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/support/wait.py", line 80, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: 
Screenshot: available via screen

2017-03-30 15:28:25 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 15:28:25 [hangzhou] INFO: get_webpage_count:0
2017-03-30 15:28:25 [hangzhou] INFO: success
2017-03-30 15:28:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 421,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 7, 28, 25, 165373),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TimeoutException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 7, 27, 51, 89254)}
2017-03-30 15:28:25 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 15:28:57 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 15:28:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 15:28:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 15:28:57 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:28:57 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 15:28:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 15:28:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 15:28:58 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 15:28:58 [scrapy.core.engine] INFO: Spider opened
2017-03-30 15:28:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:30:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 137, in parse
    int_pages = int(temp)
ValueError: invalid literal for int() with base 10: ''
2017-03-30 15:30:01 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 15:30:01 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 15:30:01 [hangzhou] INFO: get_webpage_count:0
2017-03-30 15:30:01 [hangzhou] INFO: success
2017-03-30 15:30:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 423,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 7, 30, 1, 648095),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2017, 3, 30, 7, 28, 58, 99228)}
2017-03-30 15:30:01 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 16:37:06 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 16:37:06 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 16:37:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 16:37:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:37:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:37:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 16:37:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 16:37:06 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 16:37:06 [scrapy.core.engine] INFO: Spider opened
2017-03-30 16:37:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:38:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:38:36 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 16:38:36 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 16:38:42 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 16:38:42 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 16:38:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 16:38:42 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:38:42 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:38:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 16:38:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 16:38:43 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 16:38:43 [scrapy.core.engine] INFO: Spider opened
2017-03-30 16:38:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:39:35 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 16:39:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 16:39:41 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 16:39:41 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 16:39:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 16:39:41 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:39:41 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:39:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 16:39:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 16:39:42 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 16:39:42 [scrapy.core.engine] INFO: Spider opened
2017-03-30 16:39:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:40:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:40:52 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 16:40:52 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-03-30 16:41:01 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 16:41:01 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 16:41:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 16:41:01 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:41:01 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:41:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 16:41:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 16:41:01 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 16:41:01 [scrapy.core.engine] INFO: Spider opened
2017-03-30 16:41:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:42:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:43:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 143, in parse
    next_page = driver.find_element_by_id('tmp_downloadhelper_iframe')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 271, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with id 'tmp_downloadhelper_iframe'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"106","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:59633","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"id\", \"value\": \"tmp_downloadhelper_iframe\", \"sessionId\": \"c93e78d0-1524-11e7-a81e-d1e279f70a89\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/c93e78d0-1524-11e7-a81e-d1e279f70a89/element"}}
Screenshot: available via screen

2017-03-30 16:43:06 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:43:06 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 16:43:06 [hangzhou] INFO: get_webpage_count:0
2017-03-30 16:43:06 [hangzhou] INFO: success
2017-03-30 16:43:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 1,
 'downloader/request_bytes': 854,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 8, 43, 6, 704555),
 'log_count/ERROR': 2,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 8, 41, 1, 898193)}
2017-03-30 16:43:06 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 16:43:56 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 16:43:56 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 16:43:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 16:43:56 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:43:56 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 16:43:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 16:43:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 16:43:56 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 16:43:56 [scrapy.core.engine] INFO: Spider opened
2017-03-30 16:43:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 16:44:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 143, in parse
    next_page = driver.find_element_by_id('tmp_downloadhelper_iframe')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 271, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with id 'tmp_downloadhelper_iframe'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"106","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:60269","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"id\", \"value\": \"tmp_downloadhelper_iframe\", \"sessionId\": \"04ae1420-1525-11e7-b008-4d4d198fdc84\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/04ae1420-1525-11e7-b008-4d4d198fdc84/element"}}
Screenshot: available via screen

2017-03-30 16:44:49 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 16:44:49 [hangzhou] INFO: get_webpage_count:0
2017-03-30 16:44:49 [hangzhou] INFO: success
2017-03-30 16:44:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 421,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 8, 44, 49, 449212),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 8, 43, 56, 975553)}
2017-03-30 16:44:49 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 17:06:21 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 17:06:21 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 17:06:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 17:06:21 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 17:06:21 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 17:06:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 17:06:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 17:06:22 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 17:06:22 [scrapy.core.engine] INFO: Spider opened
2017-03-30 17:06:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 17:06:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 137, in parse
    if next_page.click():
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:49569","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1490864796567\", \"sessionId\": \"267534a0-1528-11e7-a36d-c3017bfa325a\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/267534a0-1528-11e7-a36d-c3017bfa325a/element/:wdc:1490864796567/click"}}
Screenshot: available via screen

2017-03-30 17:07:02 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 17:07:02 [hangzhou] INFO: get_webpage_count:0
2017-03-30 17:07:02 [hangzhou] INFO: success
2017-03-30 17:07:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 9, 7, 2, 558663),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 9, 6, 22, 66963)}
2017-03-30 17:07:02 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 17:09:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 17:09:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 17:09:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 17:09:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 17:09:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 17:09:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 17:09:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 17:09:44 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 17:09:44 [scrapy.core.engine] INFO: Spider opened
2017-03-30 17:09:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 17:10:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 137, in parse
    if next_page.click():
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:50615","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1490864993144\", \"sessionId\": \"9f818470-1528-11e7-8027-f926410c3cde\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/9f818470-1528-11e7-8027-f926410c3cde/element/:wdc:1490864993144/click"}}
Screenshot: available via screen

2017-03-30 17:10:12 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 17:10:12 [hangzhou] INFO: get_webpage_count:0
2017-03-30 17:10:12 [hangzhou] INFO: success
2017-03-30 17:10:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 9, 10, 12, 510221),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 9, 9, 44, 987351)}
2017-03-30 17:10:12 [scrapy.core.engine] INFO: Spider closed (finished)
2017-03-30 17:11:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 17:11:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 17:11:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 17:11:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 17:11:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 17:11:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 17:11:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 17:11:36 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 17:11:36 [scrapy.core.engine] INFO: Spider opened
2017-03-30 17:11:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 17:13:03 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-03-30 17:25:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-03-30 17:25:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-03-30 17:25:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-03-30 17:25:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 17:25:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-03-30 17:25:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-03-30 17:25:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-03-30 17:25:09 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-03-30 17:25:09 [scrapy.core.engine] INFO: Spider opened
2017-03-30 17:25:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-03-30 17:25:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 168, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.StaleElementReferenceException: Message: {"errorMessage":"Element does not exist in cache","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:54937","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1490865917532\", \"sessionId\": \"c64b1ab0-152a-11e7-b0a2-9f1dbf1fdef5\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/c64b1ab0-152a-11e7-b0a2-9f1dbf1fdef5/element/:wdc:1490865917532/click"}}
Screenshot: available via screen

2017-03-30 17:25:53 [scrapy.core.engine] INFO: Closing spider (finished)
2017-03-30 17:25:53 [hangzhou] INFO: get_webpage_count:0
2017-03-30 17:25:53 [hangzhou] INFO: success
2017-03-30 17:25:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7251,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 3, 30, 9, 25, 53, 778579),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/StaleElementReferenceException': 1,
 'start_time': datetime.datetime(2017, 3, 30, 9, 25, 9, 371733)}
2017-03-30 17:25:53 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 10:41:18 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 10:41:18 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 10:41:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 10:41:18 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:41:18 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:41:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 10:41:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 10:41:18 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 10:41:18 [scrapy.core.engine] INFO: Spider opened
2017-04-05 10:41:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 10:41:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 136, in parse
    next_page = driver.find_element_by_xpath('//div[@class="rdfw_list_copy"]/div[@title=""]/div')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//div[@class=\"rdfw_list_copy\"]/div[@title=\"\"]/div'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"161","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:51617","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@class=\\\"rdfw_list_copy\\\"]/div[@title=\\\"\\u793e\\u4fdd\\u67e5\\u8be2\\\"]/div\", \"sessionId\": \"5bed3850-19a9-11e7-a27f-b16ee81c368b\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/5bed3850-19a9-11e7-a27f-b16ee81c368b/element"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 140, in parse
    next_page = driver.find_element_by_xpath('//div[@class="rdfw_btn_left"]')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//div[@class=\"rdfw_btn_left\"]'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"115","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:51617","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@class=\\\"rdfw_btn_left\\\"]\", \"sessionId\": \"5bed3850-19a9-11e7-a27f-b16ee81c368b\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/5bed3850-19a9-11e7-a27f-b16ee81c368b/element"}}
Screenshot: available via screen

2017-04-05 10:41:51 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 10:41:51 [hangzhou] INFO: get_webpage_count:0
2017-04-05 10:41:51 [hangzhou] INFO: success
2017-04-05 10:41:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 2, 41, 51, 826883),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 4, 5, 2, 41, 18, 483011)}
2017-04-05 10:41:51 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 10:42:45 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 10:42:45 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 10:42:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 10:42:45 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:42:45 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:42:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 10:42:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 10:42:45 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 10:42:45 [scrapy.core.engine] INFO: Spider opened
2017-04-05 10:42:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 10:45:06 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 10:45:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-05 10:45:06 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-05 10:45:06 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 10:45:07 [hangzhou] INFO: get_webpage_count:0
2017-04-05 10:45:07 [hangzhou] INFO: success
2017-04-05 10:45:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 5, 2, 45, 7, 1850),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 4, 5, 2, 42, 45, 974239)}
2017-04-05 10:45:07 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-05 10:45:15 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 10:45:15 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 10:45:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 10:45:15 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:45:15 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:45:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 10:45:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 10:45:16 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 10:45:16 [scrapy.core.engine] INFO: Spider opened
2017-04-05 10:45:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 10:47:08 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 10:47:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-05 10:47:17 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 10:47:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 10:47:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 10:47:17 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:47:17 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:47:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 10:47:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 10:47:18 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 10:47:18 [scrapy.core.engine] INFO: Spider opened
2017-04-05 10:47:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 10:51:00 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 10:51:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 10:51:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 10:51:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 10:51:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:51:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:51:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 10:51:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 10:51:09 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 10:51:09 [scrapy.core.engine] INFO: Spider opened
2017-04-05 10:51:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 10:53:55 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 10:53:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-05 10:54:02 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 10:54:02 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 10:54:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 10:54:02 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:54:02 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 10:54:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 10:54:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 10:54:03 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 10:54:03 [scrapy.core.engine] INFO: Spider opened
2017-04-05 10:54:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 10:59:21 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 11:08:22 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 964, in send
    self.connect()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 936, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 722, in create_connection
    raise err
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 713, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 113, in parse
    elem_user = driver.find_element_by_name("loginname")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 367, in find_element_by_name
    return self.find_element(by=By.NAME, value=name)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 61] Connection refused>
2017-04-05 11:08:26 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-05 11:08:26 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 11:08:26 [hangzhou] INFO: get_webpage_count:0
2017-04-05 11:08:26 [hangzhou] INFO: success
2017-04-05 11:08:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 423,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 5, 3, 8, 26, 775518),
 'log_count/ERROR': 2,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/URLError': 1,
 'start_time': datetime.datetime(2017, 4, 5, 2, 54, 3, 198670)}
2017-04-05 11:08:26 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-05 11:08:31 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 11:08:31 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 11:08:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 11:08:31 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 11:08:31 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 11:08:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 11:08:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 11:08:32 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 11:08:32 [scrapy.core.engine] INFO: Spider opened
2017-04-05 11:08:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 11:16:45 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 11:18:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 11:18:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 11:18:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 11:18:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 11:18:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 11:18:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 11:18:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 11:18:14 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 11:18:14 [scrapy.core.engine] INFO: Spider opened
2017-04-05 11:18:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 11:21:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 190, in parse
    int_pages = int(temp)
ValueError: invalid literal for int() with base 10: ''
2017-04-05 11:21:12 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 11:21:12 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 11:21:12 [hangzhou] INFO: get_webpage_count:0
2017-04-05 11:21:12 [hangzhou] INFO: success
2017-04-05 11:21:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 3, 21, 12, 369035),
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2017, 4, 5, 3, 18, 14, 803952)}
2017-04-05 11:21:12 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 11:22:54 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 11:22:54 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 11:22:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 11:22:54 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 11:22:54 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 11:22:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 11:22:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 11:22:54 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 11:22:54 [scrapy.core.engine] INFO: Spider opened
2017-04-05 11:22:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 11:25:00 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 11:25:00 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 136, in parse
    next_page = driver.find_element_by_xpath('//div[@class="rdfw_list_copy"]/div[@title=""]/div')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//div[@class=\"rdfw_list_copy\"]/div[@title=\"\"]/div'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"161","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:52909","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@class=\\\"rdfw_list_copy\\\"]/div[@title=\\\"\\u793e\\u4fdd\\u67e5\\u8be2\\\"]/div\", \"sessionId\": \"2c4d63d0-19af-11e7-9375-47714d17d472\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/2c4d63d0-19af-11e7-9375-47714d17d472/element"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 144, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-05 11:25:00 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-05 11:25:00 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 11:25:00 [hangzhou] INFO: get_webpage_count:0
2017-04-05 11:25:00 [hangzhou] INFO: success
2017-04-05 11:25:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 5, 3, 25, 0, 632442),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 4, 5, 3, 22, 54, 842001)}
2017-04-05 11:25:00 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-05 11:27:30 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 11:27:30 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 11:27:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 11:27:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 11:27:30 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 11:27:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 11:27:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 11:27:30 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 11:27:30 [scrapy.core.engine] INFO: Spider opened
2017-04-05 11:27:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 11:28:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 197, in parse
    int_pages = int(temp)
ValueError: invalid literal for int() with base 10: ''
2017-04-05 11:28:47 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 11:28:47 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 11:28:47 [hangzhou] INFO: get_webpage_count:0
2017-04-05 11:28:47 [hangzhou] INFO: success
2017-04-05 11:28:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 3, 28, 47, 897456),
 'log_count/ERROR': 2,
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2017, 4, 5, 3, 27, 30, 715051)}
2017-04-05 11:28:47 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 13:53:48 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 13:53:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 13:53:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 13:53:48 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 13:53:48 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 13:53:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 13:53:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 13:53:48 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 13:53:48 [scrapy.core.engine] INFO: Spider opened
2017-04-05 13:53:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 13:54:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 180, in parse
    next_page = driver.find_element_by_xpath('//li[@class="sbcx-biz-jbyanglao"]')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//li[@class=\"sbcx-biz-jbyanglao\"]'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"119","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:58807","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//li[@class=\\\"sbcx-biz-jbyanglao\\\"]\", \"sessionId\": \"3e519d70-19c4-11e7-a16f-b1b9ccf626c7\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/3e519d70-19c4-11e7-a16f-b1b9ccf626c7/element"}}
Screenshot: available via screen

2017-04-05 13:54:11 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 13:54:11 [hangzhou] INFO: get_webpage_count:0
2017-04-05 13:54:11 [hangzhou] INFO: success
2017-04-05 13:54:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 5, 54, 11, 379846),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 4, 5, 5, 53, 48, 382342)}
2017-04-05 13:54:11 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 13:55:12 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 13:55:12 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 13:55:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 13:55:12 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 13:55:12 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 13:55:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 13:55:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 13:55:12 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 13:55:12 [scrapy.core.engine] INFO: Spider opened
2017-04-05 13:55:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 13:55:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 203, in parse
    int_pages = int(temp)
ValueError: invalid literal for int() with base 10: ''
2017-04-05 13:55:36 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 13:55:36 [hangzhou] INFO: get_webpage_count:0
2017-04-05 13:55:36 [hangzhou] INFO: success
2017-04-05 13:55:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 5, 55, 36, 148727),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2017, 4, 5, 5, 55, 12, 430238)}
2017-04-05 13:55:36 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 14:04:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 14:04:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 14:04:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 14:04:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:04:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:04:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 14:04:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 14:04:14 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 14:04:14 [scrapy.core.engine] INFO: Spider opened
2017-04-05 14:04:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 14:04:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 174, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"null is not an object (evaluating 'document.querySelector('#sbcx-area-start').options')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:61994","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"b3b6c1c0-19c5-11e7-b91b-af7a4e3f7c85\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/b3b6c1c0-19c5-11e7-b91b-af7a4e3f7c85/execute"}}
Screenshot: available via screen

2017-04-05 14:04:24 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 14:04:24 [hangzhou] INFO: get_webpage_count:0
2017-04-05 14:04:24 [hangzhou] INFO: success
2017-04-05 14:04:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 429,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 6, 4, 24, 283040),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 5, 6, 4, 14, 853380)}
2017-04-05 14:04:24 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 14:11:40 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 14:11:40 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 14:11:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 14:11:40 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:11:40 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:11:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 14:11:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 14:11:40 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 14:11:40 [scrapy.core.engine] INFO: Spider opened
2017-04-05 14:11:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 14:11:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 174, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-start').options[2].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:64037","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"bca52cd0-19c6-11e7-8a95-79958395261f\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/bca52cd0-19c6-11e7-8a95-79958395261f/execute"}}
Screenshot: available via screen

2017-04-05 14:11:51 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 14:11:51 [hangzhou] INFO: get_webpage_count:0
2017-04-05 14:11:51 [hangzhou] INFO: success
2017-04-05 14:11:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 425,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 6, 11, 51, 727419),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 5, 6, 11, 40, 343609)}
2017-04-05 14:11:51 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 14:24:31 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 14:24:31 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 14:24:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 14:24:31 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:24:31 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:24:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 14:24:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 14:24:31 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 14:24:31 [scrapy.core.engine] INFO: Spider opened
2017-04-05 14:24:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 14:24:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 180, in parse
    next_page = driver.find_element_by_xpath('//li[@class="sbcx-biz-jbyanglao"]')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//li[@class=\"sbcx-biz-jbyanglao\"]'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"119","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:50961","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//li[@class=\\\"sbcx-biz-jbyanglao\\\"]\", \"sessionId\": \"88809050-19c8-11e7-9e7a-45be4e3e63dd\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/88809050-19c8-11e7-9e7a-45be4e3e63dd/element"}}
Screenshot: available via screen

2017-04-05 14:24:48 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 14:24:48 [hangzhou] INFO: get_webpage_count:0
2017-04-05 14:24:48 [hangzhou] INFO: success
2017-04-05 14:24:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 6, 24, 48, 910243),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 4, 5, 6, 24, 31, 690272)}
2017-04-05 14:24:48 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 14:27:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 14:27:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 14:27:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 14:27:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:27:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:27:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 14:27:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 14:27:08 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 14:27:08 [scrapy.core.engine] INFO: Spider opened
2017-04-05 14:27:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 14:27:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 176, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:51909","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"e6737790-19c8-11e7-8cbe-373738116817\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/e6737790-19c8-11e7-8cbe-373738116817/execute"}}
Screenshot: available via screen

2017-04-05 14:27:20 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 14:27:20 [hangzhou] INFO: get_webpage_count:0
2017-04-05 14:27:20 [hangzhou] INFO: success
2017-04-05 14:27:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 6, 27, 20, 144634),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 5, 6, 27, 8, 451895)}
2017-04-05 14:27:20 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 14:27:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 14:27:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 14:27:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 14:27:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:27:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 14:27:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 14:27:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 14:27:35 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 14:27:35 [scrapy.core.engine] INFO: Spider opened
2017-04-05 14:27:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 14:27:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 205, in parse
    int_pages = int(temp)
ValueError: invalid literal for int() with base 10: ''
2017-04-05 14:27:51 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 14:27:51 [hangzhou] INFO: get_webpage_count:0
2017-04-05 14:27:51 [hangzhou] INFO: success
2017-04-05 14:27:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 427,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 6, 27, 51, 84814),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2017, 4, 5, 6, 27, 35, 475671)}
2017-04-05 14:27:51 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-05 16:53:57 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 16:53:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 16:53:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 16:53:57 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 16:53:57 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 16:53:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 16:53:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 16:53:57 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 16:53:57 [scrapy.core.engine] INFO: Spider opened
2017-04-05 16:53:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 16:55:01 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 16:55:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-05 16:55:01 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-05 16:55:01 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 16:55:01 [hangzhou] INFO: get_webpage_count:0
2017-04-05 16:55:01 [hangzhou] INFO: success
2017-04-05 16:55:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 425,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 5, 8, 55, 1, 539805),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 4, 5, 8, 53, 57, 382236)}
2017-04-05 16:55:01 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-05 16:55:03 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 16:55:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 16:55:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 16:55:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 16:55:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 16:55:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 16:55:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 16:55:04 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 16:55:04 [scrapy.core.engine] INFO: Spider opened
2017-04-05 16:55:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 16:57:05 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-05 16:57:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.zjzwfw.gov.cn/> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 104, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-05 16:57:05 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-05 16:57:05 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 16:57:05 [hangzhou] INFO: get_webpage_count:0
2017-04-05 16:57:05 [hangzhou] INFO: success
2017-04-05 16:57:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 5, 8, 57, 5, 250931),
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 4, 5, 8, 55, 4, 230163)}
2017-04-05 16:57:05 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-05 16:57:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-05 16:57:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-05 16:57:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-05 16:57:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 16:57:08 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-05 16:57:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-05 16:57:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-05 16:57:08 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-05 16:57:08 [scrapy.core.engine] INFO: Spider opened
2017-04-05 16:57:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-05 16:57:27 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-05 16:57:27 [hangzhou] INFO: get_webpage_count:0
2017-04-05 16:57:27 [hangzhou] INFO: success
2017-04-05 16:57:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 420,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 5, 8, 57, 27, 420046),
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 5, 8, 57, 8, 318951)}
2017-04-05 16:57:27 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 11:26:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 11:26:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 11:26:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 11:26:49 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:26:49 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:26:49 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 11:26:49 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/midle.py", line 14, in <module>
    RedisOpera = redis.StrictRedis(host=Environmental_parameters.redis_host, port=Environmental_parameters.redis_port)
AttributeError: module 'social_security_spider.Environmental_parameters' has no attribute 'redis_host'
2017-04-06 11:28:03 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 11:28:03 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 11:28:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 11:28:03 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:28:03 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:28:03 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 11:28:03 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/midle.py", line 14, in <module>
    RedisOpera = redis.StrictRedis(host=Environmental_parameters.redis_host, port=Environmental_parameters.redis_port)
AttributeError: module 'social_security_spider.Environmental_parameters' has no attribute 'redis_host'
2017-04-06 11:30:01 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 11:30:01 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 11:30:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 11:30:01 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:30:01 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:30:02 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 11:30:02 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/midle.py", line 14, in <module>
    RedisOpera = redis.StrictRedis(host=Environmental_parameters.redis_host, port=Environmental_parameters.redis_port)
AttributeError: module 'social_security_spider.Environmental_parameters' has no attribute 'redis_host'
2017-04-06 11:30:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 11:30:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 11:30:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 11:30:49 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:30:49 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:30:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 11:30:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 11:30:50 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 11:30:50 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py", line 2, in <module>
    from . import es
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/es.py", line 10, in <module>
    es = Elasticsearch(Environmental_parameters.es_url)
AttributeError: module 'social_security_spider.Environmental_parameters' has no attribute 'es_url'
2017-04-06 11:31:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 11:31:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 11:31:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 11:31:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:31:35 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:31:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 11:31:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 11:31:36 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 11:31:36 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py", line 2, in <module>
    from . import es
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/es.py", line 10, in <module>
    es = Elasticsearch(Environmental_parameters.es_url)
AttributeError: module 'social_security_spider.Environmental_parameters' has no attribute 'es_url'
2017-04-06 11:32:04 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 11:32:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 11:32:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 11:32:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:32:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:32:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 11:32:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 11:32:05 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 11:32:05 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 11:34:50 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 11:34:50 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 11:34:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 11:34:50 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:34:50 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 11:34:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 11:34:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 11:34:51 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 11:34:51 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 13:39:59 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 13:39:59 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 13:39:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 13:39:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 13:39:59 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 13:39:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 13:39:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 13:39:59 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 13:39:59 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 13:48:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 13:48:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 13:48:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 13:48:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 13:48:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 13:48:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 13:48:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 13:48:14 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 13:48:14 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 14:01:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:01:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:01:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:01:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:01:14 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:01:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:01:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:01:15 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:01:15 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 14:02:45 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:02:45 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:02:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:02:45 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:02:45 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:02:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:02:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:02:45 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:02:45 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 14:07:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:07:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:07:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:07:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:07:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:07:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:07:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:07:37 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:07:37 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 14:08:37 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:08:37 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:08:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:08:37 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:08:37 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:08:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:08:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:08:37 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:08:37 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 14:08:46 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:08:46 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:08:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:08:46 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:08:46 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:08:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:08:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:08:46 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:08:46 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 14:15:55 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:15:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:15:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:15:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:15:55 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:15:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:15:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:15:55 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.JsonWithEncodingCnblogsPipeline']
2017-04-06 14:15:55 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:15:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:15:56 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:15:56 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:15:56 [hangzhou] INFO: get_webpage_count:0
2017-04-06 14:15:56 [hangzhou] INFO: success
2017-04-06 14:15:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1723,
 'downloader/response_count': 2,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 15, 56, 20261),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 4, 6, 6, 15, 55, 485258)}
2017-04-06 14:15:56 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:18:09 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:18:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:18:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:18:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:18:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:18:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:18:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:18:10 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:18:10 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'social_security_spider.pipelines' has no attribute 'JsonWithEncodingCnblogsPipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'social_security_spider.pipelines' doesn't define any object named 'JsonWithEncodingCnblogsPipeline'
2017-04-06 14:18:25 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:18:25 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:18:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:18:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:18:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:18:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:18:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:18:25 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:18:25 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 14:18:46 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:18:46 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:18:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:18:46 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:18:46 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:18:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:18:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:18:47 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:18:47 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:18:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:18:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:18:47 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:18:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 981,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1723,
 'downloader/response_count': 2,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 18, 47, 558261),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 4, 6, 6, 18, 47, 116014)}
2017-04-06 14:18:47 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:25:06 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:25:06 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:25:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:25:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:25:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:25:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:25:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:25:06 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:25:06 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:25:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:25:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:25:06 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:25:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 986,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1722,
 'downloader/response_count': 2,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 25, 6, 888665),
 'log_count/INFO': 8,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 4, 6, 6, 25, 6, 411576)}
2017-04-06 14:25:06 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:31:04 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:31:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:31:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:31:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:31:04 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:31:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:31:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:31:04 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:31:04 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:31:04 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: __init__() missing 1 required positional argument: 'spider'
2017-04-06 14:31:29 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:31:29 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:31:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:31:29 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:31:29 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:31:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:31:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:31:29 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:31:29 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-06 14:31:29 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 40, in from_settings
    mw = mwcls()
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py", line 20, in __init__
    Environmental_parameters['mongodb_server'],
TypeError: 'module' object is not subscriptable
2017-04-06 14:32:39 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:32:39 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:32:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:32:39 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:32:39 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:32:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:32:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:32:39 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:32:39 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:32:39 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:32:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:32:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:32:40 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:32:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 982,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1722,
 'downloader/response_count': 2,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 32, 40, 622193),
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 4, 6, 6, 32, 39, 891969)}
2017-04-06 14:32:40 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:33:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:33:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:33:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:33:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:33:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:33:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:33:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:33:09 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:33:09 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:33:09 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:33:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:33:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:33:09 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:33:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 994,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1722,
 'downloader/response_count': 2,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 33, 9, 820486),
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 4, 6, 6, 33, 9, 225934)}
2017-04-06 14:33:09 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:36:45 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:36:45 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:36:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:36:45 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:36:45 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:36:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:36:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:36:46 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:36:46 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:36:46 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:36:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:36:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:36:46 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:36:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 995,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1723,
 'downloader/response_count': 2,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 36, 46, 625008),
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 4, 6, 6, 36, 46, 27759)}
2017-04-06 14:36:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:38:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:38:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:38:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:38:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:38:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:38:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:38:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:38:44 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:38:44 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:38:44 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:38:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:38:44 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:38:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 38, 44, 918255),
 'log_count/INFO': 7,
 'log_count/WARNING': 3,
 'start_time': datetime.datetime(2017, 4, 6, 6, 38, 44, 902226)}
2017-04-06 14:38:44 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:39:01 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:39:01 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:39:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:39:01 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:39:01 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:39:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:39:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:39:02 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:39:02 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:39:02 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:39:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:39:02 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:39:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 39, 2, 375091),
 'log_count/INFO': 7,
 'log_count/WARNING': 3,
 'start_time': datetime.datetime(2017, 4, 6, 6, 39, 2, 357375)}
2017-04-06 14:39:02 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:39:09 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:39:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:39:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:39:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:39:09 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:39:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:39:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:39:10 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:39:10 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:39:10 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:39:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:39:10 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:39:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 39, 10, 16733),
 'log_count/INFO': 7,
 'log_count/WARNING': 3,
 'start_time': datetime.datetime(2017, 4, 6, 6, 39, 10, 11527)}
2017-04-06 14:39:10 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:40:00 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:40:00 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:40:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:40:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:40:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:40:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:40:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:40:00 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:40:00 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:40:00 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:40:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:40:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:40:35 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:40:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 947,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 1723,
 'downloader/response_count': 2,
 'downloader/response_status_count/302': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 40, 35, 65724),
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2017, 4, 6, 6, 40, 0, 670650)}
2017-04-06 14:40:35 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:43:19 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:43:19 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:43:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:43:19 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:43:19 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:43:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:43:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:43:19 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:43:19 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:43:19 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:43:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:43:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:43:20 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:43:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 416,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 694,
 'downloader/response_count': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 43, 20, 51845),
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 6, 6, 43, 19, 705112)}
2017-04-06 14:43:20 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:43:37 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:43:37 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:43:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:43:37 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:43:37 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:43:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:43:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:43:37 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:43:37 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:43:37 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:43:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:43:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <405 https://www.baidu.com/>: HTTP status code is not handled or not allowed
2017-04-06 14:43:38 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:43:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 416,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 694,
 'downloader/response_count': 1,
 'downloader/response_status_count/405': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 43, 38, 466439),
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 6, 6, 43, 37, 989084)}
2017-04-06 14:43:38 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 14:44:28 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 14:44:28 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 14:44:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 14:44:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:44:28 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 14:44:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 14:44:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 14:44:28 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 14:44:28 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 14:44:28 [scrapy.core.engine] INFO: Spider opened
2017-04-06 14:44:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:46:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 173, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-start').options[2].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:50211","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"7d2331f0-1a94-11e7-8460-c3f21e8913a2\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/7d2331f0-1a94-11e7-8460-c3f21e8913a2/execute"}}
Screenshot: available via screen

2017-04-06 14:46:35 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 14:46:35 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 14:46:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 6, 46, 35, 260176),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 6, 6, 44, 28, 994005)}
2017-04-06 14:46:35 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-06 15:06:06 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 15:06:06 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 15:06:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 15:06:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 15:06:06 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 15:06:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 15:06:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 15:06:07 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 15:06:07 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 15:06:07 [scrapy.core.engine] INFO: Spider opened
2017-04-06 15:06:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 15:11:49 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-06 15:11:56 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 15:11:56 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 15:11:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 15:11:56 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 15:11:56 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 15:11:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 15:11:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 15:11:56 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 15:11:56 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 15:11:56 [scrapy.core.engine] INFO: Spider opened
2017-04-06 15:11:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 15:13:43 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-06 15:15:10 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-06 15:15:10 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-06 15:15:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-06 15:15:10 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 15:15:10 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-06 15:15:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-06 15:15:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-06 15:15:11 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-06 15:15:11 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-06 15:15:11 [scrapy.core.engine] INFO: Spider opened
2017-04-06 15:15:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 15:16:48 [scrapy.core.scraper] ERROR: Error processing {'name': ''}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 651, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py", line 34, in process_item
    self.collection.insert(dict(item))
  File "/usr/local/lib/python3.6/site-packages/pymongo/collection.py", line 2467, in insert
    with self._socket_for_writes() as sock_info:
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py", line 82, in __enter__
    return next(self.gen)
  File "/usr/local/lib/python3.6/site-packages/pymongo/mongo_client.py", line 823, in _get_socket
    server = self._get_topology().select_server(selector)
  File "/usr/local/lib/python3.6/site-packages/pymongo/topology.py", line 214, in select_server
    address))
  File "/usr/local/lib/python3.6/site-packages/pymongo/topology.py", line 189, in select_servers
    self._error_message(selector))
pymongo.errors.ServerSelectionTimeoutError: 192.168.1.220:27017: [Errno 61] Connection refused
2017-04-06 15:16:48 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-06 15:16:48 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-06 15:16:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 6, 7, 16, 48, 262690),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 6, 7, 15, 11, 47682)}
2017-04-06 15:16:48 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-07 16:32:21 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-07 16:32:21 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-07 16:32:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-07 16:32:21 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-07 16:32:21 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-07 16:32:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-07 16:32:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-07 16:32:22 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-07 16:32:22 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-07 16:32:22 [scrapy.core.engine] INFO: Spider opened
2017-04-07 16:32:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-07 16:33:49 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-07 16:33:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 103, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-07 16:33:49 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-07 16:33:49 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-07 16:33:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 7, 8, 33, 49, 265636),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 4, 7, 8, 32, 22, 558934)}
2017-04-07 16:33:49 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-07 16:33:55 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-07 16:33:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-07 16:33:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-07 16:33:56 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-07 16:33:56 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-07 16:33:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-07 16:33:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-07 16:33:56 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-07 16:33:56 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-07 16:33:56 [scrapy.core.engine] INFO: Spider opened
2017-04-07 16:33:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-07 16:51:05 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-10 15:26:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-10 15:26:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-10 15:26:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-10 15:26:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:26:44 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:26:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-10 15:26:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-10 15:26:44 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-10 15:26:44 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-10 15:26:44 [scrapy.core.engine] INFO: Spider opened
2017-04-10 15:26:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 15:29:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 156, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55262","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1491809336863\", \"sessionId\": \"10d541e0-1dbf-11e7-b6f5-836b53f8f135\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/10d541e0-1dbf-11e7-b6f5-836b53f8f135/element/:wdc:1491809336863/click"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 163, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55262","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1491809336863\", \"sessionId\": \"10d541e0-1dbf-11e7-b6f5-836b53f8f135\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/10d541e0-1dbf-11e7-b6f5-836b53f8f135/element/:wdc:1491809336863/click"}}
Screenshot: available via screen

2017-04-10 15:29:15 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 15:29:15 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-10 15:29:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 471,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 10, 7, 29, 15, 501082),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 10, 7, 26, 44, 890346)}
2017-04-10 15:29:15 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-10 15:30:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-10 15:30:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-10 15:30:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-10 15:30:34 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:30:34 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:30:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-10 15:30:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-10 15:30:34 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-10 15:30:34 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-10 15:30:34 [scrapy.core.engine] INFO: Spider opened
2017-04-10 15:30:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 15:31:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 156, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55551","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1491809489024\", \"sessionId\": \"9ce4f860-1dbf-11e7-82f7-e1c0e45c933f\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/9ce4f860-1dbf-11e7-82f7-e1c0e45c933f/element/:wdc:1491809489024/click"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 163, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55551","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1491809489024\", \"sessionId\": \"9ce4f860-1dbf-11e7-82f7-e1c0e45c933f\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/9ce4f860-1dbf-11e7-82f7-e1c0e45c933f/element/:wdc:1491809489024/click"}}
Screenshot: available via screen

2017-04-10 15:31:44 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 15:31:44 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-10 15:31:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 10, 7, 31, 44, 240603),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 10, 7, 30, 34, 686815)}
2017-04-10 15:31:44 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-10 15:36:43 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-10 15:36:43 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-10 15:36:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-10 15:36:43 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:36:43 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:36:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-10 15:36:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-10 15:36:44 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-10 15:36:44 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-10 15:36:44 [scrapy.core.engine] INFO: Spider opened
2017-04-10 15:36:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 15:41:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 156, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56962","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1491810093918\", \"sessionId\": \"77533e80-1dc0-11e7-92c2-81617c1892cf\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/77533e80-1dc0-11e7-92c2-81617c1892cf/element/:wdc:1491810093918/click"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 167, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56962","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1491810093918\", \"sessionId\": \"77533e80-1dc0-11e7-92c2-81617c1892cf\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/77533e80-1dc0-11e7-92c2-81617c1892cf/element/:wdc:1491810093918/click"}}
Screenshot: available via screen

2017-04-10 15:41:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 15:41:46 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-10 15:41:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 10, 7, 41, 46, 617009),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 10, 7, 36, 44, 245594)}
2017-04-10 15:41:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-10 15:42:51 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-10 15:42:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-10 15:42:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-10 15:42:51 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:42:51 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:42:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-10 15:42:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-10 15:42:52 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-10 15:42:52 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-10 15:42:52 [scrapy.core.engine] INFO: Spider opened
2017-04-10 15:42:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 15:46:36 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-10 15:47:00 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-10 15:47:00 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-10 15:47:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-10 15:47:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:47:00 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 15:47:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-10 15:47:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-10 15:47:00 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-10 15:47:00 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-10 15:47:00 [scrapy.core.engine] INFO: Spider opened
2017-04-10 15:47:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 16:00:02 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 383, in parse
    item["name"] = ""
  File "/usr/local/lib/python3.6/site-packages/scrapy/item.py", line 63, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'HangzhouItem does not support field: name'
2017-04-10 16:00:13 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 16:00:13 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-10 16:00:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 466,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 10, 8, 0, 13, 884276),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2017, 4, 10, 7, 47, 0, 822210)}
2017-04-10 16:00:13 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-10 16:23:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-10 16:23:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-10 16:23:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-10 16:23:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 16:23:36 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 16:23:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-10 16:23:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-10 16:23:37 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:13: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-10 16:23:37 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-10 16:23:37 [scrapy.core.engine] INFO: Spider opened
2017-04-10 16:23:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 16:26:27 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-10 18:02:25 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-10 18:02:25 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-10 18:02:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-10 18:02:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 18:02:25 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-10 18:02:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-10 18:02:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-10 18:02:26 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-10 18:02:26 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-10 18:02:26 [scrapy.core.engine] INFO: Spider opened
2017-04-10 18:02:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-10 18:03:06 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-10 18:03:06 [hangzhou] INFO: we let it done:hangzhou
2017-04-10 18:03:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 10, 10, 3, 6, 565388),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 10, 10, 2, 26, 67471)}
2017-04-10 18:03:06 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 10:28:30 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 10:28:30 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 10:28:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 10:28:31 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-11 10:28:31 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-11 10:28:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 10:28:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 10:28:31 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 10:28:31 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 10:28:31 [scrapy.core.engine] INFO: Spider opened
2017-04-11 10:28:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 10:28:45 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-11 10:28:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 964, in send
    self.connect()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 936, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 722, in create_connection
    raise err
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 713, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 150, in parse
    driver.save_screenshot('2.png')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 802, in get_screenshot_as_file
    png = self.get_screenshot_as_png()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 821, in get_screenshot_as_png
    return base64.b64decode(self.get_screenshot_as_base64().encode('ascii'))
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 831, in get_screenshot_as_base64
    return self.execute(Command.SCREENSHOT)['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 61] Connection refused>
2017-04-11 10:28:45 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-11 10:28:45 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 10:28:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 11, 2, 28, 45, 501187),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/URLError': 1,
 'start_time': datetime.datetime(2017, 4, 11, 2, 28, 31, 374466)}
2017-04-11 10:28:45 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-11 10:28:48 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 10:28:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 10:28:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 10:28:48 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.useragent.UserAgentMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-11 10:28:48 [py.warnings] WARNING: /usr/local/lib/python3.6/site-packages/scrapy/utils/deprecate.py:156: ScrapyDeprecationWarning: `scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware` class is deprecated, use `scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware` instead
  ScrapyDeprecationWarning)

2017-04-11 10:28:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 10:28:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 10:28:48 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 10:28:48 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 10:28:48 [scrapy.core.engine] INFO: Spider opened
2017-04-11 10:28:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 10:29:28 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 10:29:28 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 10:29:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 2, 29, 28, 40555),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 3,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 2, 28, 48, 603279)}
2017-04-11 10:29:28 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 10:34:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 10:34:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 10:34:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 10:34:25 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-11 10:34:25 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 936, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 948, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy.downloadermiddleware'
2017-04-11 10:34:42 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 10:34:42 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 10:34:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 10:34:42 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-11 10:34:42 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 936, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 948, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy.downloadermiddleware'
2017-04-11 10:36:19 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 10:36:19 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 10:36:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 10:36:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 10:36:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 10:36:19 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 10:36:19 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 10:36:19 [scrapy.core.engine] INFO: Spider opened
2017-04-11 10:36:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 11:13:23 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-11 11:13:29 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 11:13:29 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 11:13:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 3, 13, 29, 123835),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 2, 36, 19, 769745)}
2017-04-11 11:13:29 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 11:19:51 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 11:19:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 11:19:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 11:19:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 11:19:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 11:19:52 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 11:19:52 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 11:19:52 [scrapy.core.engine] INFO: Spider opened
2017-04-11 11:19:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 14:27:15 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-11 14:27:27 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 14:27:27 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 14:27:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 14:27:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 14:27:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 14:27:27 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 14:27:27 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 14:27:27 [scrapy.core.engine] INFO: Spider opened
2017-04-11 14:27:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 14:29:11 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-11 14:30:04 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-11 14:30:19 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 14:30:19 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 14:30:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 14:30:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 14:30:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 14:30:19 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 14:30:19 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 14:30:19 [scrapy.core.engine] INFO: Spider opened
2017-04-11 14:30:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 14:32:01 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-11 14:38:29 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-11 14:38:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 14:38:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 14:38:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 14:38:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 14:38:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 14:38:36 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 14:38:36 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 14:38:36 [scrapy.core.engine] INFO: Spider opened
2017-04-11 14:38:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 15:29:51 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-11 16:05:07 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 16:05:07 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 16:05:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 16:05:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 16:05:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 16:05:08 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 16:05:08 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 16:05:08 [scrapy.core.engine] INFO: Spider opened
2017-04-11 16:05:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 16:07:32 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-11 16:07:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 16:07:32 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 16:07:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 8, 7, 32, 196992),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 8, 5, 8, 656295)}
2017-04-11 16:07:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 16:15:26 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 16:15:26 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 16:15:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 16:15:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 16:15:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 16:15:26 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 16:15:26 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 16:15:26 [scrapy.core.engine] INFO: Spider opened
2017-04-11 16:15:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 16:15:59 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-11 16:15:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 159, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 964, in send
    self.connect()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 936, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 722, in create_connection
    raise err
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 713, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 162, in parse
    next_page = driver.find_element_by_xpath('//div[@class="rdfw_btn_left"]')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 61] Connection refused>
2017-04-11 16:15:59 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-11 16:15:59 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 16:15:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 11, 8, 15, 59, 548847),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/URLError': 1,
 'start_time': datetime.datetime(2017, 4, 11, 8, 15, 26, 994108)}
2017-04-11 16:15:59 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-11 16:16:08 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 16:16:08 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 16:16:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 16:16:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 16:16:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 16:16:08 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 16:16:08 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 16:16:08 [scrapy.core.engine] INFO: Spider opened
2017-04-11 16:16:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 16:16:48 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 16:16:48 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 16:16:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 8, 16, 48, 351112),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 8, 16, 8, 893449)}
2017-04-11 16:16:48 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 16:19:02 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 16:19:02 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 16:19:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 16:19:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 16:19:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 16:19:02 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 16:19:02 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 16:19:02 [scrapy.core.engine] INFO: Spider opened
2017-04-11 16:19:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 16:19:09 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-11 16:20:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 16:20:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 16:20:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 16:20:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 16:20:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 16:20:49 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-11 16:20:49 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py", line 2, in <module>
    from . import mongo
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/mongo.py", line 48
    "annual_individual_account_actual_payment_months": lxml_obj_to_str(postitem["Annual_individual_account_actual_payment_months"],
                                                     ^
SyntaxError: invalid syntax
2017-04-11 16:45:32 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 16:45:32 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 16:45:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 16:45:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 16:45:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 16:45:32 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 16:45:32 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 16:45:32 [scrapy.core.engine] INFO: Spider opened
2017-04-11 16:45:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 16:46:12 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 16:46:12 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 16:46:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 470,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 8, 46, 12, 871580),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 8, 45, 32, 999893)}
2017-04-11 16:46:12 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 17:08:06 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 17:08:06 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 17:08:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 17:08:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 17:08:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 17:08:06 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 17:08:06 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 17:08:06 [scrapy.core.engine] INFO: Spider opened
2017-04-11 17:08:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 17:08:46 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 17:08:46 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 17:08:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 9, 8, 46, 26800),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 9, 8, 6, 779357)}
2017-04-11 17:08:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 17:30:13 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 17:30:13 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 17:30:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 17:30:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 17:30:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 17:30:13 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 17:30:13 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 17:30:13 [scrapy.core.engine] INFO: Spider opened
2017-04-11 17:30:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 17:30:53 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 17:30:53 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 17:30:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 9, 30, 53, 140091),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 9, 30, 13, 438418)}
2017-04-11 17:30:53 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 17:39:53 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 17:39:53 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 17:39:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 17:39:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 17:39:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 17:39:53 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 17:39:53 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 17:39:53 [scrapy.core.engine] INFO: Spider opened
2017-04-11 17:39:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 17:40:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 17:40:32 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 17:40:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 9, 40, 32, 826991),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 9, 39, 53, 542273)}
2017-04-11 17:40:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 17:45:55 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 17:45:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 17:45:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 17:45:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 17:45:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 17:45:55 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 17:45:55 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 17:45:55 [scrapy.core.engine] INFO: Spider opened
2017-04-11 17:45:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 17:46:35 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 17:46:35 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 17:46:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 466,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 9, 46, 35, 572721),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 9, 45, 55, 474685)}
2017-04-11 17:46:35 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-11 17:48:50 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-11 17:48:50 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-11 17:48:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-11 17:48:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-11 17:48:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-11 17:48:50 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-11 17:48:50 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-11 17:48:50 [scrapy.core.engine] INFO: Spider opened
2017-04-11 17:48:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-11 17:49:30 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-11 17:49:30 [hangzhou] INFO: we let it done:hangzhou
2017-04-11 17:49:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 11, 9, 49, 30, 179046),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 11, 9, 48, 50, 336724)}
2017-04-11 17:49:30 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 14:08:17 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 14:08:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 14:08:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 14:08:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 14:08:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 14:08:18 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 14:08:18 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 14:08:18 [scrapy.core.engine] INFO: Spider opened
2017-04-12 14:08:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 14:09:19 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-12 14:09:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 14:09:19 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 14:09:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 6, 9, 19, 709948),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 12, 6, 8, 18, 68910)}
2017-04-12 14:09:19 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 14:10:53 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 14:10:53 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 14:10:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 14:10:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 14:10:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 14:10:54 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 14:10:54 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 14:10:54 [scrapy.core.engine] INFO: Spider opened
2017-04-12 14:10:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 14:11:34 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 14:11:34 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 14:11:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 6, 11, 34, 182235),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 12, 6, 10, 54, 42583)}
2017-04-12 14:11:34 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 14:15:42 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 14:15:42 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 14:15:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 14:15:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 14:15:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 14:15:42 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 14:15:42 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 14:15:42 [scrapy.core.engine] INFO: Spider opened
2017-04-12 14:15:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 14:16:21 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 14:16:21 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 14:16:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 6, 16, 21, 224702),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 12, 6, 15, 42, 461841)}
2017-04-12 14:16:21 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 14:24:00 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 14:24:00 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 14:24:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 14:24:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 14:24:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 14:24:00 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 14:24:00 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 14:24:00 [scrapy.core.engine] INFO: Spider opened
2017-04-12 14:24:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 14:24:40 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 14:24:40 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 14:24:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 6, 24, 40, 456728),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 12, 6, 24, 0, 657563)}
2017-04-12 14:24:40 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 14:31:18 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 14:31:18 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 14:31:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 14:31:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 14:31:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 14:31:18 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 14:31:18 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 14:31:18 [scrapy.core.engine] INFO: Spider opened
2017-04-12 14:31:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 14:31:19 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-12 14:31:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 14:31:19 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 14:31:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1398,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 6, 31, 19, 156180),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 12, 6, 31, 18, 729869)}
2017-04-12 14:31:19 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 14:31:27 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 14:31:27 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 14:31:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 14:31:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 14:31:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 14:31:27 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 14:31:27 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 14:31:27 [scrapy.core.engine] INFO: Spider opened
2017-04-12 14:31:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 14:32:48 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-12 16:51:29 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 16:51:29 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 16:51:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 16:51:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 16:51:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 16:51:29 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 16:51:29 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 16:51:29 [scrapy.core.engine] INFO: Spider opened
2017-04-12 16:51:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 16:52:09 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 16:52:09 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 16:52:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 8, 52, 9, 370931),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 12, 8, 51, 29, 437525)}
2017-04-12 16:52:09 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 17:16:45 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 17:16:45 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 17:16:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 17:16:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 17:16:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 17:16:45 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 17:16:45 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 17:16:45 [scrapy.core.engine] INFO: Spider opened
2017-04-12 17:16:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 17:19:21 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-12 17:19:48 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 17:19:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 17:19:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 17:19:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 17:19:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 17:19:48 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 17:19:48 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 17:19:48 [scrapy.core.engine] INFO: Spider opened
2017-04-12 17:19:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 17:20:28 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 17:20:28 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 17:20:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 471,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 9, 20, 28, 833983),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 12, 9, 19, 48, 768870)}
2017-04-12 17:20:28 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 17:21:46 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 17:21:46 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 17:21:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 17:21:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 17:21:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 17:21:46 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 17:21:46 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 17:21:46 [scrapy.core.engine] INFO: Spider opened
2017-04-12 17:21:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 17:22:25 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 17:22:25 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 17:22:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 9, 22, 25, 667397),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 12, 9, 21, 46, 526251)}
2017-04-12 17:22:25 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 17:51:03 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 17:51:03 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 17:51:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 17:51:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 17:51:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 17:51:04 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 17:51:04 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 17:51:04 [scrapy.core.engine] INFO: Spider opened
2017-04-12 17:51:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 17:51:04 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-12 17:51:04 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-12 17:51:04 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-12 17:51:04 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 17:51:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1416,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 12, 9, 51, 4, 581526),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 12, 9, 51, 4, 239522)}
2017-04-12 17:51:04 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-12 17:51:11 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 17:51:11 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 17:51:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 17:51:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 17:51:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 17:51:12 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 17:51:12 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 17:51:12 [scrapy.core.engine] INFO: Spider opened
2017-04-12 17:51:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 17:51:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-12 17:51:12 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 17:51:12 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 17:51:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1395,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 9, 51, 12, 576475),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 12, 9, 51, 12, 185051)}
2017-04-12 17:51:12 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 17:52:22 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 17:52:22 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 17:52:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 17:52:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 17:52:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 17:52:22 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 17:52:22 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 17:52:22 [scrapy.core.engine] INFO: Spider opened
2017-04-12 17:52:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-12 17:53:04 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-12 17:53:04 [hangzhou] INFO: we let it done:hangzhou
2017-04-12 17:53:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 12, 9, 53, 4, 573228),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 12, 9, 52, 22, 400455)}
2017-04-12 17:53:04 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-12 17:56:22 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-12 17:56:22 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-12 17:56:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-12 17:56:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-12 17:56:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-12 17:56:23 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-12 17:56:23 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-12 17:56:23 [scrapy.core.engine] INFO: Spider opened
2017-04-12 17:56:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 09:52:04 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-13 11:04:03 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 11:04:03 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 11:04:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 11:04:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 11:04:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 11:04:03 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 11:04:03 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 11:04:03 [scrapy.core.engine] INFO: Spider opened
2017-04-13 11:04:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 11:10:17 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-13 11:36:13 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 11:36:13 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 11:36:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 11:36:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 11:36:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 11:36:13 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 11:36:13 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 11:36:13 [scrapy.core.engine] INFO: Spider opened
2017-04-13 11:36:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 11:36:53 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 11:36:53 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 11:36:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 470,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 3, 36, 53, 191006),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 3, 36, 13, 425793)}
2017-04-13 11:36:53 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 11:39:04 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 11:39:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 11:39:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 11:39:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 11:39:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 11:39:04 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 11:39:04 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 11:39:04 [scrapy.core.engine] INFO: Spider opened
2017-04-13 11:39:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 11:39:45 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 11:39:45 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 11:39:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 3, 39, 45, 302738),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 3, 39, 4, 389184)}
2017-04-13 11:39:45 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 13:07:54 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 13:07:54 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 13:07:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 13:07:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 13:07:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 13:07:54 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 13:07:54 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 13:07:54 [scrapy.core.engine] INFO: Spider opened
2017-04-13 13:07:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 13:08:34 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 13:08:34 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 13:08:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 5, 8, 34, 909089),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 5, 7, 54, 579859)}
2017-04-13 13:08:34 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 13:19:57 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 13:19:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 13:19:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 13:19:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 13:19:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 13:19:58 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 13:19:58 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 13:19:58 [scrapy.core.engine] INFO: Spider opened
2017-04-13 13:19:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 13:20:40 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 13:20:40 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 13:20:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 5, 20, 40, 779081),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 5, 19, 58, 60852)}
2017-04-13 13:20:40 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 13:23:43 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 13:23:43 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 13:23:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 13:23:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 13:23:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 13:23:44 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 13:23:44 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 13:23:44 [scrapy.core.engine] INFO: Spider opened
2017-04-13 13:23:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 13:24:24 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 13:24:24 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 13:24:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 468,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 5, 24, 24, 575816),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 5, 23, 44, 194871)}
2017-04-13 13:24:24 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 13:26:15 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 13:26:15 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 13:26:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 13:26:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 13:26:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 13:26:16 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 13:26:16 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 13:26:16 [scrapy.core.engine] INFO: Spider opened
2017-04-13 13:26:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 13:26:56 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 13:26:56 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 13:26:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 5, 26, 56, 738846),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 5, 26, 16, 66464)}
2017-04-13 13:26:56 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 13:27:56 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 13:27:56 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 13:27:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 13:27:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 13:27:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 13:27:56 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 13:27:56 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 13:27:56 [scrapy.core.engine] INFO: Spider opened
2017-04-13 13:27:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 13:48:30 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-13 13:48:37 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 13:48:37 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 13:48:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 13:48:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 13:48:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 13:48:37 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 13:48:37 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 13:48:37 [scrapy.core.engine] INFO: Spider opened
2017-04-13 13:48:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 13:49:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 189, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"null is not an object (evaluating 'document.querySelector('#sbcx-area-start').options')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:54137","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"d86518d0-200c-11e7-be21-dd4ddf39e256\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/d86518d0-200c-11e7-be21-dd4ddf39e256/execute"}}
Screenshot: available via screen

2017-04-13 13:49:08 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 13:49:08 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 13:49:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 5, 49, 8, 848288),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 13, 5, 48, 37, 662289)}
2017-04-13 13:49:08 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 13:49:38 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 13:49:38 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 13:49:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 13:49:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 13:49:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 13:49:39 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 13:49:39 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 13:49:39 [scrapy.core.engine] INFO: Spider opened
2017-04-13 13:49:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 14:00:06 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-13 14:00:06 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 14:00:06 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 14:00:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 6, 0, 6, 560309),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 5, 49, 39, 213203)}
2017-04-13 14:00:06 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 14:00:15 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 14:00:15 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 14:00:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 14:00:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 14:00:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 14:00:15 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 14:00:15 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 14:00:15 [scrapy.core.engine] INFO: Spider opened
2017-04-13 14:00:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:09:58 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-13 15:11:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:11:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:11:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:11:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:11:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:11:37 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:11:37 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:11:37 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:11:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:20:55 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-13 15:21:07 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:21:07 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:21:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:21:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:21:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:21:08 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:21:08 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:21:08 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:21:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:21:08 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-13 15:21:08 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 15:21:08 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 15:21:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1416,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 7, 21, 8, 875957),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 13, 7, 21, 8, 453202)}
2017-04-13 15:21:08 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 15:21:16 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:21:16 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:21:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:21:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:21:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:21:17 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:21:17 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:21:17 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:21:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:21:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-13 15:21:17 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 15:21:17 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 15:21:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1395,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 7, 21, 17, 826207),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 13, 7, 21, 17, 377702)}
2017-04-13 15:21:17 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 15:21:32 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:21:32 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:21:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:21:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:21:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:21:32 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:21:32 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:21:32 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:21:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:27:29 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-13 15:27:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:27:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:27:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:27:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:27:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:27:36 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:27:36 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:27:36 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:27:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:32:32 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-13 15:32:51 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:32:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:32:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:32:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:32:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:32:51 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:32:51 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:32:51 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:32:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:34:55 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-13 15:35:17 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:35:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:35:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:35:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:35:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:35:17 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:35:17 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:35:17 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:35:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:35:56 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 15:35:56 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 15:35:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 466,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 7, 35, 56, 426527),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 7, 35, 17, 522624)}
2017-04-13 15:35:56 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 15:37:58 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:37:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:37:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:37:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:37:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:37:58 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:37:58 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:37:58 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:37:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:38:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 189, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"null is not an object (evaluating 'document.querySelector('#sbcx-area-start').options')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:58027","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"1f178e20-201c-11e7-b69e-df54d9ef35a2\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/1f178e20-201c-11e7-b69e-df54d9ef35a2/execute"}}
Screenshot: available via screen

2017-04-13 15:38:28 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 15:38:28 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 15:38:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 468,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 7, 38, 28, 782796),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 13, 7, 37, 58, 810720)}
2017-04-13 15:38:28 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-13 15:38:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-13 15:38:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-13 15:38:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-13 15:38:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-13 15:38:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-13 15:38:36 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-13 15:38:36 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-13 15:38:36 [scrapy.core.engine] INFO: Spider opened
2017-04-13 15:38:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-13 15:39:14 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-13 15:39:14 [hangzhou] INFO: we let it done:hangzhou
2017-04-13 15:39:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 13, 7, 39, 14, 783355),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 13, 7, 38, 36, 257014)}
2017-04-13 15:39:14 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:06:54 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:06:54 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:06:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:06:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:06:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:06:55 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:06:55 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:06:55 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:06:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:07:36 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 160, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:53877","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492160852502\", \"sessionId\": \"b663a400-20f1-11e7-aa5e-615ce78deda0\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/b663a400-20f1-11e7-aa5e-615ce78deda0/element/:wdc:1492160852502/click"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 172, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:53877","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492160852502\", \"sessionId\": \"b663a400-20f1-11e7-aa5e-615ce78deda0\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/b663a400-20f1-11e7-aa5e-615ce78deda0/element/:wdc:1492160852502/click"}}
Screenshot: available via screen

2017-04-14 17:07:36 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:07:36 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:07:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 471,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 7, 36, 789976),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 6, 55, 414636)}
2017-04-14 17:07:36 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:07:45 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:07:45 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:07:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:07:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:07:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:07:45 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:07:45 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:07:45 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:07:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:08:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 398, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:53986","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492160930198\", \"sessionId\": \"d3ce76a0-20f1-11e7-b41c-cfc2698f091f\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/d3ce76a0-20f1-11e7-b41c-cfc2698f091f/element/:wdc:1492160930198/click"}}
Screenshot: available via screen

2017-04-14 17:08:54 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:08:54 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:08:54 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:08:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 8, 54, 837837),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 7, 45, 819084)}
2017-04-14 17:08:54 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:10:51 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:10:51 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:10:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:10:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:10:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:10:51 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:10:51 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:10:51 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:10:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:11:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 398, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:54185","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492161104285\", \"sessionId\": \"43762480-20f2-11e7-a835-fb7717c97e4a\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/43762480-20f2-11e7-a835-fb7717c97e4a/element/:wdc:1492161104285/click"}}
Screenshot: available via screen

2017-04-14 17:11:48 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:11:48 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:11:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 11, 48, 898390),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 10, 51, 850875)}
2017-04-14 17:11:48 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:12:23 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:12:23 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:12:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:12:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:12:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:12:23 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:12:23 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:12:23 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:12:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:13:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 193, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:54386","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"7a0dd1f0-20f2-11e7-9162-831c284780e7\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/7a0dd1f0-20f2-11e7-9162-831c284780e7/execute"}}
Screenshot: available via screen

2017-04-14 17:13:13 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:13:13 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:13:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 13, 13, 177773),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 12, 23, 671468)}
2017-04-14 17:13:13 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:13:32 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:13:32 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:13:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:13:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:13:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:13:32 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:13:32 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:13:32 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:13:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:17:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 417, in parse
    item["Urban_rural_Endowment_insurance"] = "no"
  File "/usr/local/lib/python3.6/site-packages/scrapy/item.py", line 63, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'HangzhouItem does not support field: Urban_rural_Endowment_insurance'
2017-04-14 17:18:04 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:18:04 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:18:04 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:18:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 474,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 18, 4, 591119),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 13, 32, 596919)}
2017-04-14 17:18:04 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:20:01 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:20:01 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:20:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:20:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:20:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:20:02 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:20:02 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:20:02 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:20:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:21:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 193, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:54802","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"8b857310-20f3-11e7-81f4-97adbf2991d7\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/8b857310-20f3-11e7-81f4-97adbf2991d7/execute"}}
Screenshot: available via screen

2017-04-14 17:21:01 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:21:01 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:21:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 21, 1, 984434),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 20, 2, 447050)}
2017-04-14 17:21:01 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:21:42 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:21:42 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:21:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:21:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:21:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:21:43 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:21:43 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:21:43 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:21:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:22:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 160, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:54977","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492161739791\", \"sessionId\": \"c77ed7d0-20f3-11e7-8f98-c567caa62154\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/c77ed7d0-20f3-11e7-8f98-c567caa62154/element/:wdc:1492161739791/click"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 172, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:54977","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492161739791\", \"sessionId\": \"c77ed7d0-20f3-11e7-8f98-c567caa62154\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/c77ed7d0-20f3-11e7-8f98-c567caa62154/element/:wdc:1492161739791/click"}}
Screenshot: available via screen

2017-04-14 17:22:23 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:22:23 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:22:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 22, 23, 953576),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 21, 43, 63417)}
2017-04-14 17:22:23 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:23:13 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:23:13 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:23:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:23:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:23:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:23:14 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:23:14 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:23:14 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:23:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:24:11 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 160, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55098","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492161835192\", \"sessionId\": \"fdc1d590-20f3-11e7-8695-f55e945690c5\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/fdc1d590-20f3-11e7-8695-f55e945690c5/element/:wdc:1492161835192/click"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 172, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55098","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492161835192\", \"sessionId\": \"fdc1d590-20f3-11e7-8695-f55e945690c5\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/fdc1d590-20f3-11e7-8695-f55e945690c5/element/:wdc:1492161835192/click"}}
Screenshot: available via screen

2017-04-14 17:24:14 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:24:14 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:24:14 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:24:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 471,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 24, 14, 872349),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 23, 14, 89047)}
2017-04-14 17:24:14 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:25:48 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:25:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:25:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:25:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:25:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:25:49 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:25:49 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:25:49 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:25:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:28:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 193, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55230","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"598ea880-20f4-11e7-b40d-b3309d924833\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/598ea880-20f4-11e7-b40d-b3309d924833/execute"}}
Screenshot: available via screen

2017-04-14 17:28:20 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:28:20 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:28:20 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:28:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 28, 20, 152934),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 25, 49, 104773)}
2017-04-14 17:28:20 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:30:04 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:30:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:30:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:30:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:30:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:30:05 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:30:05 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:30:05 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:30:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:32:53 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 193, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55425","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"f26c43a0-20f4-11e7-bac1-d57f6050bf62\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/f26c43a0-20f4-11e7-bac1-d57f6050bf62/execute"}}
Screenshot: available via screen

2017-04-14 17:33:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:33:09 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:33:09 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:33:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 33, 9, 693703),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 30, 5, 135455)}
2017-04-14 17:33:09 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:33:27 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:33:27 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:33:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:33:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:33:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:33:27 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:33:27 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:33:27 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:33:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:38:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 193, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55619","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"6b6d96f0-20f5-11e7-af53-577aa7681ae6\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/6b6d96f0-20f5-11e7-af53-577aa7681ae6/execute"}}
Screenshot: available via screen

2017-04-14 17:38:32 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:38:32 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:38:32 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:38:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 38, 32, 889383),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 33, 27, 503357)}
2017-04-14 17:38:32 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:38:54 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:38:54 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:38:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:38:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:38:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:38:54 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:38:54 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:38:54 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:38:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:39:19 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-14 17:39:33 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:39:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:39:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:39:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:39:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:39:33 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:39:33 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:39:33 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:39:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:40:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 197, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55923","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"459cff50-20f6-11e7-aa10-4f4ad5cdd684\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/459cff50-20f6-11e7-aa10-4f4ad5cdd684/execute"}}
Screenshot: available via screen

2017-04-14 17:41:00 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:41:00 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:41:00 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:41:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 41, 0, 448950),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 39, 33, 690565)}
2017-04-14 17:41:00 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:47:44 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:47:44 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:47:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:47:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:47:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:47:45 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:47:45 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:47:45 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:47:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:49:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 402, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56367","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492163345555\", \"sessionId\": \"6abb7310-20f7-11e7-8f02-e760bc2a2932\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/6abb7310-20f7-11e7-8f02-e760bc2a2932/element/:wdc:1492163345555/click"}}
Screenshot: available via screen

2017-04-14 17:49:13 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:49:13 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:49:13 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:49:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 468,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 49, 13, 522486),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 47, 45, 331994)}
2017-04-14 17:49:13 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:54:45 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:54:45 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:54:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:54:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:54:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:54:46 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:54:46 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:54:46 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:54:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:55:17 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-14 17:55:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 964, in send
    self.connect()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 936, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 722, in create_connection
    raise err
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 713, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 154, in parse
    driver.save_screenshot('2.png')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 802, in get_screenshot_as_file
    png = self.get_screenshot_as_png()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 821, in get_screenshot_as_png
    return base64.b64decode(self.get_screenshot_as_base64().encode('ascii'))
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 831, in get_screenshot_as_base64
    return self.execute(Command.SCREENSHOT)['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 61] Connection refused>
2017-04-14 17:55:17 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-14 17:55:17 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:55:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 55, 17, 727140),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/URLError': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 54, 46, 503156)}
2017-04-14 17:55:17 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-14 17:56:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:56:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:56:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:56:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:56:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:56:24 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:56:24 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:56:24 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:56:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:57:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 195, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:58638","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"9fbf1d90-20f8-11e7-b8c6-6914a0b65c2b\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/9fbf1d90-20f8-11e7-b8c6-6914a0b65c2b/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 205, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:58638","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"9fbf1d90-20f8-11e7-b8c6-6914a0b65c2b\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/9fbf1d90-20f8-11e7-b8c6-6914a0b65c2b/execute"}}
Screenshot: available via screen

2017-04-14 17:59:00 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 17:59:00 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 17:59:00 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 17:59:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 9, 59, 0, 487546),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 56, 24, 870554)}
2017-04-14 17:59:00 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 17:59:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 17:59:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 17:59:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 17:59:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 17:59:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 17:59:35 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 17:59:35 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 17:59:35 [scrapy.core.engine] INFO: Spider opened
2017-04-14 17:59:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 18:02:35 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 195, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:59514","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"115247c0-20f9-11e7-bca5-d9ebfd677acd\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/115247c0-20f9-11e7-bca5-d9ebfd677acd/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 205, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:59514","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"115247c0-20f9-11e7-bca5-d9ebfd677acd\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/115247c0-20f9-11e7-bca5-d9ebfd677acd/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 214, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:59514","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"115247c0-20f9-11e7-bca5-d9ebfd677acd\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/115247c0-20f9-11e7-bca5-d9ebfd677acd/execute"}}
Screenshot: available via screen

2017-04-14 18:02:40 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 18:02:40 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-14 18:02:40 [hangzhou] INFO: we let it done:hangzhou
2017-04-14 18:02:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 14, 10, 2, 40, 908866),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 14, 9, 59, 35, 437873)}
2017-04-14 18:02:40 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-14 18:03:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-14 18:03:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-14 18:03:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-14 18:03:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-14 18:03:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-14 18:03:35 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-14 18:03:35 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-14 18:03:35 [scrapy.core.engine] INFO: Spider opened
2017-04-14 18:03:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-14 18:05:37 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 13:25:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 13:25:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 13:25:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 13:25:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 13:25:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 13:25:35 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 13:25:35 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 13:25:35 [scrapy.core.engine] INFO: Spider opened
2017-04-17 13:25:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 13:44:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 605, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:53377","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1492406994546\", \"sessionId\": \"4d11a800-232e-11e7-bfdd-8f1db79bd75d\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/4d11a800-232e-11e7-bfdd-8f1db79bd75d/element/:wdc:1492406994546/click"}}
Screenshot: available via screen

2017-04-17 13:44:54 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 13:44:54 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 13:44:54 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 13:44:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 5, 44, 54, 940270),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 17, 5, 25, 35, 495779)}
2017-04-17 13:44:54 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 13:54:25 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 13:54:25 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 13:54:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 13:54:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 13:54:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 13:54:25 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 13:54:25 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 13:54:25 [scrapy.core.engine] INFO: Spider opened
2017-04-17 13:54:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 13:55:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 191, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"null is not an object (evaluating 'document.querySelector('#sbcx-area-start').options')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56556","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"52db2500-2332-11e7-93a6-cd374e6ed29e\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/52db2500-2332-11e7-93a6-cd374e6ed29e/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 201, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"null is not an object (evaluating 'document.querySelector('#sbcx-area-start').options')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56556","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"52db2500-2332-11e7-93a6-cd374e6ed29e\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/52db2500-2332-11e7-93a6-cd374e6ed29e/execute"}}
Screenshot: available via screen

2017-04-17 13:55:01 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 13:55:01 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 13:55:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 5, 55, 1, 897655),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 17, 5, 54, 26, 6198)}
2017-04-17 13:55:01 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 13:55:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 13:55:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 13:55:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 13:55:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 13:55:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 13:55:50 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 13:55:50 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 13:55:50 [scrapy.core.engine] INFO: Spider opened
2017-04-17 13:55:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 13:56:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 195, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56962","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"83be6740-2332-11e7-a048-7128381d5a0a\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/83be6740-2332-11e7-a048-7128381d5a0a/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 205, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56962","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"83be6740-2332-11e7-a048-7128381d5a0a\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/83be6740-2332-11e7-a048-7128381d5a0a/execute"}}
Screenshot: available via screen

2017-04-17 13:56:33 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 13:56:33 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 13:56:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 466,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 5, 56, 33, 170751),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 17, 5, 55, 50, 14424)}
2017-04-17 13:56:33 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 13:57:04 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 13:57:04 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 13:57:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 13:57:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 13:57:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 13:57:05 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 13:57:05 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 13:57:05 [scrapy.core.engine] INFO: Spider opened
2017-04-17 13:57:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 14:03:42 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 14:03:45 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 14:03:45 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 14:03:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 6, 3, 45, 997699),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 5, 57, 5, 95761)}
2017-04-17 14:03:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 14:34:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 14:34:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 14:34:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 14:34:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 14:34:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 14:34:24 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 14:34:24 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 14:34:24 [scrapy.core.engine] INFO: Spider opened
2017-04-17 14:34:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 14:34:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 191, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"null is not an object (evaluating 'document.querySelector('#sbcx-area-start').options')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:61882","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"e7253c00-2337-11e7-9853-bb18ea60ea02\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/e7253c00-2337-11e7-9853-bb18ea60ea02/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 201, in parse
    driver.execute_script(js)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"null is not an object (evaluating 'document.querySelector('#sbcx-area-start').options')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"148","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:61882","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-start').options[2].selected = true\", \"args\": [], \"sessionId\": \"e7253c00-2337-11e7-9853-bb18ea60ea02\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/e7253c00-2337-11e7-9853-bb18ea60ea02/execute"}}
Screenshot: available via screen

2017-04-17 14:34:55 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 14:34:55 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 14:34:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 6, 34, 55, 971611),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 17, 6, 34, 24, 267542)}
2017-04-17 14:34:55 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 14:36:25 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 14:36:25 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 14:36:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 14:36:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 14:36:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 14:36:25 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 14:36:25 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 14:36:25 [scrapy.core.engine] INFO: Spider opened
2017-04-17 14:36:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 14:36:29 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 14:36:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 111, in parse
    driver.save_screenshot('1.png')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 802, in get_screenshot_as_file
    png = self.get_screenshot_as_png()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 821, in get_screenshot_as_png
    return base64.b64decode(self.get_screenshot_as_base64().encode('ascii'))
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 831, in get_screenshot_as_base64
    return self.execute(Command.SCREENSHOT)['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-17 14:36:29 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-17 14:36:29 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 14:36:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 17, 6, 36, 29, 537563),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 4, 17, 6, 36, 25, 485942)}
2017-04-17 14:36:29 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-17 14:36:31 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 14:36:31 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 14:36:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 14:36:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 14:36:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 14:36:32 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 14:36:32 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 14:36:32 [scrapy.core.engine] INFO: Spider opened
2017-04-17 14:36:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 14:38:16 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 14:38:16 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 14:38:16 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 14:38:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 6, 38, 16, 183082),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 6, 36, 32, 316761)}
2017-04-17 14:38:16 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 14:43:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 14:43:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 14:43:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 14:43:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 14:43:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 14:43:49 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 14:43:49 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 14:43:49 [scrapy.core.engine] INFO: Spider opened
2017-04-17 14:43:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 14:45:33 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 14:45:33 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 14:45:33 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 14:45:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 470,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 6, 45, 33, 555016),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 6, 43, 49, 863620)}
2017-04-17 14:45:33 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 14:47:32 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 14:47:32 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 14:47:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 14:47:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 14:47:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 14:47:33 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 14:47:33 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 14:47:33 [scrapy.core.engine] INFO: Spider opened
2017-04-17 14:47:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 14:49:15 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 14:49:15 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 14:49:15 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 14:49:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 6, 49, 15, 69247),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 6, 47, 33, 145173)}
2017-04-17 14:49:15 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 14:57:30 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 14:57:30 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 14:57:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 14:57:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 14:57:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 14:57:30 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 14:57:30 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 14:57:30 [scrapy.core.engine] INFO: Spider opened
2017-04-17 14:57:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 14:59:14 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 14:59:14 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 14:59:14 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 14:59:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 468,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 6, 59, 14, 490104),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 6, 57, 30, 572649)}
2017-04-17 14:59:14 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:01:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:01:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:01:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:01:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:01:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:01:15 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:01:15 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:01:15 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:01:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:01:15 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-17 15:01:15 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:01:15 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:01:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1395,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 1, 15, 515974),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 17, 7, 1, 15, 157721)}
2017-04-17 15:01:15 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:01:29 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:01:29 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:01:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:01:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:01:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:01:29 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:01:29 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:01:29 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:01:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:01:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-17 15:01:30 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:01:30 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:01:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1395,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 1, 30, 192311),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 17, 7, 1, 29, 820269)}
2017-04-17 15:01:30 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:01:36 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:01:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:01:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:01:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:01:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:01:36 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:01:36 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:01:36 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:01:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:03:20 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 15:03:20 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:03:20 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:03:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 3, 20, 53549),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 7, 1, 36, 668550)}
2017-04-17 15:03:20 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:03:50 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:03:50 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:03:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:03:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:03:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:03:51 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:03:51 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:03:51 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:03:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:04:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 197, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:51196","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"039250e0-233c-11e7-8404-0f524c654afd\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/039250e0-233c-11e7-8404-0f524c654afd/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 207, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:51196","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"039250e0-233c-11e7-8404-0f524c654afd\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/039250e0-233c-11e7-8404-0f524c654afd/execute"}}
Screenshot: available via screen

2017-04-17 15:04:38 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:04:38 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:04:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 474,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 4, 38, 113681),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 17, 7, 3, 51, 14918)}
2017-04-17 15:04:38 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:04:46 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:04:46 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:04:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:04:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:04:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:04:46 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:04:46 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:04:46 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:04:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:06:28 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 15:06:28 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:06:28 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:06:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 468,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 6, 28, 419404),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 7, 4, 46, 516428)}
2017-04-17 15:06:28 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:08:02 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:08:02 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:08:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:08:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:08:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:08:02 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:08:02 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:08:02 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:08:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:09:43 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 15:09:43 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:09:43 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:09:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 9, 43, 991140),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 7, 8, 2, 756420)}
2017-04-17 15:09:43 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:11:09 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:11:09 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:11:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:11:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:11:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:11:09 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:11:09 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:11:09 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:11:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:11:09 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-17 15:11:09 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:11:09 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:11:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1422,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 11, 9, 986264),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 17, 7, 11, 9, 581710)}
2017-04-17 15:11:09 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:11:14 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:11:14 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:11:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:11:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:11:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:11:14 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:11:14 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:11:14 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:11:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:11:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-17 15:11:14 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:11:14 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:11:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1395,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 11, 14, 984167),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 17, 7, 11, 14, 620474)}
2017-04-17 15:11:14 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:11:17 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:11:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:11:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:11:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:11:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:11:17 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:11:17 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:11:17 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:11:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:11:17 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-17 15:11:17 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:11:17 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:11:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1398,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 11, 17, 716571),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 17, 7, 11, 17, 362811)}
2017-04-17 15:11:17 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 15:12:48 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 15:12:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 15:12:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 15:12:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 15:12:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 15:12:48 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 15:12:48 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 15:12:48 [scrapy.core.engine] INFO: Spider opened
2017-04-17 15:12:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 15:14:30 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 15:14:30 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 15:14:30 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 15:14:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 466,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 7, 14, 30, 388478),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 7, 12, 48, 719897)}
2017-04-17 15:14:30 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 16:13:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 16:13:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 16:13:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 16:13:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 16:13:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 16:13:48 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 16:13:48 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 16:13:48 [scrapy.core.engine] INFO: Spider opened
2017-04-17 16:13:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 16:14:16 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 16:44:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 16:44:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 16:44:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 16:44:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 16:44:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 16:44:50 [twisted] CRITICAL: Unhandled error in Deferred:
2017-04-17 16:44:50 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 72, in crawl
    self.engine = self._create_engine()
  File "/usr/local/lib/python3.6/site-packages/scrapy/crawler.py", line 97, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "/usr/local/lib/python3.6/site-packages/scrapy/middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/misc.py", line 44, in load_object
    mod = import_module(module)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 978, in _gcd_import
  File "<frozen importlib._bootstrap>", line 961, in _find_and_load
  File "<frozen importlib._bootstrap>", line 950, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 655, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 205, in _call_with_frames_removed
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py", line 2, in <module>
    from . import mongo
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/mongo.py", line 168
    "basic_medical_cash_pay": lxml_obj_to_str(postitem["Basic_medical_cash_pay")[i],
                                                                               ^
SyntaxError: invalid syntax
2017-04-17 16:45:40 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 16:45:40 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 16:45:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 16:45:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 16:45:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 16:45:40 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 16:45:40 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 16:45:40 [scrapy.core.engine] INFO: Spider opened
2017-04-17 16:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 16:46:59 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 16:52:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 16:52:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 16:52:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 16:52:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 16:52:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 16:52:35 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 16:52:35 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 16:52:35 [scrapy.core.engine] INFO: Spider opened
2017-04-17 16:52:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 16:53:44 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 16:56:55 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 16:56:55 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 16:56:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 16:56:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 16:56:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 16:56:56 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 16:56:56 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 16:56:56 [scrapy.core.engine] INFO: Spider opened
2017-04-17 16:56:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:02:50 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 17:02:58 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:02:58 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:02:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:02:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:02:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:02:59 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:02:59 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:02:59 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:02:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:04:13 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 17:06:16 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:06:16 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:06:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:06:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:06:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:06:17 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:06:17 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:06:17 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:06:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:06:20 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 17:06:20 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 110, in parse
    driver.get("http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh")
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 250, in get
    self.execute(Command.GET, {'url': url})
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-17 17:06:20 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-17 17:06:20 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 17:06:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 17, 9, 6, 20, 565743),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 4, 17, 9, 6, 17, 473425)}
2017-04-17 17:06:20 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-17 17:06:23 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:06:23 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:06:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:06:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:06:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:06:23 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:06:23 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:06:23 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:06:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:08:00 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 17:08:00 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 17:08:00 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 17:08:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 474,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 9, 8, 0, 705714),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 9, 6, 23, 654989)}
2017-04-17 17:08:00 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 17:11:24 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:11:24 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:11:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:11:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:11:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:11:25 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:11:25 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:11:25 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:11:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:11:25 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1297, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "/usr/local/lib/python3.6/site-packages/twisted/python/failure.py", line 389, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 61: Connection refused.
2017-04-17 17:11:25 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 17:11:25 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 17:11:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/twisted.internet.error.ConnectionRefusedError': 3,
 'downloader/request_bytes': 1416,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 9, 11, 25, 651339),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 17, 9, 11, 25, 221878)}
2017-04-17 17:11:25 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 17:12:17 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:12:17 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:12:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:12:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:12:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:12:18 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:12:18 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:12:18 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:12:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:32:12 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 17:32:32 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:32:32 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:32:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:32:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:32:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:32:33 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:32:33 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:32:33 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:32:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:34:11 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 17:34:11 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 17:34:11 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 17:34:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 466,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 9, 34, 11, 354602),
 'item_scraped_count': 1,
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 9, 32, 33, 195381)}
2017-04-17 17:34:11 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 17:34:41 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:34:41 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:34:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:34:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:34:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:34:41 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:34:41 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:34:41 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:34:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:53:59 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-17 17:54:10 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:54:10 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:54:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:54:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:54:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:54:10 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:54:10 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:54:10 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:54:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 17:55:50 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 17:55:50 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 17:55:50 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 17:55:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 9, 55, 50, 948505),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 9, 54, 10, 879944)}
2017-04-17 17:55:50 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 17:59:29 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 17:59:29 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 17:59:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 17:59:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 17:59:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 17:59:30 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 17:59:30 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 17:59:30 [scrapy.core.engine] INFO: Spider opened
2017-04-17 17:59:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 18:01:09 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 18:01:09 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 18:01:09 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 18:01:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 466,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 10, 1, 9, 654001),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 9, 59, 30, 378078)}
2017-04-17 18:01:09 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 18:01:50 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 18:01:50 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 18:01:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 18:01:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 18:01:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 18:01:51 [py.warnings] WARNING: /Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/pipelines.py:14: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-04-17 18:01:51 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 18:01:51 [scrapy.core.engine] INFO: Spider opened
2017-04-17 18:01:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 18:03:55 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 18:03:59 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 18:03:59 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 18:03:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 10, 3, 59, 194063),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 10, 1, 51, 355500)}
2017-04-17 18:03:59 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-17 18:05:25 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-17 18:05:25 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-17 18:05:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-17 18:05:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-17 18:05:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-17 18:05:25 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-17 18:05:25 [scrapy.core.engine] INFO: Spider opened
2017-04-17 18:05:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-17 18:07:19 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-17 18:07:21 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-17 18:07:21 [hangzhou] INFO: we let it done:hangzhou
2017-04-17 18:07:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 474,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 17, 10, 7, 21, 473416),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 17, 10, 5, 25, 709427)}
2017-04-17 18:07:21 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-18 09:51:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-18 09:51:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-18 09:51:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-18 09:51:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-18 09:51:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-18 09:51:36 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-18 09:51:36 [scrapy.core.engine] INFO: Spider opened
2017-04-18 09:51:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-18 10:27:45 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-18 10:27:49 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-18 10:27:49 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-18 10:27:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-18 10:27:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-18 10:27:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-18 10:27:49 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-18 10:27:49 [scrapy.core.engine] INFO: Spider opened
2017-04-18 10:27:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-18 10:29:28 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-18 10:29:28 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-18 10:29:28 [hangzhou] INFO: we let it done:hangzhou
2017-04-18 10:29:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 18, 2, 29, 28, 264902),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 18, 2, 27, 49, 420472)}
2017-04-18 10:29:28 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-18 10:35:07 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-18 10:35:07 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-18 10:35:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-18 10:35:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-18 10:35:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-18 10:35:08 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-18 10:35:08 [scrapy.core.engine] INFO: Spider opened
2017-04-18 10:35:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-18 10:36:46 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2017-04-18 10:36:46 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-18 10:36:46 [hangzhou] INFO: we let it done:hangzhou
2017-04-18 10:36:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 18, 2, 36, 46, 319275),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2017, 4, 18, 2, 35, 8, 73165)}
2017-04-18 10:36:46 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 14:24:47 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 14:24:47 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 14:24:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 14:24:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 14:24:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 14:24:47 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 14:24:47 [scrapy.core.engine] INFO: Spider opened
2017-04-26 14:24:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:24:47 [scrapy.core.scraper] ERROR: Error downloading <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh>
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/util/connection.py", line 83, in create_connection
    raise err
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 356, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1026, in _send_output
    self.send(msg)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 964, in send
    self.connect()
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connection.py", line 166, in connect
    conn = self._new_conn()
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
requests.packages.urllib3.exceptions.NewConnectionError: <requests.packages.urllib3.connection.HTTPConnection object at 0x10ec80710>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/requests/adapters.py", line 423, in send
    timeout=timeout
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/connectionpool.py", line 649, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "/usr/local/lib/python3.6/site-packages/requests/packages/urllib3/util/retry.py", line 376, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
requests.packages.urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='182.254.215.182', port=5999): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x10ec80710>: Failed to establish a new connection: [Errno 61] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py", line 1299, in _inlineCallbacks
    result = g.send(result)
  File "/usr/local/lib/python3.6/site-packages/scrapy/core/downloader/middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/midle.py", line 27, in process_request
    proxy = requests.get(url, auth=('zs5scom', 'zs5scom')).text
  File "/usr/local/lib/python3.6/site-packages/requests/api.py", line 70, in get
    return request('get', url, params=params, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/requests/api.py", line 56, in request
    return session.request(method=method, url=url, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/requests/sessions.py", line 488, in request
    resp = self.send(prep, **send_kwargs)
  File "/usr/local/lib/python3.6/site-packages/requests/sessions.py", line 609, in send
    r = adapter.send(request, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/requests/adapters.py", line 487, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='182.254.215.182', port=5999): Max retries exceeded with url: / (Caused by NewConnectionError('<requests.packages.urllib3.connection.HTTPConnection object at 0x10ec80710>: Failed to establish a new connection: [Errno 61] Connection refused',))
2017-04-26 14:24:48 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 14:24:48 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 14:24:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 3,
 'downloader/exception_type_count/requests.exceptions.ConnectionError': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 6, 24, 48, 17461),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 4, 26, 6, 24, 47, 752328)}
2017-04-26 14:24:48 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 14:25:38 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 14:25:38 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 14:25:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 14:25:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 14:25:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 14:25:38 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 14:25:38 [scrapy.core.engine] INFO: Spider opened
2017-04-26 14:25:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:25:54 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-26 14:26:37 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 14:26:37 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 14:26:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 14:26:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 14:26:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 14:26:38 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 14:26:38 [scrapy.core.engine] INFO: Spider opened
2017-04-26 14:26:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:26:40 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-26 14:44:22 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 14:44:22 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 14:44:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 14:44:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 14:44:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 14:44:22 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 14:44:22 [scrapy.core.engine] INFO: Spider opened
2017-04-26 14:44:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:44:24 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-26 14:44:24 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 111, in parse
    driver = webdriver.PhantomJS()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/phantomjs/webdriver.py", line 52, in __init__
    self.service.start()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/common/service.py", line 96, in start
    self.assert_process_still_running()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/common/service.py", line 109, in assert_process_still_running
    % (self.path, return_code)
selenium.common.exceptions.WebDriverException: Message: Service phantomjs unexpectedly exited. Status code was: -2

2017-04-26 14:44:24 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-26 14:44:24 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 14:44:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 468,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 26, 6, 44, 24, 244156),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 6, 44, 22, 437542)}
2017-04-26 14:44:24 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-26 14:46:53 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 14:46:53 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 14:46:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 14:46:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 14:46:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 14:46:53 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 14:46:53 [scrapy.core.engine] INFO: Spider opened
2017-04-26 14:46:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:47:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 146, in parse
    img_url = "http://puser.zjzwfw.gov.cn/sso/" + img
TypeError: must be str, not list
2017-04-26 14:47:50 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 14:47:50 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 14:47:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 6, 47, 50, 648042),
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2017, 4, 26, 6, 46, 53, 929270)}
2017-04-26 14:47:50 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 14:48:12 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 14:48:12 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 14:48:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 14:48:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 14:48:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 14:48:12 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 14:48:12 [scrapy.core.engine] INFO: Spider opened
2017-04-26 14:48:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:51:19 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-26 14:51:57 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 14:51:57 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 14:51:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 14:51:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 14:51:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 14:51:57 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 14:51:57 [scrapy.core.engine] INFO: Spider opened
2017-04-26 14:51:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:53:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 190, in parse
    next_page = driver.find_element_by_xpath('//div[@class="rdfw_list_copy"]/div[@title=""]/div')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//div[@class=\"rdfw_list_copy\"]/div[@title=\"\"]/div'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"161","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:49889","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@class=\\\"rdfw_list_copy\\\"]/div[@title=\\\"\\u793e\\u4fdd\\u67e5\\u8be2\\\"]/div\", \"sessionId\": \"d83e1d80-2a4c-11e7-8c4b-7d1deb2ac66a\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/d83e1d80-2a4c-11e7-8c4b-7d1deb2ac66a/element"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 194, in parse
    next_page = driver.find_element_by_xpath('//div[@class="rdfw_btn_left"]')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//div[@class=\"rdfw_btn_left\"]'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"115","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:49889","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@class=\\\"rdfw_btn_left\\\"]\", \"sessionId\": \"d83e1d80-2a4c-11e7-8c4b-7d1deb2ac66a\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/d83e1d80-2a4c-11e7-8c4b-7d1deb2ac66a/element"}}
Screenshot: available via screen

2017-04-26 14:53:37 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:53:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 14:53:37 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 14:53:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 6, 53, 37, 367413),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 6, 51, 57, 436809)}
2017-04-26 14:53:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 14:54:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 14:54:35 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 14:54:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 14:54:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 14:54:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 14:54:36 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 14:54:36 [scrapy.core.engine] INFO: Spider opened
2017-04-26 14:54:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:55:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 190, in parse
    next_page = driver.find_element_by_xpath('//div[@class="rdfw_list_copy"]/div[@title=""]/div')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//div[@class=\"rdfw_list_copy\"]/div[@title=\"\"]/div'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"161","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:50246","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@class=\\\"rdfw_list_copy\\\"]/div[@title=\\\"\\u793e\\u4fdd\\u67e5\\u8be2\\\"]/div\", \"sessionId\": \"36ea1b90-2a4d-11e7-a977-e38b30000168\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/36ea1b90-2a4d-11e7-a977-e38b30000168/element"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 194, in parse
    next_page = driver.find_element_by_xpath('//div[@class="rdfw_btn_left"]')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//div[@class=\"rdfw_btn_left\"]'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"115","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:50246","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@class=\\\"rdfw_btn_left\\\"]\", \"sessionId\": \"36ea1b90-2a4d-11e7-a977-e38b30000168\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/36ea1b90-2a4d-11e7-a977-e38b30000168/element"}}
Screenshot: available via screen

2017-04-26 14:55:44 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 14:55:44 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 14:55:44 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 14:55:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 6, 55, 44, 118413),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 6, 54, 36, 227509)}
2017-04-26 14:55:44 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 15:16:34 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:16:34 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:16:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:16:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:16:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:16:35 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:16:35 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:16:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:18:28 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-26 15:23:26 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:23:26 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:23:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:23:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:23:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:23:27 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:23:27 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:23:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:24:15 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-26 15:24:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 191, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55338","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1493191441716\", \"sessionId\": \"3e8b3ec0-2a51-11e7-a922-c7341d7dae3a\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/3e8b3ec0-2a51-11e7-a922-c7341d7dae3a/element/:wdc:1493191441716/click"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 203, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 236, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 415, in execute
    return self._request(command_info[0], url, body=data)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py", line 489, in _request
    resp = opener.open(request, timeout=self._timeout)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 526, in open
    response = self._open(req, data)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 544, in _open
    '_open', req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 504, in _call_chain
    result = func(*args)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1346, in http_open
    return self.do_open(http.client.HTTPConnection, req)
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/urllib/request.py", line 1321, in do_open
    r = h.getresponse()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 1331, in getresponse
    response.begin()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "/usr/local/Cellar/python3/3.6.0/Frameworks/Python.framework/Versions/3.6/lib/python3.6/http/client.py", line 266, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response
2017-04-26 15:24:15 [scrapy.core.engine] INFO: Closing spider (shutdown)
2017-04-26 15:24:15 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 15:24:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2017, 4, 26, 7, 24, 15, 158932),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/RemoteDisconnected': 1,
 'start_time': datetime.datetime(2017, 4, 26, 7, 23, 27, 76364)}
2017-04-26 15:24:15 [scrapy.core.engine] INFO: Spider closed (shutdown)
2017-04-26 15:24:21 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:24:21 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:24:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:24:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:24:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:24:21 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:24:21 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:24:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:25:50 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 191, in parse
    next_page.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55563","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1493191537410\", \"sessionId\": \"5f199880-2a51-11e7-8b5c-0b48089874e5\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/5f199880-2a51-11e7-8b5c-0b48089874e5/element/:wdc:1493191537410/click"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 203, in parse
    next.click()
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 77, in click
    self._execute(Command.CLICK_ELEMENT)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webelement.py", line 491, in _execute
    return self._parent.execute(command, params)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementNotVisibleException: Message: {"errorMessage":"Element is not currently visible and may not be manipulated","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"81","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:55563","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"id\": \":wdc:1493191537410\", \"sessionId\": \"5f199880-2a51-11e7-8b5c-0b48089874e5\"}","url":"/click","urlParsed":{"anchor":"","query":"","file":"click","directory":"/","path":"/click","relative":"/click","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/click","queryKey":{},"chunks":["click"]},"urlOriginal":"/session/5f199880-2a51-11e7-8b5c-0b48089874e5/element/:wdc:1493191537410/click"}}
Screenshot: available via screen

2017-04-26 15:25:56 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:25:56 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 15:25:56 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 15:25:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 7, 25, 56, 316687),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ElementNotVisibleException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 7, 24, 21, 737318)}
2017-04-26 15:25:56 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 15:28:06 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:28:06 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:28:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:28:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:28:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:28:06 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:28:06 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:28:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:29:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 190, in parse
    next_page = driver.find_element_by_xpath('//div[@style="width: 1230px; left: 0px;"]//div[2]/@title')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: {"errorMessage":"Unable to find element with xpath '//div[@style=\"width: 1230px; left: 0px;\"]//div[2]/@title'","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"142","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56119","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@style=\\\"width: 1230px; left: 0px;\\\"]//div[2]/@title\", \"sessionId\": \"e514c270-2a51-11e7-9c34-8b72e4ae3fc8\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/e514c270-2a51-11e7-9c34-8b72e4ae3fc8/element"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 202, in parse
    next = driver.find_element_by_xpath('//div[@style="width: 1230px; left: 0px;"]//div[2]/@title')
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 295, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 756, in find_element
    'value': value})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: {"errorMessage":"The result of the xpath expression \"//div[@style=\"width: 1230px; left: 0px;\"]//div[2]/@title\" is: [object Attr]. It should be an element.","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"142","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56119","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"using\": \"xpath\", \"value\": \"//div[@style=\\\"width: 1230px; left: 0px;\\\"]//div[2]/@title\", \"sessionId\": \"e514c270-2a51-11e7-9c34-8b72e4ae3fc8\"}","url":"/element","urlParsed":{"anchor":"","query":"","file":"element","directory":"/","path":"/element","relative":"/element","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/element","queryKey":{},"chunks":["element"]},"urlOriginal":"/session/e514c270-2a51-11e7-9c34-8b72e4ae3fc8/element"}}
Screenshot: available via screen

2017-04-26 15:29:22 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:29:22 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 15:29:22 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 15:29:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 7, 29, 22, 332601),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/InvalidSelectorException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 7, 28, 6, 532735)}
2017-04-26 15:29:22 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 15:30:15 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:30:15 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:30:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:30:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:30:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:30:15 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:30:15 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:30:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:32:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 228, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56439","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"3226fbf0-2a52-11e7-aca2-77469ff020f5\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/3226fbf0-2a52-11e7-aca2-77469ff020f5/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 238, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:56439","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"3226fbf0-2a52-11e7-aca2-77469ff020f5\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/3226fbf0-2a52-11e7-aca2-77469ff020f5/execute"}}
Screenshot: available via screen

2017-04-26 15:32:37 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:32:37 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 15:32:37 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 15:32:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 7, 32, 37, 128879),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 7, 30, 15, 845033)}
2017-04-26 15:32:37 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 15:33:11 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:33:11 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:33:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:33:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:33:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:33:11 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:33:11 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:33:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:34:27 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-26 15:38:12 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:38:12 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:38:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:38:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:38:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:38:12 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:38:12 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:38:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:47:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 228, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:57628","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"4e4ada30-2a53-11e7-96d2-958693ed1924\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/4e4ada30-2a53-11e7-96d2-958693ed1924/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 238, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:57628","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"4e4ada30-2a53-11e7-96d2-958693ed1924\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/4e4ada30-2a53-11e7-96d2-958693ed1924/execute"}}
Screenshot: available via screen

2017-04-26 15:47:19 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:47:19 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 15:47:19 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 15:47:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 466,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 7, 47, 19, 800312),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 7, 38, 12, 454689)}
2017-04-26 15:47:19 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 15:47:48 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:47:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:47:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:47:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:47:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:47:48 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:47:48 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:47:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:49:03 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 228, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:58743","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"a60b5730-2a54-11e7-9f88-ebc88be22597\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/a60b5730-2a54-11e7-9f88-ebc88be22597/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 239, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:58743","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"a60b5730-2a54-11e7-9f88-ebc88be22597\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/a60b5730-2a54-11e7-9f88-ebc88be22597/execute"}}
Screenshot: available via screen

2017-04-26 15:49:03 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 15:49:03 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 15:49:03 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 15:49:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 465,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 7, 49, 3, 51073),
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 7, 47, 48, 247823)}
2017-04-26 15:49:03 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 15:58:35 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 15:58:36 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 15:58:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 15:58:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 15:58:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 15:58:36 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 15:58:36 [scrapy.core.engine] INFO: Spider opened
2017-04-26 15:58:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 16:00:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://puser.zjzwfw.gov.cn/sso/usp.do?action=ssoLogin&servicecode=njdh> (referer: None)
Traceback (most recent call last):
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 228, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"undefined is not an object (evaluating 'document.querySelector('#sbcx-area-end').options[1].selected = true')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"146","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:61375","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('#sbcx-area-end').options[1].selected = true\", \"args\": [], \"sessionId\": \"284c90f0-2a56-11e7-8fc1-119590108a6f\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/284c90f0-2a56-11e7-8fc1-119590108a6f/execute"}}
Screenshot: available via screen


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/site-packages/scrapy/utils/defer.py", line 102, in iter_errback
    yield next(it)
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/offsite.py", line 29, in process_spider_output
    for x in result:
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/referer.py", line 22, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/usr/local/lib/python3.6/site-packages/scrapy/spidermiddlewares/depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "/Users/xiaxiaodong/python/python3/social_security_spider/social_security_spider/spiders/spider.py", line 239, in parse
    driver.execute_script(js2)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 467, in execute_script
    'args': converted_args})['value']
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py", line 238, in execute
    self.error_handler.check_response(response)
  File "/usr/local/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py", line 193, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: {"errorMessage":"null is not an object (evaluating 'document.querySelector('.sbcx-pre-condition city form-control').options')","request":{"headers":{"Accept":"application/json","Accept-Encoding":"identity","Connection":"close","Content-Length":"169","Content-Type":"application/json;charset=UTF-8","Host":"127.0.0.1:61375","User-Agent":"Python-urllib/3.6"},"httpVersion":"1.1","method":"POST","post":"{\"script\": \"document.querySelector('.sbcx-pre-condition city form-control').options[1].selected = true\", \"args\": [], \"sessionId\": \"284c90f0-2a56-11e7-8fc1-119590108a6f\"}","url":"/execute","urlParsed":{"anchor":"","query":"","file":"execute","directory":"/","path":"/execute","relative":"/execute","port":"","host":"","password":"","user":"","userInfo":"","authority":"","protocol":"","source":"/execute","queryKey":{},"chunks":["execute"]},"urlOriginal":"/session/284c90f0-2a56-11e7-8fc1-119590108a6f/execute"}}
Screenshot: available via screen

2017-04-26 16:00:47 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 16:00:47 [scrapy.core.engine] INFO: Closing spider (finished)
2017-04-26 16:00:47 [hangzhou] INFO: we let it done:hangzhou
2017-04-26 16:00:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 19904,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 4, 26, 8, 0, 47, 776783),
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2017, 4, 26, 7, 58, 36, 298502)}
2017-04-26 16:00:47 [scrapy.core.engine] INFO: Spider closed (finished)
2017-04-26 16:48:01 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 16:48:01 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 16:48:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 16:48:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 16:48:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 16:48:01 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 16:48:01 [scrapy.core.engine] INFO: Spider opened
2017-04-26 16:48:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 17:04:53 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
2017-04-26 17:05:02 [scrapy.utils.log] INFO: Scrapy 1.3.0 started (bot: social_security_spider)
2017-04-26 17:05:02 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'social_security_spider', 'LOG_FILE': 'scrapy.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'social_security_spider.spiders', 'SPIDER_MODULES': ['social_security_spider.spiders']}
2017-04-26 17:05:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-04-26 17:05:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['social_security_spider.midle.ProxyMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'social_security_spider.midle.RotateUserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-04-26 17:05:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-04-26 17:05:02 [scrapy.middleware] INFO: Enabled item pipelines:
['social_security_spider.pipelines.MongoDBPipeline']
2017-04-26 17:05:02 [scrapy.core.engine] INFO: Spider opened
2017-04-26 17:05:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-04-26 17:10:56 [scrapy.crawler] INFO: Received SIG_UNBLOCK, shutting down gracefully. Send again to force 
